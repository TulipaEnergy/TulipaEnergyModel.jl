<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Data-Handling Workflow From Raw Data (Example) · TulipaEnergyModel.jl</title><meta name="title" content="Data-Handling Workflow From Raw Data (Example) · TulipaEnergyModel.jl"/><meta property="og:title" content="Data-Handling Workflow From Raw Data (Example) · TulipaEnergyModel.jl"/><meta property="twitter:title" content="Data-Handling Workflow From Raw Data (Example) · TulipaEnergyModel.jl"/><meta name="description" content="Documentation for TulipaEnergyModel.jl."/><meta property="og:description" content="Documentation for TulipaEnergyModel.jl."/><meta property="twitter:description" content="Documentation for TulipaEnergyModel.jl."/><meta property="og:url" content="https://TulipaEnergy.github.io/TulipaEnergyModel.jl/10-tutorials/20-workflow-from-raw-data/"/><meta property="twitter:url" content="https://TulipaEnergy.github.io/TulipaEnergyModel.jl/10-tutorials/20-workflow-from-raw-data/"/><link rel="canonical" href="https://TulipaEnergy.github.io/TulipaEnergyModel.jl/10-tutorials/20-workflow-from-raw-data/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="TulipaEnergyModel.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TulipaEnergyModel.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Welcome</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../11-setting-up/">Tutorial Setup</a></li><li><a class="tocitem" href="../12-basics/">The Basics</a></li><li><a class="tocitem" href="../13-assets/">Gereralized Assets and Flows</a></li><li><a class="tocitem" href="../14-fully-flexible-time/">Fully-Flexible Time Resolution</a></li><li><a class="tocitem" href="../15-clustering-rep-periods/">Blended Representative Periods with Tulipa Clustering</a></li><li><a class="tocitem" href="../16-storage/">Seasonal and Non-seasonal Storage</a></li><li><a class="tocitem" href="../17-multi-year-investments/">Multi-Year Investment Pathways</a></li><li><a class="tocitem" href="../18-stochastic/">Two-Stage Stochastic Optimization</a></li><li><a class="tocitem" href="../19-workflow-obz/">Data-Handling Workflow (Example)</a></li><li class="is-active"><a class="tocitem" href>Data-Handling Workflow From Raw Data (Example)</a><ul class="internal"><li><a class="tocitem" href="#1.-Set-up"><span>1. Set up</span></a></li><li><a class="tocitem" href="#2.-Context-and-input-data"><span>2. Context and input data</span></a></li><li><a class="tocitem" href="#3.-Transforming-and-cleaning-the-data"><span>3. Transforming and cleaning the data</span></a></li><li><a class="tocitem" href="#4.-Running-the-model"><span>4. Running the model</span></a></li><li><a class="tocitem" href="#5.-Inspect-the-results"><span>5. Inspect the results</span></a></li><li><a class="tocitem" href="#6.-Construct-the-second-scenario"><span>6. Construct the second scenario</span></a></li><li><a class="tocitem" href="#7.-Analyze-differences-between-the-two-scenarios"><span>7. Analyze differences between the two scenarios</span></a></li><li><a class="tocitem" href="#8.-Further-analysis"><span>8. Further analysis</span></a></li></ul></li><li><a class="tocitem" href="../31-rolling-horizon/">Rolling Horizon</a></li><li><a class="tocitem" href="../40-bids-workaround/">Bids using Consumer Unit Commitment (Workaround)</a></li><li><a class="tocitem" href="../99-manual-steps/">Advanced Control</a></li></ul></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../../20-user-guide/00-getting-started/">Getting Started</a></li><li><a class="tocitem" href="../../20-user-guide/20-how-to-use/">How to Use</a></li><li><a class="tocitem" href="../../20-user-guide/50-workflow/">Analysis Workflow</a></li><li><a class="tocitem" href="../../20-user-guide/54-input-table-schemas/">Input Table Schemas</a></li><li><a class="tocitem" href="../../20-user-guide/55-outputs/">Output Variables</a></li><li><a class="tocitem" href="../../20-user-guide/60-structures/">Internal Model Structures</a></li><li><a class="tocitem" href="../../20-user-guide/65-FFTR-table/">FFTR Constraints Table</a></li></ul></li><li><a class="tocitem" href="../../30-concepts/">Concepts</a></li><li><span class="tocitem">Scientific Foundation</span><ul><li><a class="tocitem" href="../../40-scientific-foundation/40-formulation/">Mathematical Formulation</a></li><li><a class="tocitem" href="../../40-scientific-foundation/45-scientific-references/">Scientific References</a></li></ul></li><li><a class="tocitem" href="../../70-reference/">API Reference</a></li><li><a class="tocitem" href="../../80-ecosystem/">Tulipa Ecosystem</a></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../90-contributing/90-contributing/">Contributing Guidelines</a></li><li><a class="tocitem" href="../../90-contributing/91-developer/">Developer Documentation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Data-Handling Workflow From Raw Data (Example)</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Data-Handling Workflow From Raw Data (Example)</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TulipaEnergy/TulipaEnergyModel.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/TulipaEnergy/TulipaEnergyModel.jl/blob/main/docs/src/10-tutorials/20-workflow-from-raw-data.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="workflow-tutorial-raw-data"><a class="docs-heading-anchor" href="#workflow-tutorial-raw-data">Data-Handling Workflow From Raw Data (Example)</a><a id="workflow-tutorial-raw-data-1"></a><a class="docs-heading-anchor-permalink" href="#workflow-tutorial-raw-data" title="Permalink"></a></h1><p>In previous tutorials you have learned how to work with TulipaEnergyModel and related tools such as TulipaClustering and TulipaIO. However, we have not yet considered data requirements and processing to get to these steps. How do we work with &#39;raw&#39; data and convert it to the format needed for running the optimization model? How are results stored? How do we compare scenarios with different assumptions for input data? This tutorial will be about teaching you the basics in the workflow that are currently supported.</p><div class="admonition is-info" id="Important-note-802057d33024c5a4"><header class="admonition-header">Important note<a class="admonition-anchor" href="#Important-note-802057d33024c5a4" title="Permalink"></a></header><div class="admonition-body"><p>There are many ways to go about processing data, depending on your preferences. The work below is simply an example! For a general overview please visit the <a href="../../20-user-guide/50-workflow/#data">Analysis Workflow</a> section.</p></div></div><h2 id="1.-Set-up"><a class="docs-heading-anchor" href="#1.-Set-up">1. Set up</a><a id="1.-Set-up-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Set-up" title="Permalink"></a></h2><div class="admonition is-warning" id="Version-compatibility-df6476856685aa61"><header class="admonition-header">Version compatibility<a class="admonition-anchor" href="#Version-compatibility-df6476856685aa61" title="Permalink"></a></header><div class="admonition-body"><p>The code in this tutorial is based on TulipaEnergyModel version 0.18.2. If you are on a different version, some of the code may not work as expected. We recommend creating a separate environment for this tutorial. You can check your version and update if necessary using the following code:</p></div></div><pre><code class="language-julia hljs"># Check what TulipaEnergyModel version you are on
Pkg.status()
# or in console type ] followed by &#39;status TulipaEnergyModel&#39;
# if necessary run the following to ensure the compatible version for this tutorial is installed:
# Pkg.add(name=&quot;TulipaEnergyModel&quot;, version=&quot;0.18.2&quot;)</code></pre><p>Like previous tutorials we will start with working in our &#39;workflow.jl&#39; file. There are a couple of new packages we will add first.</p><pre><code class="language-julia hljs"># Guarantee to run in the current directory
using Pkg: Pkg
Pkg.activate(&quot;.&quot;)

# Add new packages specific for this tutorial
Pkg.add(&quot;CSV&quot;)          # For working with CSV files
Pkg.add(&quot;Chain&quot;)        # For handling data transformation
Pkg.add(&quot;Tables&quot;)       # For manipulating the data tables
Pkg.add(&quot;DBInterface&quot;)  # For conducting queries
Pkg.add(&quot;ODBC&quot;)         # For working with Microsoft Access database files
Pkg.add(&quot;DataFrames&quot;)
Pkg.add(&quot;Plots&quot;)

# Load the packages
import TulipaIO as TIO
import TulipaEnergyModel as TEM
using DuckDB
using DBInterface
using DataFrames
using Plots
using CSV
using Chain
using Tables
using ODBC</code></pre><h2 id="2.-Context-and-input-data"><a class="docs-heading-anchor" href="#2.-Context-and-input-data">2. Context and input data</a><a id="2.-Context-and-input-data-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Context-and-input-data" title="Permalink"></a></h2><p>We are interested in investigating the electricity prices in our future system, in moments where both solar PV and wind make up a large share of our electricity production. This will help us understand the role that dispatchable/storage technologies play within the system.</p><p>All input data required for this tutorial can be found here: <a href="https://zenodo.org/records/17454936">https://zenodo.org/records/17454936</a></p><p>Download the data and place them in a directory similar to the previous tutorials (within your VS project), for example <code>my-awesome-energy-system/tutorial-7</code>. As can be seen in this folder, the data is comprised of different file types. We have .csv files for our hourly profiles, .xlsx files for our asset and technology data, and a .accdb file for storage metadata.</p><p>The first thing we should do is transforming and cleaning the data. As you know by now, TulipaEnergyModel requires input data to be in a specific format following the schemas as explained in the documentation.</p><h2 id="3.-Transforming-and-cleaning-the-data"><a class="docs-heading-anchor" href="#3.-Transforming-and-cleaning-the-data">3. Transforming and cleaning the data</a><a id="3.-Transforming-and-cleaning-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Transforming-and-cleaning-the-data" title="Permalink"></a></h2><p>Let&#39;s start with the hourly profiles for demand and variable renewable energy production. These are respectively named <code>electricity_demand.csv</code>, <code>ninja-pv-country-NL-national-merra2</code> and <code>ninja-wind-country-NL-future_total-merra2</code>. The demand profiles are extracted from the ETM, which provides data on several scenario studies concerning the future electricity (and hydrogen and gas) system of the Netherlands. The original source can be found here <a href="https://my.energytransitionmodel.com/saved_scenarios/19919">https://my.energytransitionmodel.com/saved_scenarios/19919</a>. The production profiles are sourced from Renewables.ninja, which can be found here <a href="https://www.renewables.ninja/">https://www.renewables.ninja/</a>. We will start with the demand data.</p><pre><code class="language-julia hljs"># Create a DuckDB file to store the input data
db_file = joinpath(&quot;my-awesome-energy-system&quot;, &quot;tutorial-7&quot;, &quot;data.db&quot;)

# We will continue to make a connection
connection = DuckDB.DB(db_file)            # Create a connection to the database file

# You should see a &quot;data.db&quot; file in your repository now

# Let&#39;s import our input data into the DuckDB file
# First, define a default directory for DuckDB to conduct queries
script_dir = @__DIR__  # this gives the directory of the current script

DBInterface.execute(connection, &quot;SET FILE_SEARCH_PATH=&#39;$(script_dir)&#39;&quot;)

DBInterface.execute(connection, &quot;&quot;&quot;
    CREATE TABLE electricity_demand AS
    SELECT * FROM read_csv_auto(&#39;my-awesome-energy-system/tutorial-7/electricity_demand.csv&#39;)
&quot;&quot;&quot;)

#DBInterface.execute(connection, &quot;DROP TABLE IF EXISTS electricity_demand&quot;)

elec_demand = DBInterface.execute(connection, &quot;SELECT * FROM electricity_demand&quot;) |&gt; DataFrame

# You should see that a 8760x285 DataFrame is present, showing electricity output and input for various sectors across the year
# Now let&#39;s remove columns we do not need. We are only interested in the time (Time) and any column mentioning electricity input (demand)

cols_to_keep = filter(c -&gt; c == &quot;Time&quot; || occursin(&quot;input&quot;, c), names(elec_demand))
elec_demand = elec_demand[:, cols_to_keep]

cols_to_sum = filter(c -&gt; c != &quot;Time&quot;, names(elec_demand))
elec_demand.value = sum.(eachrow(elec_demand[:, cols_to_sum]))

elec_demand = elec_demand[:, [&quot;Time&quot;, &quot;value&quot;]]

# change Datetime to timestep
elec_demand.Time = 1:nrow(elec_demand)

# rename Time to timestep
rename!(elec_demand, :Time =&gt; :timestep)

# normalize data

max_demand = maximum(elec_demand.value)
max_demand
elec_demand.value .= elec_demand.value ./ max_demand
</code></pre><p>The demand dataframe has now been properly constructed in our database file. We will now continue with the production profiles for variable renewable energy. As mentioned before, we will be working with data generated through Renewables.ninja for both solar PV and wind.</p><pre><code class="language-julia hljs">
# Solar production

DBInterface.execute(connection, &quot;&quot;&quot;
    CREATE TABLE solar_production AS
    SELECT * FROM read_csv_auto(&#39;my-awesome-energy-system/tutorial-7/ninja-pv-country-NL-national-merra2.csv&#39;)
&quot;&quot;&quot;)

solar_prod = DBInterface.execute(connection, &quot;SELECT * FROM solar_production&quot;) |&gt; DataFrame
solar_prod = solar_prod[4:end, :]
rename!(solar_prod, [:timestep, :value])

solar_prod.value = parse.(Float64, solar_prod.value)

solar_prod = solar_prod[occursin.(&quot;2015&quot;, solar_prod.timestep), :]

solar_prod.timestep = 1:nrow(solar_prod)

# Wind production

DBInterface.execute(connection, &quot;&quot;&quot;
    CREATE TABLE wind_production AS
    SELECT * FROM read_csv_auto(&#39;my-awesome-energy-system/tutorial-7/ninja-wind-country-NL-future_total-merra2.csv&#39;)
&quot;&quot;&quot;)

wind_prod = DBInterface.execute(connection, &quot;SELECT * FROM wind_production&quot;) |&gt; DataFrame
wind_prod = wind_prod[4:end, 1:2]

rename!(wind_prod, [:timestep, :value])
wind_prod.value = parse.(Float64, wind_prod.value)


wind_prod = wind_prod[occursin.(&quot;2015&quot;, wind_prod.timestep), :]

wind_prod.timestep = 1:nrow(wind_prod)
</code></pre><p>Now that we have transformed and cleaned our original data, we will structure it in a way that matches the required input format to run TulipaEnergyModel.</p><pre><code class="language-julia hljs">
# Consider the three dataframes from before: electricity demand, solar production and wind production. Now add columns to match schemas.

insertcols!(elec_demand, 1, :profile_name =&gt; fill(&quot;demand-demand&quot;, nrow(elec_demand)))
insertcols!(elec_demand, 2, :year =&gt; fill(&quot;2050&quot;, nrow(elec_demand)))
insertcols!(elec_demand, 3, :rep_period =&gt; fill(&quot;1&quot;, nrow(elec_demand)))

insertcols!(solar_prod, 1, :profile_name =&gt; fill(&quot;availability-solar&quot;, nrow(solar_prod)))
insertcols!(solar_prod, 2, :year =&gt; fill(&quot;2050&quot;, nrow(solar_prod)))
insertcols!(solar_prod, 3, :rep_period =&gt; fill(&quot;1&quot;, nrow(solar_prod)))

insertcols!(wind_prod, 1, :profile_name =&gt; fill(&quot;availability-wind&quot;, nrow(wind_prod)))
insertcols!(wind_prod, 2, :year =&gt; fill(&quot;2050&quot;, nrow(wind_prod)))
insertcols!(wind_prod, 3, :rep_period =&gt; fill(&quot;1&quot;, nrow(wind_prod)))</code></pre><p>All profile-dependent data is now transformed and cleaned, and has what we need to structure it into one profiles-periods file according to the schema.</p><pre><code class="language-julia hljs">
# We can vertically concatenate the data into one dataframe

profiles_rep_periods = vcat(elec_demand, solar_prod, wind_prod)

# Write back to DuckDB file using the connection we established earlier

DuckDB.register_data_frame(connection, profiles_rep_periods, &quot;profiles_rep_periods_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE profiles_rep_periods AS SELECT * FROM profiles_rep_periods_temp&quot;)

# Check using TIO

TIO.show_tables(connection)  # View all the table names in the DuckDB connection

# ALTERNATIVELY (see how TIO simplifies this query?)

tables = DBInterface.execute(connection, &quot;&quot;&quot;
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema = &#39;main&#39;
&quot;&quot;&quot;) |&gt; DataFrame

println(tables)

</code></pre><p>Since we are creating this energy system from scratch, we will need to construct some dataframes ourselves to meet the minimum input criteria for running the model. In particular, we need to establish some information related to the assets, flows and other timeframe related parameters.</p><p>We will first establish the assets we want to have in our simplified energy system. Since we are interested in the impact of variable renewable energy technologies, we will consider both variable and dispatchable energy technologies. The underlying assumption is we are considering 2050 in a (largely) decarbonized system</p><pre><code class="language-julia hljs">
# Create the dataframe
asset = DataFrame(
    asset = String[],
    type  = String[],
    capacity = Float64[],
    investment_method = String[],
    investment_integer = Bool[],
    technical_lifetime = Int[],
    discount_rate = Float64[]
)

# Add rows
push!(asset, (&quot;ccgt_ccs&quot;, &quot;producer&quot;, 84600.0, &quot;simple&quot;, true, 15, 0.05))
push!(asset, (&quot;solar&quot;, &quot;producer&quot;, 550000.0, &quot;simple&quot;, true, 15, 0.05))
push!(asset, (&quot;wind&quot;, &quot;producer&quot;, 134000.0, &quot;simple&quot;, true, 15, 0.05))
push!(asset, (&quot;e_demand&quot;, &quot;consumer&quot;, 0.0, &quot;none&quot;, false, 15, 0.05))
push!(asset, (&quot;ens&quot;, &quot;producer&quot;, 1000000.0, &quot;none&quot;, false, 15, 0.05))

# The dataframe &#39;asset_both&#39; is based on the assets chosen above and can be constructed as follows

asset_both = DataFrame(
    asset = asset.asset,                        # reuse the &#39;asset&#39; column
    milestone_year = fill(2050, nrow(asset)),             # constant 2050
    commission_year = fill(2050, nrow(asset)),            # constant 2050
    initial_units = fill(1.0, nrow(asset))                # constant 1.0
)

# The dataframes &#39;asset_commission&#39; and &#39;asset_milestone&#39; are based off of &#39;asset&#39; and &#39;asset_both&#39; and can be constructed as follows

asset_commission = DataFrame(
    asset = asset.asset,                         # reuse &#39;asset&#39; column
    commission_year = asset_both.commission_year, # reuse &#39;commission_year&#39;
    investment_cost = fill(0.0, nrow(asset)),             # all zeros
    investment_limit = Vector{Union{Missing, Float64}}(missing, nrow(asset)),  # empty entries, can either contain missing or float64 values (to prevent type errors later)
    fixed_cost_storage_energy = fill(5.0, nrow(asset))    # all 5.0
)


asset_milestone = DataFrame(
    asset = asset.asset,                         # reuse &#39;asset&#39; column
    milestone_year = asset_both.milestone_year, # reuse &#39;commission_year&#39;
    investable = fill(&quot;false&quot;, nrow(asset)),             # all zeros
    peak_demand = fill(0.0, nrow(asset)),  # empty entries (remember, we will need to define peak demand by our variable &#39;max_demand&#39; later)
    commodity_price = fill(0.0, nrow(asset))    # all 5.0
)

asset_milestone.peak_demand[asset_milestone.asset .== &quot;e_demand&quot;] .= max_demand

# The dataframe assets_profiles is manually constructed for a few assets to later link them to the production/demand profiles

assets_profiles = DataFrame(
    asset = String[],
    commission_year = Int[],
    profile_type = String[],
    profile_name = String[]
)

# Add rows
push!(assets_profiles, (&quot;wind&quot;, 2050, &quot;availability&quot;, &quot;availability-wind&quot;))
push!(assets_profiles, (&quot;solar&quot;, 2050, &quot;availability&quot;, &quot;availability-solar&quot;))
push!(assets_profiles, (&quot;e_demand&quot;, 2050, &quot;demand&quot;, &quot;demand-demand&quot;))

# Add all asset dataframes to DuckDB file

DuckDB.register_data_frame(connection, asset, &quot;asset_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE asset AS SELECT * FROM asset_temp&quot;)

DuckDB.register_data_frame(connection, asset_both, &quot;asset_both_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE asset_both AS SELECT * FROM asset_both_temp&quot;)

DuckDB.register_data_frame(connection, asset_commission, &quot;asset_commission_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE asset_commission AS SELECT * FROM asset_commission_temp&quot;)

DuckDB.register_data_frame(connection, asset_milestone, &quot;asset_milestone_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE asset_milestone AS SELECT * FROM asset_milestone_temp&quot;)

DuckDB.register_data_frame(connection, assets_profiles, &quot;assets_profiles_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE assets_profiles AS SELECT * FROM assets_profiles_temp&quot;)


# Use TIO again to view how many tables we have in our database

TIO.show_tables(connection)
</code></pre><p>After constructing the asset-related datafiles and writing them to our DuckDB file, we will now do the same for the tables related to flows.</p><pre><code class="language-julia hljs">
flow = DataFrame(
    from_asset = String[],
    to_asset = String[],
    technical_lifetime = Int[],
    discount_rate = Float64[]
)

push!(flow, (&quot;ens&quot;, &quot;e_demand&quot;, 10, 0.02))
push!(flow, (&quot;ccgt_ccs&quot;, &quot;e_demand&quot;, 10, 0.02))
push!(flow, (&quot;wind&quot;, &quot;e_demand&quot;, 10, 0.02))
push!(flow, (&quot;solar&quot;, &quot;e_demand&quot;, 10, 0.02))

# We will also construct flow_both and keep it empty (for now)

flow_both = DataFrame(
    from_asset = String[],
    to_asset = String[],
    milestone_year = Int[],
    commission_year = Int[],
    decommissionable = Bool[]
)

# The dataframes flow_commission and flow_milestone are based off of the flow database and can be constructed as follows

flow_commission = DataFrame(
    from_asset = flow.from_asset,                 # reuse column
    to_asset   = flow.to_asset,                   # reuse column
    commission_year = fill(2050, nrow(flow)),             # constant 2050
    conversion_coefficient = fill(1.0, nrow(flow))        # constant 1.0
)

flow_milestone = DataFrame(
    from_asset = String[],
    to_asset = String[],
    milestone_year = Int[],
    operational_cost = Float64[]
)

push!(flow_milestone, (&quot;ens&quot;, &quot;e_demand&quot;, 2050, 180))
push!(flow_milestone, (&quot;ccgt_ccs&quot;, &quot;e_demand&quot;, 2050, 90))
push!(flow_milestone, (&quot;wind&quot;, &quot;e_demand&quot;, 2050, 5))
push!(flow_milestone, (&quot;solar&quot;, &quot;e_demand&quot;, 2050, 5))

# flow = nothing  # used for resetting table after pushing rows

# Finally, write flow dataframes to DuckDB file

DuckDB.register_data_frame(connection, flow, &quot;flow_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE flow AS SELECT * FROM flow_temp&quot;)

DuckDB.register_data_frame(connection, flow_both, &quot;flow_both_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE flow_both AS SELECT * FROM flow_both_temp&quot;)

DuckDB.register_data_frame(connection, flow_commission, &quot;flow_commission_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE flow_commission AS SELECT * FROM flow_commission_temp&quot;)

DuckDB.register_data_frame(connection, flow_milestone, &quot;flow_milestone_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE flow_milestone AS SELECT * FROM flow_milestone_temp&quot;)


# Check and confirm your dataframes have been added to the database

TIO.show_tables(connection)
</code></pre><p>Finally, we need to add the dataframes related to the timeframe of the model and how it should consider representative periods</p><pre><code class="language-julia hljs">
# We will construct the remaining dataframes needed to run the model as follows

# rep-periods-data, we can use representative periods to simplify our energy problem further


rep_periods_data = DataFrame(
    year = Int[],
    rep_period = Int[],
    num_timesteps = Int[],
    resolution = Float64[]
)

push!(rep_periods_data, (2050, 1, 8760, 1.0))


rep_periods_mapping = DataFrame(
    year = Int[],
    period = Int[],
    rep_period = Int[],
    weight = Float64[]
)

push!(rep_periods_mapping, (2050, 1, 1, 1.0))

timeframe_data = DataFrame(
    year = Int[],
    period = Int[],
    num_timesteps = Int[]
)

push!(timeframe_data, (2050, 1, 8760))

year_data = DataFrame(
    year = Int[],
    length = Int[],
    is_milestone = Bool[]
)

push!(year_data, (2050, 8760, true))

# Add dataframes to DuckDB file

DuckDB.register_data_frame(connection, rep_periods_data, &quot;rep_periods_data_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE rep_periods_data AS SELECT * FROM rep_periods_data_temp&quot;)

DuckDB.register_data_frame(connection, rep_periods_mapping, &quot;rep_periods_mapping_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE rep_periods_mapping AS SELECT * FROM rep_periods_mapping_temp&quot;)

DuckDB.register_data_frame(connection, timeframe_data, &quot;timeframe_data_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE timeframe_data AS SELECT * FROM timeframe_data_temp&quot;)

DuckDB.register_data_frame(connection, year_data, &quot;year_data_temp&quot;)
DBInterface.execute(connection, &quot;CREATE TABLE year_data AS SELECT * FROM year_data_temp&quot;)


# Finally, check to see if you have added the dataframes to the database properly

TIO.show_tables(connection)
</code></pre><p>We now should have everything we need to be able to run the model. Before we continue, a wise intermediate step to take would be to save the data you have processed so far in a separate backup DuckDB file. This way, if anything goes wrong with any further data manipulation, you will always be able to go back to this point. To make a backup, follow the following steps</p><pre><code class="language-julia hljs">
backup_file = joinpath(&quot;my-awesome-energy-system&quot;, &quot;tutorial-7&quot;, &quot;data_backup.db&quot;)

# Close connection before copying (or it will give you an error)

GC.gc()
connection = nothing
GC.gc()
connection = nothing

# Check to see if it prints nothing
connection


# Copy the data from your working file &#39;data.db&#39; into your new backup file &#39;data_backup.db&#39; (we defined db_file earlier on in the tutorial)
cp(db_file, backup_file; force=true)
println(&quot;Backup created at: $backup_file&quot;)

# reconnect

connection = DuckDB.DB(db_file)

# alternatively, if you want to load in your backup
# connection = DuckDB.DB(backup_file)
</code></pre><h2 id="4.-Running-the-model"><a class="docs-heading-anchor" href="#4.-Running-the-model">4. Running the model</a><a id="4.-Running-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Running-the-model" title="Permalink"></a></h2><p>At this point, we have a connection to our main database file, as well as a backup should anything get lost for whatever reason.</p><p>To run the model, we first populate with defaults as we did in previous tutorials. Next up; run!</p><pre><code class="language-julia hljs">
TEM.populate_with_defaults!(connection)

#remember to create a results folder before running
mkpath(&quot;my-awesome-energy-system/tutorial-7/results&quot;)

output_dir = &quot;my-awesome-energy-system/tutorial-7/results&quot;

energy_problem =
    TEM.run_scenario(connection; output_folder=output_dir)
</code></pre><h2 id="5.-Inspect-the-results"><a class="docs-heading-anchor" href="#5.-Inspect-the-results">5. Inspect the results</a><a id="5.-Inspect-the-results-1"></a><a class="docs-heading-anchor-permalink" href="#5.-Inspect-the-results" title="Permalink"></a></h2><p>Plot the electricity prices</p><p>What do you see?</p><pre><code class="language-julia hljs">TIO.get_table(connection, &quot;cons_balance_consumer&quot;)

# plot the prices

balance = TIO.get_table(connection, &quot;cons_balance_consumer&quot;)

asset = &quot;e_demand&quot;
year = 2050
rep_period = 1

filtered_asset = filter(
    row -&gt;
        row.asset == asset &amp;&amp;
            row.year == year &amp;&amp;
            row.rep_period == rep_period,
    balance,
)

plot(
    filtered_asset.time_block_start,
    filtered_asset.dual_balance_consumer;
    #label=string(from_asset, &quot; -&gt; &quot;, to_asset),
    xlabel=&quot;Hour&quot;,
    ylabel=&quot;[Euro/MWh]&quot;,
    ylims=(0,200),
    xlims=(0, 768),
    dpi=600,
)
</code></pre><p>Relatively high prices, even some energy not served! High variability of prices. Feel free to play around with the plot range to consider different moments in the year, it is currently only displaying from timestep 0 to 768. Notice the size of the problem, construction time, solving time. Keep this in mind for the next steps.</p><h2 id="6.-Construct-the-second-scenario"><a class="docs-heading-anchor" href="#6.-Construct-the-second-scenario">6. Construct the second scenario</a><a id="6.-Construct-the-second-scenario-1"></a><a class="docs-heading-anchor-permalink" href="#6.-Construct-the-second-scenario" title="Permalink"></a></h2><p>As can be seen from the electricity prices, the system seems to struggle with delivering enough electricity to satisfy demand, causing ENS pricing to activate. We will now add storage to the model to see how this alleviates this problem in our second scenario.</p><p>We have some storage information saved in a Microsoft Access database named <code>electricity_storage.accdb</code></p><p>Before loading in the data, remember we have both inputs and outputs for our original scenario currently in table format in our connection.</p><pre><code class="language-julia hljs">
TIO.show_tables(connection)


tables = DBInterface.execute(connection, &quot;&quot;&quot;
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema = &#39;main&#39;
&quot;&quot;&quot;) |&gt; DataFrame

println(tables)</code></pre><p>Depending on how extensively you would like to compare the results from both scenarios you could do a couple of things. Firstly, you can make a copy of the dataframes currently stored in our connection and load them in later to compare with the second scenario results. In our case, since we are only interested in comparing electricity prices between the two scenarios, we will rename the price results for our first scenario stored as dual variables in <code>cons_balance_consumer</code> so that it does not get overwritten in our next model run. This allows us to compare the price results later.</p><p>The first step in establishing the new scenario is to load in the Access database and see what we are working with.</p><pre><code class="language-julia hljs">
db_file = raw&quot;my-awesome-energy-system/tutorial-7/electricity_storage.accdb&quot;
conn = ODBC.Connection(&quot;Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=$db_file;&quot;)

electricity_storage = DBInterface.execute(conn, &quot;SELECT * FROM Storage&quot;) |&gt; DataFrame

# Write the dataframe into DuckDB as a permanent table
DuckDB.register_data_frame(connection, electricity_storage, &quot;electricity_storage_tmp&quot;)
DBInterface.execute(connection, &quot;CREATE OR REPLACE TABLE electricity_storage AS SELECT * FROM electricity_storage_tmp&quot;)

# Note that our original &#39;connection&#39; still exists, and we can see the new electricity_storage dataframe like so:
TIO.get_table(connection, &quot;electricity_storage&quot;)
</code></pre><p>As you can see, we have some installed capacity figures for battery and hydro pumped storage options. We can now include them in the input files through some processing.</p><pre><code class="language-julia hljs">
# Manually add the new rows (one for battery storage, one of pumped hydro storage) into the dataframes in our DuckDB file
# We have learned in tutorial 5 that our new storage technologies (battery and pumped hydro) should be defined in both asset as well as flow input data

TIO.get_table(connection, &quot;asset&quot;)

DBInterface.execute(connection, &quot;&quot;&quot;
    INSERT INTO asset (asset, type, capacity, investment_method, investment_integer, technical_lifetime, discount_rate, capacity_storage_energy)
    VALUES (&#39;battery&#39;, &#39;storage&#39;, 40000.0, &#39;simple&#39;, false, 15, 0.05, 160000)
&quot;&quot;&quot;)

DBInterface.execute(connection, &quot;&quot;&quot;
    INSERT INTO asset (asset, type, capacity, investment_method, investment_integer, technical_lifetime, discount_rate, capacity_storage_energy)
    VALUES (&#39;pumped_hydro&#39;, &#39;storage&#39;, 50000.0, &#39;simple&#39;, false, 15, 0.05, 500000)
&quot;&quot;&quot;)

# Check new entries
TIO.get_table(connection, &quot;asset&quot;)


# Now repeat for other required input tables. To make it easier we can use push! to change the dataframes first and then update the tables in our connection

push!(asset_both, (&quot;battery&quot;, 2050, 2050, 1.0))
push!(asset_both, (&quot;pumped_hydro&quot;, 2050, 2050, 1.0))
push!(asset_commission, (&quot;battery&quot;, 2050, 100,missing,5.0))
push!(asset_commission, (&quot;pumped_hydro&quot;, 2050, 100,missing,5.0))
push!(asset_milestone, (&quot;battery&quot;, 2050, &quot;false&quot;, 0.0, 0))
push!(asset_milestone, (&quot;pumped_hydro&quot;, 2050, &quot;false&quot;, 0.0, 0))

#assets to storage techs
push!(flow_commission, (&quot;solar&quot;, &quot;battery&quot;, 2050, 0.92))
push!(flow_commission, (&quot;wind&quot;, &quot;battery&quot;, 2050, 0.92))
push!(flow_commission, (&quot;ccgt_ccs&quot;, &quot;battery&quot;, 2050, 0.92))
push!(flow_commission, (&quot;solar&quot;, &quot;pumped_hydro&quot;, 2050, 0.92))
push!(flow_commission, (&quot;wind&quot;, &quot;pumped_hydro&quot;, 2050, 0.92))
push!(flow_commission, (&quot;ccgt_ccs&quot;, &quot;pumped_hydro&quot;, 2050, 0.92))

#storage techs to demand
push!(flow_commission, (&quot;battery&quot;, &quot;e_demand&quot;, 2050, 0.92))
push!(flow_commission, (&quot;pumped_hydro&quot;, &quot;e_demand&quot;, 2050, 0.7))

#repeat
push!(flow_milestone, (&quot;solar&quot;, &quot;battery&quot;, 2050, 0))
push!(flow_milestone, (&quot;wind&quot;, &quot;battery&quot;, 2050, 0))
push!(flow_milestone, (&quot;ccgt_ccs&quot;, &quot;battery&quot;, 2050, 0))
push!(flow_milestone, (&quot;solar&quot;, &quot;pumped_hydro&quot;, 2050, 0))
push!(flow_milestone, (&quot;wind&quot;, &quot;pumped_hydro&quot;, 2050, 0))
push!(flow_milestone, (&quot;ccgt_ccs&quot;, &quot;pumped_hydro&quot;, 2050, 0))

push!(flow_milestone, (&quot;battery&quot;, &quot;e_demand&quot;, 2050, 0))
push!(flow_milestone, (&quot;pumped_hydro&quot;, &quot;e_demand&quot;, 2050, 0))

#repeat
push!(flow, (&quot;solar&quot;, &quot;battery&quot;, 10, 0.02))
push!(flow, (&quot;wind&quot;, &quot;battery&quot;, 10, 0.02))
push!(flow, (&quot;ccgt_ccs&quot;, &quot;battery&quot;, 10, 0.02))
push!(flow, (&quot;solar&quot;, &quot;pumped_hydro&quot;, 10, 0.02))
push!(flow, (&quot;wind&quot;, &quot;pumped_hydro&quot;, 10, 0.02))
push!(flow, (&quot;ccgt_ccs&quot;, &quot;pumped_hydro&quot;, 10, 0.02))

push!(flow, (&quot;battery&quot;, &quot;e_demand&quot;, 10, 0.02))
push!(flow, (&quot;pumped_hydro&quot;, &quot;e_demand&quot;, 10, 0.02))

# Remember that this only updates our dataframes and NOT our duckDB file. Run the next lines to update the duckDB file:
# We use a loop to keep the code more concise, but you could also manually do it like this:
# Example for asset_both
#DuckDB.register_data_frame(connection, asset_both, &quot;asset_both_tmp&quot;)
#DBInterface.execute(connection, &quot;CREATE OR REPLACE TABLE asset_both AS SELECT * FROM asset_both_tmp&quot;)
#DBInterface.execute(connection, &quot;DROP VIEW IF EXISTS asset_both_tmp&quot;)

tables_to_update = [
    (&quot;asset_both&quot;, asset_both),
    (&quot;asset_commission&quot;, asset_commission),
    (&quot;asset_milestone&quot;, asset_milestone),
    (&quot;flow_commission&quot;, flow_commission),
    (&quot;flow_milestone&quot;, flow_milestone),
    (&quot;flow&quot;, flow)
]

for (tbl_name, df) in tables_to_update
    tmp_name = tbl_name * &quot;_tmp&quot;
    DuckDB.register_data_frame(connection, df, tmp_name)
    DBInterface.execute(connection, &quot;CREATE OR REPLACE TABLE $tbl_name AS SELECT * FROM $tmp_name&quot;)
    DBInterface.execute(connection, &quot;DROP VIEW IF EXISTS $tmp_name&quot;)
end
</code></pre><h2 id="7.-Analyze-differences-between-the-two-scenarios"><a class="docs-heading-anchor" href="#7.-Analyze-differences-between-the-two-scenarios">7. Analyze differences between the two scenarios</a><a id="7.-Analyze-differences-between-the-two-scenarios-1"></a><a class="docs-heading-anchor-permalink" href="#7.-Analyze-differences-between-the-two-scenarios" title="Permalink"></a></h2><p>Now that we have updated input data in our DuckDB connection, we can run the model again!</p><p>Before we run it, we will store the results we generated in our first run under a separate name so they will not be overwritten. This will allow us to compare the two runs later.</p><pre><code class="language-julia hljs">
DBInterface.execute(connection, &quot;ALTER TABLE cons_balance_consumer RENAME TO cons_balance_consumer_nostorage&quot;)
</code></pre><p>Now that we have stored the prices from the first run, we can continue running the model with the updated input data.</p><pre><code class="language-julia hljs">
TEM.populate_with_defaults!(connection)

energy_problem =
    TEM.run_scenario(connection; output_folder=output_dir)
</code></pre><p>What do you notice about the results? What happened to the objective value?</p><p>Let&#39;s plot the prices of both scenarios next to each other</p><pre><code class="language-julia hljs">
balance_nostorage = TIO.get_table(connection, &quot;cons_balance_consumer_nostorage&quot;)
balance = TIO.get_table(connection, &quot;cons_balance_consumer&quot;)

# Filter for the asset / year / rep_period
asset = &quot;e_demand&quot;
year = 2050
rep_period = 1

filtered_nostorage = filter(row -&gt; row.asset == asset &amp;&amp;
                                 row.year == year &amp;&amp;
                                 row.rep_period == rep_period,
                             balance_nostorage)

filtered_storage = filter(row -&gt; row.asset == asset &amp;&amp;
                                row.year == year &amp;&amp;
                                row.rep_period == rep_period,
                          balance)

# Plot both series
plot(
    filtered_nostorage.time_block_start, filtered_nostorage.dual_balance_consumer,
    label=&quot;No Storage&quot;,
    xlabel=&quot;Hour&quot;,
    ylabel=&quot;[Euro/MWh]&quot;,
    ylims=(0,200),
    xlims=(0, 768),
    dpi=600
)

# Add second series
plot!(filtered_storage.time_block_start, filtered_storage.dual_balance_consumer,
      label=&quot;With Storage&quot;)
</code></pre><p>What do you notice? What happened to the objective value of the model outcome?</p><p>It can be worthwhile to consider the price duration curve, in this plot the prices (this time of the whole year) are ranked from high to low in the two model runs.</p><pre><code class="language-julia hljs">
# Filter for asset/year
asset = &quot;e_demand&quot;
year = 2050

filtered_nostorage = filter(row -&gt; row.asset == asset &amp;&amp; row.year == year, balance_nostorage)
filtered_storage    = filter(row -&gt; row.asset == asset &amp;&amp; row.year == year, balance)

# Sort prices descending
p_no  = sort(filtered_nostorage.dual_balance_consumer; rev=true)
p_yes = sort(filtered_storage.dual_balance_consumer; rev=true)

# cumulative hours
x_no  = 1:length(p_no)
x_yes = 1:length(p_yes)

# Plot ranked prices
plot(
    x_no, p_no,
    seriestype = :steppost,
    label      = &quot;No Storage&quot;,
    xlabel     = &quot;Hour (ranked)&quot;,
    ylabel     = &quot;Price (euro/MWh)&quot;,
    xlims      = (0, 8760),
    dpi        = 600,
    legend     = :right
)

plot!(
    x_yes, p_yes,
    seriestype = :steppost,
    label      = &quot;With Storage&quot;
)
</code></pre><p>Notice the dramatic decrease of the electricity price as shown in the plot.</p><h2 id="8.-Further-analysis"><a class="docs-heading-anchor" href="#8.-Further-analysis">8. Further analysis</a><a id="8.-Further-analysis-1"></a><a class="docs-heading-anchor-permalink" href="#8.-Further-analysis" title="Permalink"></a></h2><p>Feel free to further tweak the input data and observe what happens to the system. You can directly tweak data in the connection by running queries like so (this is an example):</p><pre><code class="language-julia hljs">
DBInterface.execute(connection, &quot;&quot;&quot;
    UPDATE asset
    SET capacity = 10000.0
    WHERE asset = &#39;ccgt_ccs&#39;
&quot;&quot;&quot;)

# Remember you can have a look at the state of the tables in the connection like so (example):

TIO.get_table(connection, &quot;asset&quot;)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../19-workflow-obz/">« Data-Handling Workflow (Example)</a><a class="docs-footer-nextpage" href="../31-rolling-horizon/">Rolling Horizon »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Tuesday 24 February 2026 08:57">Tuesday 24 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
