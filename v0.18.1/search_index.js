var documenterSearchIndex = {"docs":
[{"location":"90-contributing/91-developer/#developer","page":"Developer Documentation","title":"Developer Documentation","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Welcome to TulipaEnergyModel.jl developer documentation. Here is how you can contribute to our Julia-based toolkit for modeling and optimization of electric energy systems.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"This may seem like a lot, but that's because we walk you through step-by-step. If you follow these steps, you'll contributing in no time!","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Pages = [\"91-developer.md\"]\nDepth = [2, 3]","category":"page"},{"location":"90-contributing/91-developer/#First-Time-Setup","page":"Developer Documentation","title":"First-Time Setup","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Before you can start contributing, please read our Contributing Guidelines.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Also make sure that you have installed the required software, and that it is properly configured. You only need to do this once.","category":"page"},{"location":"90-contributing/91-developer/#Installing-Software","page":"Developer Documentation","title":"Installing Software","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To contribute to TulipaEnergyModel.jl, you need the following:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Julia programming language.\nGit for version control.\nVSCode or any other editor. For VSCode, we recommend to install a few extensions. You can do it by pressing Ctrl + Shift + X (or ⇧ + ⌘ + X on MacOS) and searching by the extension name:\nJulia for Visual Studio Code\nGit Graph\nEditorConfig for consistent code formatting. In VSCode, it is available as an extension.\npre-commit to run the linters and formatters.\nTo install pre-commit, you will first need Python with pip (included by default in recent Python versions).\nYou can install pre-commit globally using\npip install --user pre-commit\nIf you prefer to create a local environment with it, do the following:\npython -m venv env\n\n# Windows\nsource env/Scripts/activate # in bash\nenv/Scripts/Activate.ps1 # in powershell\n\n# Linux or macOS\n. env/bin/activate\n\npip install --upgrade pip setuptools pre-commit\nFor every subsequent use, you don't have to install, just activate the environment:\nsource env/Scripts/activate # in bash\nenv/Scripts/Activate.ps1 # in powershell\nJuliaFormatter.jl for code formatting.\nTo install it, open a Julia REPL, for example, by typing in the command line:\njulia\nNote: julia must be part of your environment variables to call it from the command line.\nThen press ] to enter package mode and enter the following:\npkg> activate\npkg> add JuliaFormatter@v1 # NOTE: We currently have to manually force v1 (see issue #1233)\nIn VSCode, you can activate \"Format on Save\" for JuliaFormatter:\nOpen VSCode Settings (Ctrl + ,)\nIn \"Search Settings\", type \"Format on Save\" and tick the first result:\n(Image: Screenshot of Format on Save option)\nWarning: Do not use the JuliaFormatter VSCode extension because it may conflict with the formatting rules currently used in this codebase.\nLocalCoverage for coverage testing. You can install it the same way you installed JuliaFormatter, that is, by opening Julia REPL in the package mode and typing:\npkg> activate\npkg> add LocalCoverage","category":"page"},{"location":"90-contributing/91-developer/#Forking-the-Repository","page":"Developer Documentation","title":"Forking the Repository","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Any changes should be done in a fork. You can fork this repository directly on GitHub:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"(Image: Screenshot of Fork button on GitHub)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"After that, clone your fork. The fork should ideally be cloned to a folder that is not affected by any cloud, to prevent LiveServer accessing and overwriting your folder. Finally, add this repository as upstream:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"cd path/to/folder #optionally, cd to a local folder\ngit clone https://github.com/your-name/TulipaEnergyModel.jl                   # use the fork URL\ngit remote add upstream https://github.com/TulipaEnergy/TulipaEnergyModel.jl  # use the original repository URL","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Check that your origin and upstream are correct:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git remote -v","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"You should see something similar to: (Image: Screenshot of remote names, showing origin and upstream)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If your names are wrong, use this command (with the relevant names) to correct it:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git remote set-url [name] [url]","category":"page"},{"location":"90-contributing/91-developer/#Configuring-Git","page":"Developer Documentation","title":"Configuring Git","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Because operating systems use different line endings for text files, you need to configure Git to ensure code consistency across different platforms. You can do this with the following commands:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"cd /path/to/TulipaEnergyModel.jl\ngit config --unset core.autocrlf         # disable autocrlf in the EnergyModel repo\ngit config --global core.autocrlf false  # explicitly disable autocrlf globally\ngit config --global --unset core.eol     # disable explicit file-ending globally\ngit config core.eol lf                   # set Linux style file-endings in EnergyModel","category":"page"},{"location":"90-contributing/91-developer/#Activating-and-Testing-the-Package","page":"Developer Documentation","title":"Activating and Testing the Package","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Start Julia REPL either via the command line or in the editor.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In the terminal, do:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"cd /path/to/TulipaEnergyModel.jl  # change the working directory to the repo directory if needed\njulia                             # start Julia REPL","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In VSCode, first open your cloned fork as a new project. Then open the command palette with Ctrl + Shift + P (or ⇧ + ⌘ + P on MacOS) and use the command called Julia: Start REPL.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In a Julia REPL, enter the package mode by pressing ].","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In the package mode, first activate and instantiate the project, then run the tests to ensure that everything is working as expected:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"pkg> activate .   # activate the project\npkg> instantiate  # instantiate to install the required packages\npkg> test         # run the tests (uses TestItemRunner.jl)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: The test suite uses TestItemRunner.jl for better test organization and granular execution. You can also run specific test categories using tags or individual test files as described in the testing section below.","category":"page"},{"location":"90-contributing/91-developer/#Configuring-Linting-and-Formatting","page":"Developer Documentation","title":"Configuring Linting and Formatting","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"With pre-commit installed, activate it as a pre-commit hook:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"pre-commit install","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To run the linting and formatting manually, enter the command below:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"pre-commit run -a","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Do it once now to make sure that everything works as expected.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Now, you can only commit if all the pre-commit tests pass.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: On subsequent occasions when you need to run pre-commit in a new shell, you will need to activate the Python virtual environment. If so, do the following:. env/bin/activate  # for Windows the command is: . env/Scripts/activate\npre-commit run -a","category":"page"},{"location":"90-contributing/91-developer/#Code-format-and-guidelines","page":"Developer Documentation","title":"Code format and guidelines","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"This section will list the guidelines for code formatting not enforced by JuliaFormatter. We will try to follow these during development and reviews.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Naming\nCamelCase for classes and modules\nsnake_case for functions and variables\nkebab-case for file names and documentation reference tags\nUse using instead of import, in the following way:\nDon't use pure using Package, always list all necessary objects with using Package: A, B, C.\nList obvious objects, e.g., using JuMP: @variable, since @variable is obviously from JuMP in this context.\nFor other objects inside Package, use using Package: Package and explicitly call Package.A to use it, e.g., JuMP.direct_model.\nList all using in <src/TulipaEnergyModel.jl>.\nExplicitly state what a function will return; if returning nothing, simply use return.","category":"page"},{"location":"90-contributing/91-developer/#Contributing-Workflow","page":"Developer Documentation","title":"Contributing Workflow","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When the software is installed and configured, and you have forked the TulipaEnergyModel.jl repository, you can start contributing to it.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"We use the following workflow for all contributions:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Make sure that your fork is up to date\nCreate a new branch\nImplement the changes\nRun the tests\nRun the linter\nCommit the changes\nRepeat steps 3-6 until all necessary changes are done\nMake sure that your fork is still up to date\nCreate a pull request","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Below you can find detailed instructions for each step.","category":"page"},{"location":"90-contributing/91-developer/#1.-Make-Sure-That-Your-Fork-Is-Up-to-Date","page":"Developer Documentation","title":"1. Make Sure That Your Fork Is Up to Date","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Fetch from org remote, fast-forward your local main:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git switch main\ngit fetch --all --prune\ngit merge --ff-only upstream/main","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Warning: If you have a conflict on your main, it will appear now. You can delete your old main branch usinggit reset --hard upstream/main","category":"page"},{"location":"90-contributing/91-developer/#2.-Create-a-New-Branch","page":"Developer Documentation","title":"2. Create a New Branch","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Create a branch to address the issue:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git switch -c <branch_name>","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If there is an associated issue, add the issue number to the branch name, for example, 123-short-description for issue #123.\nIf there is no associated issue and the changes are small, add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update.\nIf the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: Always branch from main, i.e., the main branch of your own fork.","category":"page"},{"location":"90-contributing/91-developer/#3.-Implement-the-Changes","page":"Developer Documentation","title":"3. Implement the Changes","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Implement your changes to address the issue associated with the branch.","category":"page"},{"location":"90-contributing/91-developer/#4.-Run-the-Tests","page":"Developer Documentation","title":"4. Run the Tests","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"TulipaEnergyModel.jl uses TestItemRunner.jl for testing, which provides granular test execution and better development experience.","category":"page"},{"location":"90-contributing/91-developer/#Running-All-Tests","page":"Developer Documentation","title":"Running All Tests","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In Julia:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"TulipaEnergyModel> test","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Or, using the CLI version:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"julia --project=test test/runtests.jl --verbose","category":"page"},{"location":"90-contributing/91-developer/#Running-Tests-with-filters","page":"Developer Documentation","title":"Running Tests with filters","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"The test suite uses tags for efficient test filtering during development. Here are some tags:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":":unit - Single component or function tests\n:integration - End-to-end tests\n:validation - Tests verifying expected values, behavior, or mathematical correctness\n:fast - Quick tests suitable for frequent execution\n:slow - Resource-intensive tests requiring significant time or memory","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Check test/runtests.jl for a complete list or run with the --list-tags option.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Examples of running specific test categories:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"# Run only fast unit tests\njulia --project=test test/runtests.jl --tags unit,fast\n\n# Run only files that match the name:\njulia --project=test test/runtests.jl --file test-model.jl","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"And it's also possible to run a specific @testitem. If you are on VSCode with the Julia extension installed, you will see a \"play\" button on the left side of the @testitem. Otherwise, if you know (part of) the name of the test, you can run it with:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"julia --project=test test/runtests.jl --name \"Some test name\"","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Use --help to see the full help.","category":"page"},{"location":"90-contributing/91-developer/#Test-Coverage","page":"Developer Documentation","title":"Test Coverage","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To run the tests with code coverage, you can use the LocalCoverage package:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"julia> using LocalCoverage\n# ]\npkg> activate .\n# <backspace>\njulia> cov = generate_coverage()","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"This will run the tests, track line coverage and print a report table as output. Note that we want to maintain 100% test coverage. If any file does not show 100% coverage, please add tests to cover the missing lines.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If you are having trouble reaching 100% test coverage, you can set your pull request to 'draft' status and ask for help.","category":"page"},{"location":"90-contributing/91-developer/#Writing-New-Tests","page":"Developer Documentation","title":"Writing New Tests","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When adding new tests, use the @testitem macro with appropriate setup and tags:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"@testitem \"Test description\" setup = [CommonSetup] tags = [:unit, :fast] begin\n    # Test code here\n    @test actual_result == expected_result\nend","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Choose appropriate tags based on your test characteristics. If you need to add a new tag, check the TAGS_DATA dictionary on the test/runtests.jl file.","category":"page"},{"location":"90-contributing/91-developer/#5.-Run-the-Linter","page":"Developer Documentation","title":"5. Run the Linter","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In the bash/git bash terminal, run pre-commit:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":". env/bin/activate # if necessary (for Windows the command is: . env/Scripts/activate)\npre-commit run -a","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If any of the checks failed, find in the pre-commit log what the issues are and fix them. Then, add them again (git add), rerun the tests & linter, and commit.","category":"page"},{"location":"90-contributing/91-developer/#6.-Commit-the-Changes","page":"Developer Documentation","title":"6. Commit the Changes","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When the test are passing, commit the changes and push them to the remote repository. Use:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git commit -am \"A short but descriptive commit message\" # Equivalent to: git commit -a -m \"commit msg\"\ngit push -u origin <branch_name>","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When writing the commit message:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"use imperative, present tense (Add feature, Fix bug);\nhave informative titles;\nif necessary, add a body with details.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: Try to create \"atomic git commits\". Read The Utopic Git History to learn more.","category":"page"},{"location":"90-contributing/91-developer/#7.-Make-Sure-That-Your-Fork-Is-Still-Up-to-Date","page":"Developer Documentation","title":"7. Make Sure That Your Fork Is Still Up to Date","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If necessary, fetch any main updates from upstream and rebase your branch into origin/main. For example, do this if it took some time to resolve the issue you have been working on. If you don't resolve conflicts locally, you will get conflicts in your pull request.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Do the following steps:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git switch main                  # switch to the main branch\ngit fetch --all --prune          # fetch the updates\ngit merge --ff-only upstream/main  # merge as a fast-forward\ngit switch <branch_name>         # switch back to the issue branch\ngit rebase main <branch_name>    # rebase it","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If it says that you have conflicts, resolve them by opening the file(s) and editing them until the code looks correct to you. You can check the changes with:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git diff             # Check that changes are correct.\ngit add <file_name>\ngit diff --staged    # Another way to check changes, i.e., what you will see in the pull request.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Once the conflicts are resolved, commit and push.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"git status # Another way to show that all conflicts are fixed.\ngit rebase --continue\ngit push --force origin <branch_name>","category":"page"},{"location":"90-contributing/91-developer/#8.-Create-a-Pull-Request","page":"Developer Documentation","title":"8. Create a Pull Request","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When there are no more conflicts and all the test are passing, create a pull request to merge your remote branch into the org main. You can do this on GitHub by opening the branch in your fork and clicking \"Compare & pull request\".","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"(Image: Screenshot of Compare & pull request button on GitHub)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Fill in the pull request details:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Describe the changes.\nList the issue(s) that this pull request closes.\nFill in the collaboration confirmation.\n(Optional) Choose a reviewer.\nWhen all of the information is filled in, click \"Create pull request\".","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"(Image: Screenshot of the pull request information)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"You pull request will appear in the list of pull requests in the TulipaEnergyModel.jl repository, where you can track the review process.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Sometimes reviewers request changes. After pushing any changes, the pull request will be automatically updated. Do not forget to re-request a review.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Once your reviewer approves the pull request, you need to merge it with the main branch using \"Squash and Merge\". You can also delete the branch that originated the pull request by clicking the button that appears after the merge. For branches that were pushed to the main repo, it is recommended that you do so.","category":"page"},{"location":"90-contributing/91-developer/#Building-the-Documentation-Locally","page":"Developer Documentation","title":"Building the Documentation Locally","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Following the latest suggestions, we recommend using LiveServer to build the documentation.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: Ensure you have the package Revise installed in your global environment before running servedocs.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Here is how you do it:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Run julia --project=docs in the package root to open Julia in the environment of the docs.\nIf this is the first time building the docs\nPress ] to enter pkg mode\nRun pkg> dev . to use the development version of your package\nPress backspace to leave pkg mode\nRun julia> using LiveServer\nRun julia> servedocs(launch_browser=true)","category":"page"},{"location":"90-contributing/91-developer/#Performance-Considerations","page":"Developer Documentation","title":"Performance Considerations","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If you updated something that might impact the performance of the package, you can run the Benchmark.yml workflow from your pull request. To do that, add the tag benchmark in the pull request. This will trigger the workflow and post the results as a comment in you pull request.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Warning: This requires that your branch was pushed to the main repo. If you have created a pull request from a fork, the Benchmark.yml workflow does not work. Instead, close your pull request, push your branch to the main repo, and open a new pull request.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If you want to manually run the benchmarks, you can do the following:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Navigate to the benchmark folder\nRun julia --project=.\nEnter pkg mode by pressing ]\nRun dev .. to add the development version of TulipaEnergyModel\nNow run\ninclude(\"benchmarks.jl\")\ntune!(SUITE)\nresults = run(SUITE, verbose=true)","category":"page"},{"location":"90-contributing/91-developer/#Manually-running-the-benchmark-across-versions","page":"Developer Documentation","title":"Manually running the benchmark across versions","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"We use the package AirspeedVelocity.jl to run the benchmarks in the CI, but it can also be used to compare explicitly named versions manually.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Run the following to install AirspeedVelocity's commands to your Julia bin folder (~/.julia/bin on MacOS and Linux). On Windows, if you are using the default Julia installation, search for C:/Users/ then the folder of your Windows user and then .julia/bin\njulia -e 'using Pkg; Pkg.activate(temp=true); Pkg.add(\"AirspeedVelocity\")'\nCheck that benchpkg was installed:\nbenchpkg --version\nIf if can't be found, then it is possible that your Julia bin folder is not in the PATH. After fixing this, try again.\nThen, run benchpkg with --rev to list the versions to be tested and --bench-on to indicate with script to use (if necessary). For instance:\nbenchpkg TulipaEnergyModel --rev=v0.12.0,main --bench-on=main\nAfter all logging, the output should look like\n|                                      | v0.12.0       | main            | v0.12.0/main |\n|:-------------------------------------|:-------------:|:---------------:|:------------:|\n| energy_problem/create_model          | 25.1 ± 1.2 s  | 19.7 ± 1.1 s    | 1.27         |\n| energy_problem/input_and_constructor | 11.2 ± 0.15 s | 8.57 ± 0.064 s  | 1.3          |\n| time_to_load                         | 1.7 ± 0.022 s | 1.73 ± 0.0055 s | 0.979        |\nBe aware that the versions passed in rev must be compatible to the benchmark defined at bench-on. So, for instance, testing v0.10.4 above would fail, before the versions are too different.\nIf you are working on a local version of TulipaEnergyModel, it is possible to test the local modifications. First, make sure that you are at the root of the TulipaEnergyModel repo, and then issue\nbenchpkg --rev=<other>,dirty\nThe dirty value refers to the current local modifications. The <other> values can be tags or branches to compare.\nWhen this is done, you can print just the table afterwards using benchmarktable:\nbenchpkgtable TulipaEnergyModel --rev=v0.12.0,main\n...\n|                                      | v0.12.0       | main            | v0.12.0/main |\n|:-------------------------------------|:-------------:|:---------------:|:------------:|\n| energy_problem/create_model          | 25.1 ± 1.2 s  | 19.7 ± 1.1 s    | 1.27         |\n| energy_problem/input_and_constructor | 11.2 ± 0.15 s | 8.57 ± 0.064 s  | 1.3          |\n| time_to_load                         | 1.7 ± 0.022 s | 1.73 ± 0.0055 s | 0.979        |\nIt is also possible to generate a plot, using benchpkgplot:\nbenchpkgplot TulipaEnergyModel --rev=v0.12.0,main --format=jpeg\nDifferent formats can be used. Here is the output:\n(Image: Plot of benchmark made with benchpkgplot)","category":"page"},{"location":"90-contributing/91-developer/#Profiling","page":"Developer Documentation","title":"Profiling","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To profile the code in a more manual way, here are some tips:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Wrap your code into functions.\nCall the function once to precompile it. This must be done after every change to the function.\nPrefix the function call with @time. This is the most basic timing, part of Julia.\nPrefix the function call with @btime. This is part of the BenchmarkTools package, which you might need to install. @btime will evaluate the function a few times to give a better estimate.\nPrefix the function call with @benchmark. Also part of BenchmarkTools. This will produce a nice histogram of the times and give more information. @btime and @benchmark do the same thing in the background.\nCall @profview. This needs to be done in VSCode, or using the ProfileView package. This will create a flame graph, where each function call is a block. The size of the block is proportional to the aggregate time it takes to run. The blocks below a block are functions called inside the function above.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"See the file <benchmark/profiling.jl> for an example of profiling code.","category":"page"},{"location":"90-contributing/91-developer/#Testing-the-generate-MPS-files","page":"Developer Documentation","title":"Testing the generate MPS files","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To make sure that unintended changes don't change the model, we have a workflow that automatically compares the generated MPS files. Here is an explanation of how it works, and how to run the same comparison locally.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Before we start, notice that there are files in benchmark/model-mps-folder with the .mps files for each of the test inputs. There are the existing MPS files.","category":"page"},{"location":"90-contributing/91-developer/#Updating-the-MPS-files","page":"Developer Documentation","title":"Updating the MPS files","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To update the MPS files, you can simple run a script from the root of TulipaEnergyModel.jl:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"julia --project=. utils/scripts/model-mps-update.jl","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If you know that your changes will modify the model, then you need to update the MPS files as just showed.","category":"page"},{"location":"90-contributing/91-developer/#Comparison-of-MPS-files-via-script","page":"Developer Documentation","title":"Comparison of MPS files via script","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"One quick way to check the difference between the existing MPS files and the new ones is just to run the update, and check the git diff. However, if you don't want to update, or just want a summary of the changes, you can run the script:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"julia --project=. utils/scripts/model-mps-compare.jl","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"warning: Warning\nThis comparison uses the local version of benchmark/model-mps-folder. So, if you run the update script, there will be no changes to be shown.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"The generated log will look something liek this:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"┌ Info: New comparison\n│ Comparing files\n│ - <path>/<file>.mps\n└ - <temp-path>/<file>.mps\n[ Info: Create mps for <path> in <temp-path>\n[ Info: No difference found\n┌ Info: New comparison\n│ Comparing files\n│ - <path>/<file>.mps\n└ - <temp-path>/<file>.mps\n[ Info: Create mps for <path> in <temp-path>\n┌ Error: Line 1272\"\n│ ..Existing: '    assets_investment[2030,ocgt] max_output_flows_limit[ocgt,2030,1,18:18] -100'\n│ .......New: '    assets_investment[2030,ocgt] max_output_flows_limit[ocgt,2030,1,18:18] -200'\n└ @ Main <path>/utils/scripts/model-mps-compare.jl:75","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"There are 2 cases:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"The first case starts at the beginning of the log and ends in \"No difference found\". There was nothing to show for that file.\nThe second case has \"errors\", i.e., differences between the existing and new MPS files. Here is what to expect from the error lines:\nError: Line ####: The line number of the MPS file (which you can manually inspect).\n..Existing: Shows the existing line.\n.......New: Shows the new line.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"If the environment variable TULIPA_COMPARE_MPS_LOGFILE is defined and is a path to a file, then the log will be written to a file instead of printed. This is mostly relevant for the GitHub workflow.","category":"page"},{"location":"90-contributing/91-developer/#GitHub-Workflow","page":"Developer Documentation","title":"GitHub Workflow","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When creating a pull request, the workflow CompareMPS.yml will run the comparison above and write a PR comment to indicate whether the files are the same or not. If the files are not the same, then the workflow fails, and there are two ways in which the workflow can fail:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Expected failure: If you are making a change to the model, then the MPS file will be different. Then you should 1.1. Verify that the changes are only what you expected to see (i.e., use the MPS difference to debug possible issues). 1.2. Run the update script listed above to fix the comparison (i.e., the new MPS becomes the existing MPS). 1.3. Commit and push your modifications and wait for the comparison to run again.\nUnexpected failure: If you made modifications that were not supposed to change the model, then you need to investigate what happened. Use the MPS difference to debug what you have done. There is no easy fix for this. If you think there are bugs in the comparison script, discuss with your PR reviewer and open an issue if necessary.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"warning: Warning\nThe comparison workflow only writes PR comments if the branch is made from within TulipaEnergyModel (i.e., not from forks). To see the log online in that case, you have to open the GitHub action log, or run the comparison locally, as explained in the previous section.","category":"page"},{"location":"90-contributing/91-developer/#Releasing-a-New-Version","page":"Developer Documentation","title":"Releasing a New Version","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"When publishing a new version of the model to the Julia Registry, follow this procedure:","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"note: Note\nTo be able to register, you need to be a member of the organisation TulipaEnergy and set your visibility to public: (Image: Screenshot of public members of TulipaEnergy on GitHub)","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Click on the Project.toml file on GitHub.\nEdit the file and change the version number according to semantic versioning: Major.Minor.Patch\n(Image: Screenshot of editing Project.toml on GitHub)\nCommit the changes in a new branch and open a pull request. Change the commit message according to the version number.\n(Image: Screenshot of PR with commit message \"Release 0.6.1\")\nCreate the pull request and squash & merge it after the review and testing process. Delete the branch after the squash and merge.\n(Image: Screenshot of full PR template on GitHub)\nGo to the main page of repo and click in the commit. (Image: Screenshot of how to access commit on GitHub)\nAdd the following comment to the commit: @JuliaRegistrator register\n(Image: Screenshot of calling JuliaRegistrator in commit comments)\nThe bot should start the registration process.\n(Image: Screenshot of JuliaRegistrator bot message)\nAfter approval, the bot will take care of the PR at the Julia Registry and automatically create the release for the new version.\n(Image: Screenshot of new version on registry)\nThank you for helping make frequent releases!","category":"page"},{"location":"90-contributing/91-developer/#Adding-a-Package-to-the-TulipaEnergy-Organisation","page":"Developer Documentation","title":"Adding a Package to the TulipaEnergy Organisation","text":"","category":"section"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"To get started creating a new (Julia) package that will live in the TulipaEnergy organisation and interact with TulipaEnergyModel, please start by using BestieTemplate.jl, and follow the steps in their Full guide for a new package.","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"This will set up the majority of automation and workflows we use and make your repo consistent with the others!","category":"page"},{"location":"90-contributing/91-developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Note: TulipaEnergyModel.jl is the core repo of the organisation. The Discussions are focused there and in some cases the documentation of other packages should forward to the TulipaEnergyModel docs to avoid duplicate or scattered information.","category":"page"},{"location":"10-tutorials/16-storage/#Tutorial-5:-Seasonal-and-Non-seasonal-Storage","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"","category":"section"},{"location":"10-tutorials/16-storage/#Introduction","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Introduction","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Tulipa has two types of storage representations:","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"seasonal - inter-temporal constraints over the clustered analysis period (i.e. year)\nnon-seasonal - intra-temporal constraints inside the representative periods","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Here is the concept documentation for more details: Storage Modelling","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"The data we will be working with is once again located in the my-awesome-energy-system folder, this time under tutorial 5","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Let's have a look at their input parameters...","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"For instance, what are the storage capacities? Efficiencies? Initial storage levels? Any other parameters?","category":"page"},{"location":"10-tutorials/16-storage/#Previously-in-the-TLC","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Previously in the TLC","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Let's start the workflow in Lesson 4, but using our new storage data (and a temporary hack - sorry, a fix is coming soon):","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"using Pkg\nPkg.activate(\".\")\n# Pkg.add(\"TulipaEnergyModel\")\n# Pkg.add(\"TulipaIO\")\n# Pkg.add(\"TulipaClustering\")\n# Pkg.add(\"DuckDB\")\n# Pkg.add(\"DataFrames\")\n# Pkg.add(\"Plots\")\n# Pkg.add(\"Distances\")\n\nPkg.instantiate()\n\nimport TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nimport TulipaClustering as TC\nusing DuckDB\nusing DataFrames\nusing Plots\nusing Distances\n\nconnection = DBInterface.connect(DuckDB.DB)\n\ninput_dir = \"my-awesome-energy-system/tutorial-5\"\noutput_dir = \"my-awesome-energy-system/tutorial-5/results\"\n\nTIO.read_csv_folder(connection, input_dir)\n\nperiod_duration = 24\nprofiles_df = TIO.get_table(connection, \"profiles_periods\")\nTC.combine_periods!(profiles_df)\nTC.split_into_periods!(profiles_df; period_duration)\n\nnum_rep_periods = 10\nmethod = :convex_hull  # :k_means, :convex_hull, :convex_hull_with_null, :conical_hull\ndistance = CosineDist()  # CosineDist()\n\nclustering_result = TC.find_representative_periods(profiles_df, num_rep_periods; method, distance)\n\nweight_type = :convex  # :convex, :conical, :conical_bounded\ntol = 1e-2\nniters = 100\nlearning_rate = 0.001\n\nTC.fit_rep_period_weights!(\n    clustering_result;\n    weight_type,\n    tol,\n    niters,\n    learning_rate,\n)\nTC.write_clustering_result_to_tables(connection, clustering_result)\n\nTEM.populate_with_defaults!(connection)\n\nenergy_problem = TEM.run_scenario(connection; output_folder=output_dir)","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"At this point, everything should work the same as Lesson 4.","category":"page"},{"location":"10-tutorials/16-storage/#Results","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Results","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Note: Remember to look at your output folder to see the exported results and check which primal and dual information you want to analyze.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Nice, so what about the storage level?","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"# Retrieve and group the data\nstorage_levels = TIO.get_table(connection, \"var_storage_level_rep_period\")\ngdf = groupby(storage_levels, [:asset])\n\n# Create a simple plot\nn_subplots = length(gdf)\np = plot(; layout=grid(n_subplots, 1))\nfor (i, group) in enumerate(gdf)\n    plot!(\n        p[i],\n        group.time_block_end,\n        group.solution;\n        group=group.rep_period,\n        title=string(unique(group.asset)),\n        xlabel=\"Hour\",\n        ylabel=\"[MWh]\",\n        xlims=(1, 24),\n        dpi=600,\n    )\nend\np","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"What is happening? Any ideas?","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"It seems that 2 representative periods is not that fun.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Change the number of representatives to 10 and rerun the whole workflow.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Note: You need to run the whole workflow to update the representatives.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"The battery storage looks reasonable, but what is happening with the hydrogen storage?","category":"page"},{"location":"10-tutorials/16-storage/#The-parameter-is_seasonal","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"The parameter is_seasonal","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Change the parameter is_seasonal from false to true for the hydrogen storage in the file assets.csv.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Rerun the workflow and check the results again...","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"What do you notice in the output folder? Any new variables/constraints?","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Check the storage level of the hydrogen storage.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Note: It's now in the variable var_storage_level_over_clustered_year because it's seasonal.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"TIO.gettable(connection, \"varstorageleveloverclusteredyear\") # Or any other table name","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"seasonal_storage_levels = TIO.get_table(connection, \"var_storage_level_over_clustered_year\")\ngdf = groupby(seasonal_storage_levels, [:asset])\nn_subplots = length(gdf)\np = plot(; layout=grid(n_subplots, 1))\nfor (i, group) in enumerate(gdf)\n    plot!(\n        p[i],\n        group.period_block_end,\n        group.solution;\n        title=string(unique(group.asset)),\n        xlabel=\"Hour\",\n        ylabel=\"[MWh]\",\n        dpi=600,\n    )\nend\np","category":"page"},{"location":"10-tutorials/16-storage/#Changing-other-storage-parameters","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Changing other storage parameters","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"As you saw before, there are several parameters for the storage assets. Let's play with some of them...","category":"page"},{"location":"10-tutorials/16-storage/#The-parameter-initial_storage_level","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"The parameter initial_storage_level","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Change the initial_storage_level of the battery to empty (blank) and rerun the workflow.","category":"page"},{"location":"10-tutorials/16-storage/#The-parameter-storage_loss_from_stored_energy","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"The parameter storage_loss_from_stored_energy","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Change the storage_loss_from_stored_energy of the battery to empty (blank) and rerun the workflow.","category":"page"},{"location":"10-tutorials/16-storage/#Comparing-with-the-full-year-of-optimization","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Comparing with the full year of optimization","text":"","category":"section"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"The following code:","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Creates a new connection conn_hourly_benchmark to store the results of the hourly benchmark\nRuns TulipaClustering with 1 representative period of 8760 hours. Therefore, the whole hourly year\nTulipaClustering does not cluster in this case, it just runs to create the necessary tables for TulipaEnergyModel\nUpdates the values of the is_seasonal parameter to false.\nSince it is 1 year and 1 representative, the storage is not considered seasonal (it is within the representative period)\nStores the run in a new object called ep_hourly","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"## Hourly benchmark\nconn_hourly_benchmark = DBInterface.connect(DuckDB.DB)\nTIO.read_csv_folder(conn_hourly_benchmark, input_dir)\nperiod_duration_year = 8760 # the whole year\n### we are working in a wrapper function to have less code when calling TulipaClustering ;)\nprofiles_df = TIO.get_table(conn_hourly_benchmark, \"profiles_periods\")\nTC.combine_periods!(profiles_df)\nTC.split_into_periods!(profiles_df; period_duration=period_duration_year)\nnum_rep_periods_year = 1 # the whole year\nmethod = :convex_hull  # :k_means, :convex_hull, :convex_hull_with_null, :conical_hull\ndistance = CosineDist()  # CosineDist()\nclustering_result = TC.find_representative_periods(profiles_df, num_rep_periods_year; method, distance)\nweight_type = :convex  # :convex, :conical, :conical_bounded\ntol = 1e-2\nniters = 100\nlearning_rate = 0.001\nTC.fit_rep_period_weights!(\n    clustering_result;\n    weight_type,\n    tol,\n    niters,\n    learning_rate,\n)\nTC.write_clustering_result_to_tables(conn_hourly_benchmark, clustering_result)\nTEM.populate_with_defaults!(conn_hourly_benchmark)\nDuckDB.query(\n    conn_hourly_benchmark, \"ALTER TABLE rep_periods_mapping ALTER COLUMN period SET DATA TYPE INT\")\n### we update the `is_seasonal` column to false to make sure all the storage assets are non-seasonal since we only have one representative period that is the whole year\nDuckDB.query(\n    conn_hourly_benchmark, \"UPDATE asset SET is_seasonal = false\")\n### we can solve it know\nep_hourly = TEM.run_scenario(conn_hourly_benchmark)","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"You can use this result and the ones from the clustering to see the comparison of the two solutions.\nHere is an example of how to combine the plots for this case:","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"# plotting the results for the hourly benchmark\nstorage_levels_hourly = TIO.get_table(conn_hourly_benchmark, \"var_storage_level_rep_period\")\nasset_to_filter = \"h2_storage\"\nhourly_filtered_asset = filter(\n    row ->\n        row.asset == asset_to_filter,\n    storage_levels_hourly,\n)\nplot(\n    hourly_filtered_asset.time_block_end,\n    hourly_filtered_asset.solution;\n    label=\"hourly\",\n    title=\"Storage level for $asset_to_filter\",\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    xlims=(1, 8760),\n    dpi=600,\n)\n# adding the seasonal storage levels\nseasonal_filtered_asset = filter(\n    row ->\n        row.asset == asset_to_filter,\n    seasonal_storage_levels,\n)\n\n# multiplying the period_block_end by period_duration (24 in the original example) to have the same time scale\nseasonal_filtered_asset.period_block_end .*= period_duration\nseasonal_filtered_asset\nplot!(\n    seasonal_filtered_asset.period_block_end,\n    seasonal_filtered_asset.solution;\n    label=\"$num_rep_periods rep periods\",\n)","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Caveat! This is a mock-up case study with several symmetries in the data, so the results here show the trend but shouldn't be taken as general rules. Each case study needs to be fine-tuned to determine the best number of representatives.","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Here you can see the results comparing from different number of representative periods. See, that the more representatives, the better the approximations (but watch out! the longer the time to solve).","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"(Image: seasonal_storage_levels)","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"Here there is a zoom to best approximation of the hydrogen storage:","category":"page"},{"location":"10-tutorials/16-storage/","page":"Tutorial 5: Seasonal and Non-seasonal Storage","title":"Tutorial 5: Seasonal and Non-seasonal Storage","text":"(Image: seasonal_storage_levels-2)","category":"page"},{"location":"90-contributing/90-contributing/#contributing","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"","category":"section"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"Great that you want to contribute to the development of Tulipa! Please read these guidelines and our Developer Documentation to get you started.","category":"page"},{"location":"90-contributing/90-contributing/#GitHub-Rules-of-Engagement","page":"Contributing Guidelines","title":"GitHub Rules of Engagement","text":"","category":"section"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"If you want to discuss something that isn't immediately actionable, post under Discussions. Convert it to an issue once it's actionable.\nAll PR's should have an associated issue (unless it's a very minor fix).\nAssign yourself to issues you want to address. Consider if you will be able to work on them in the near future (this week) — if not, leave them available for someone else.\nWhen finalizing a pull request, set the Status to \"Ready for Review.\" If someone specific needs to review it, assign them as the reviewer (otherwise anyone can review).\nIf you want to discuss an issue at the next group meeting (or just get some attention), mark it with the \"question\" label.\nIssues without updates for 60 days (and PRs without updates in 30 days) will be labelled as \"stale\" and filtered out of view. There is a Stale project board to view and revive these.","category":"page"},{"location":"90-contributing/90-contributing/#Contributing-Workflow","page":"Contributing Guidelines","title":"Contributing Workflow","text":"","category":"section"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"Fork → Branch → Code → Push → Pull → Squash & Merge","category":"page"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"Fork the repository (once)\nCreate a new branch (in your fork)\nDo fantastic coding\nPush to your fork\nCreate a pull request from your fork to the main repository\n(After review) Squash and merge","category":"page"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"For a step-by-step guide to these steps, see our Developer Documentation.","category":"page"},{"location":"90-contributing/90-contributing/","page":"Contributing Guidelines","title":"Contributing Guidelines","text":"We use this workflow in our quest to achieve the Utopic Git History.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Tutorial-4:-Representative-Periods-with-Tulipa-Clustering","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/#Introduction","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Introduction","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Using representative periods is a simplification method to reduce the size of the problem. Instead of solving for every time period, the model solves for a few chosen representatives of the data. The original data is then reconstructed or approximated by blending the representatives.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Tulipa uses the package TulipaClustering.jl to choose representatives and cluster input data.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Set-up-the-environment","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Set up the environment","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Add the new packages:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"using Pkg: Pkg\nPkg.activate(\".\")\nPkg.add(name=\"TulipaClustering\")\nPkg.add(\"Distances\")","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Import packages:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"import TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nimport TulipaClustering as TC\nusing DuckDB\nusing DataFrames\nusing Plots\nusing Distances","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Question: Do you remember how to install the two new libraries into your environment?","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Set-up-the-workflow","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Set up the workflow","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"The data for this tutorial can be found in the folder my-awesome-energy-system/tutorial-4","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Load the data:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"connection = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-4\"\noutput_dir = \"my-awesome-energy-system/tutorial-4/results\"\nTIO.read_csv_folder(connection, input_dir)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error later.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Try to run the problem as usual:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"TEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(connection; output_folder=output_dir)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Uh oh! It doesn't work. Why not?","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"ERROR: DataValidationException: The following issues were found in the data:\n- Column 'rep_period' of table 'rep_periods_data' does not have a default","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Because we need data from the clustering!","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Adding-TulipaClustering","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Adding TulipaClustering","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"We need to produce representative period data from the base period data.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Splitting-the-Profile-Data-into-Periods","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Splitting the Profile Data into Periods","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Let's say we want to split the year into days, i.e., periods of length 24. TulipaClustering provides two methods that can help: combine_periods! combines existing periods into consequentive timesteps, and split_into_periods! splits it back into periods of desired length:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"period_duration = 24  # group data into days\n\nprofiles_df = TIO.get_table(connection, \"profiles_periods\")\nTC.combine_periods!(profiles_df)\nTC.split_into_periods!(profiles_df; period_duration)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Clustering-the-Data","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Clustering the Data","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"We use find_representative_periods to reduce the base periods to RPs. The method has two mandatory positional arguments:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"the profile dataframe,\nthe number of representative periods you want to obtain.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"You can also change two optional arguments (after a semicolon):","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"drop_incomplete_last_period tells the algorithm how to treat the last period if it has fewer timesteps than the other ones (defaults to false),\nmethod clustering method (defaults to :k_means),\ndistance a metric used to measure how different the datapoints are (defaults to SqEuclidean()),","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"num_rep_periods = 7\nmethod = :k_medoids  # :k_means, :convex_hull, :convex_hull_with_null, :conical_hull\ndistance = Euclidean()  # CosineDist()\n\nclustering_result = TC.find_representative_periods(profiles_df, num_rep_periods; method, distance)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"The clustering_result contains some useful information:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"profiles is a dataframe with profiles for RPs,\nweight_matrix is a matrix of weights of RPs in blended periods,\nclustering_matrix and rp_matrix are matrices of profile data for each base and representative period (useful to keep for the next step, but you should not need these unless you want to do some extra math here)\nauxiliary_data contains some extra data that was generated during the clustering process and is generally not interesting to the user who is not planning to interact with the clustering method on a very low level.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Weight-Fitting","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Weight Fitting","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"After the clustering is done, each period is assigned to one representative period. We call this a \"Dirac assignment\" after the Dirac measure: a measure that is concentrated on one item (i.e., one base period is mapped into exactly one representative period).","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"TulipaClustering supports blended weights for representative periods. To produce these, we use projected gradient descent. You don't need to know all the math behind it, but it has a few parameters that are useful to understand:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"weight_type can be :conical (weights are positive), :conical_bounded (weights are positive, add at most into one), :convex (weights are positive, add into one), :dirac (one unit weight and the rest are zeros). The order here is from less restrictive to more restrictive.\ntol is the algorithm's tolerance. A tolerance of 1e-2 means that weights are estimated up to two decimal places (e.g., something like 0.15).\nniters and learning_rate tell for how many iterations to run the descent and by how much to adjust the weights in each iterations. More iterations make the method slower but produce better results. Larger learning rate makes the method converge faster but in a less stable manner (i.e., weights might start going up and down a lot from iteration to iteration). Sometimes you need to find the right balance for yourself. In general, if the weights produced by the method look strange, try decreasing the learning rate and/or increasing the number of iterations.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Now fit the weights:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"weight_type = :dirac  # :convex, :conical, :conical_bounded\ntol = 1e-2\nniters = 100\nlearning_rate = 0.001\n\nTC.fit_rep_period_weights!(\n    clustering_result;\n    weight_type,\n    tol,\n    niters,\n    learning_rate,\n)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Running-the-Model","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Running the Model","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"To run the model, add the data to the system with TulipaIO and then run it as usual:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"TC.write_clustering_result_to_tables(connection, clustering_result)\n\nTEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(connection; output_folder=output_dir)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Interpreting-the-Results","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Interpreting the Results","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"To plot the results, first read the data with TulipaIO and filter what's needed (and rename time_block_start to timestep while you're at it):","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"flows = TIO.get_table(connection, \"var_flow\")\n\nselect!(\n    flows,\n    :from_asset,\n    :to_asset,\n    :year,\n    :rep_period,\n    :time_block_start => :timestep,\n    :solution\n)\n\nfrom_asset = \"ccgt\"\nto_asset = \"e_demand\"\nyear = 2030\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year,\n    flows,\n)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"To reinterpret the RP data as base periods data, first create a new dataframe that contains both by using the inner join operation:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"rep_periods_mapping = TIO.get_table(connection, \"rep_periods_mapping\")\ndf = innerjoin(filtered_flow, rep_periods_mapping, on=[:year, :rep_period])","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Next, use Julia's Split-Apply-Combine approach to group the dataframe into smaller ones. Each grouped dataframe contains a single data point for one base period and all RPs it maps to. Then multiply the results by weights and add them up.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"gdf = groupby(df, [:from_asset, :to_asset, :year, :period, :timestep])\nresult_df = combine(gdf, [:weight, :solution] => ((w, s) -> sum(w .* s)) => :solution)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"Now you can plot the results. Remove the period data since you don't need it anymore, and re-sort the data to make sure it is in the right order.","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"TC.combine_periods!(result_df)\nsort!(result_df, :timestep)\n\nplot(\n    result_df.timestep,\n    result_df.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    marker=:circle,\n    markersize=2,\n    xlims=(1, 168),\n    dpi=600,\n)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"This concludes this tutorial! Play around with different parameters to see how the results change. For example, when you use :dirac vs :convex weights, do you see the difference? How does the solution change as you increase the number of RPs?","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#The-Script-as-a-Whole","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"The Script as a Whole","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"using Pkg\nPkg.activate(\".\")\n# Pkg.add(\"TulipaEnergyModel\")\n# Pkg.add(\"TulipaIO\")\nPkg.add(\"TulipaClustering\")\n# Pkg.add(\"DuckDB\")\n# Pkg.add(\"DataFrames\")\n# Pkg.add(\"Plots\")\nPkg.add(\"Distances\")\n\nPkg.instantiate()\n\nimport TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nimport TulipaClustering as TC\nusing DuckDB\nusing DataFrames\nusing Plots\nusing Distances\n\nconnection = DBInterface.connect(DuckDB.DB)\n\ninput_dir = \"my-awesome-energy-system/tutorial-4\"\noutput_dir = \"my-awesome-energy-system/tutorial-4/results\"\n\nTIO.read_csv_folder(connection, input_dir)\n\n\nperiod_duration = 24\nprofiles_df = TIO.get_table(connection, \"profiles_periods\")\nTC.combine_periods!(profiles_df)\nTC.split_into_periods!(profiles_df; period_duration)\n\nnum_rep_periods = 2\nmethod = :k_medoids  # :k_means, :convex_hull, :convex_hull_with_null, :conical_hull\ndistance = Euclidean()  # CosineDist()\n\nclustering_result = TC.find_representative_periods(profiles_df, num_rep_periods; method, distance)\n\nweight_type = :dirac  # :convex, :conical, :conical_bounded\ntol = 1e-2\nniters = 100\nlearning_rate = 0.001\n\nTC.fit_rep_period_weights!(\n    clustering_result;\n    weight_type,\n    tol,\n    niters,\n    learning_rate,\n)\nTC.write_clustering_result_to_tables(connection, clustering_result)\n\nTEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(connection; output_folder=output_dir)\n\n\nflows = TIO.get_table(connection, \"var_flow\")\nselect!(\n    flows,\n    :from_asset,\n    :to_asset,\n    :year,\n    :rep_period,\n    :time_block_start => :timestep,\n    :solution\n)\n\nfrom_asset = \"ccgt\"\nto_asset = \"e_demand\"\nyear = 2030\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year,\n    flows,\n)\n\n\nrep_periods_mapping = TIO.get_table(connection, \"rep_periods_mapping\")\n\ndf = innerjoin(filtered_flow, rep_periods_mapping, on=[:year, :rep_period])\ngdf = groupby(df, [:from_asset, :to_asset, :year, :period, :timestep])\nresult_df = combine(gdf, [:weight, :solution] => ((w, s) -> sum(w .* s)) => :solution)\nTC.combine_periods!(result_df)\nsort!(result_df, :timestep)\nplot(\n    result_df.timestep,\n    result_df.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    marker=:circle,\n    markersize=2,\n    xlims=(1, 168),\n    dpi=600,\n)\n","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/#Working-with-the-New-Tables-Created-by-TulipaClustering","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Working with the New Tables Created by TulipaClustering","text":"","category":"section"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"You can check the new tables with TulipaIO, for example:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"TIO.get_table(connection,\"rep_periods_mapping\")","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"If you want to save the intermediary tables created by the clustering, you can do this with DuckDB:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"DuckDB.execute(\n    connection,\n    \"COPY 'profiles_rep_periods' TO 'profiles-rep-periods.csv' (HEADER, DELIMITER ',')\",\n)","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"The new tables are:","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"profilesrepperiods\nrepperiodsdata\nrepperiodsmapping\ntimeframe_data","category":"page"},{"location":"10-tutorials/15-clustering-rep-periods/","page":"Tutorial 4: Representative Periods with Tulipa Clustering","title":"Tutorial 4: Representative Periods with Tulipa Clustering","text":"This is useful when you don't have to rerun the clustering every time.","category":"page"},{"location":"20-user-guide/50-schemas/#data","page":"Analysis Workflow","title":"Analysis Workflow","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"In this section we will look at the analysis workflow and data-handling in more detail, explaining what you need to go from raw data to analysis results.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Pages = [\"50-schemas.md\"]\nDepth = [2, 3]","category":"page"},{"location":"20-user-guide/50-schemas/#workflow-overview","page":"Analysis Workflow","title":"Workflow overview","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Here is a snapshot overview of a regular workflow:","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"(Image: Tulipa Workflow. Textual explanation below.)","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Workflow explanation (follow the boxes):","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"External source: The first thing that you need, and hopefully have, is data. Currently, Tulipa does not provide any public data sources, so you need to load all required data.\nCreate connection: Tulipa uses a DuckDB database to store the input data, the representation of variables, constraints, and other internal tables, as well as the output. This database is linked through the connection argument in various parts of the API. Most notably, run_scenario and EnergyProblem receive the connection as the main argument to create the model (and various internal tables).\nDuckDB connection: This area (yellow) shows which tables are created in DuckDB throughout the workflow.\nLoad data: Whether you have CSV/Excel/Parquet files or a separate Database containing your data, you need to load it into the DuckDB connection, i.e., create tables (or table views) with the data that you will process for Tulipa.\nDuckDB connection: These are the Sources tables. This data can be in whatever format you want, but you will need to transform it into the Tulipa format later.\nProcess data into an instance (1 model run) with DuckDB/TulipaIO: Now you need to prepare the data for clustering. Even if you don't want to cluster your data, you still need to run TulipaClustering.dummy_cluster! to generate Tulipa's required tables. Since your data in now inside the connection, you can use DuckDB's SQL and/or TulipaIO's convenience functions to manipulate it. Another method is to use Julia/Python/Excel to create the data externally (from the source files or DuckDB) and load it back into DuckDB. The important thing is you need to satisfy the TulipaClustering format.\nDuckDB connection: These are the Instance data tables, but it can also be loaded with the Sources.\nCluster into representative periods using TulipaClustering: Run TulipaClustering to compute the representative periods and create the necessary tables.\nDuckDB connection: These are the Time data tables. The tables created in this step are part of the cluster group (see Groups of tables below)\nPrepare data for TulipaEnergyModel's format: Process your data (using TulipaIO, DuckDB or whatever method you choose) into the Tulipa Format, following the schema. Since the format is quite extensive, you might want to use the populate_with_defaults! function to generate all columns and work from there. See Minimum data and using defaults for more details.\nDuckDB connection: TulipaEnergyModel expects the Time data tables from the previous step and these Tulipa format tables. In rare instances, your data will be complete, but most likely you will need to fill-out your tables with default values for columns that are not important for your problem. The tables prepared in this step are part of the input group of tables.\nCreate internal tables for the model indices: Finally, you're ready to use TulipaEnergyModel! There are multiple ways to create and solve the model, but the idea is the same. The first interaction with Tulipa will create the tables to store the variables, constraints, and expressions indices, as well as other necessary internal tables. Data validation also checks that the tables follow the expected requirements.\nDuckDB connection: These are the Internal data tables. Notably, the variables and constraints indices tables are created in their respective groups: variables and constraints. See the Groups of tables section for more details.\nCreate model: This is most of the heavy-lifting of the workflow, apart from solving the model. This step creates all the Julia/JuMP structures using the tables from the previous step. For instance, a JuMP variable is created for each row of each variable table.\nDuckDB connection: Very little data is created in DuckDB in this step. Some expressions that could not have been created before are created in the expressions group. A lot of Julia/JuMP-specific things are created, but they cannot be stored in the DuckDB connection.\nSolve model: Finally, send the model to the solver and wait for a result.\nStore primal and dual solutions: This step computes the dual variables and then loads the values of the primals and duals into the variables and constraints tables.\nDuckDB connection: Technically, no new tables are created in this step. Instead, new columns are attached to the variables and constraints tables.\nProcess output for plots and dashboard: Now prepare the output that you need, once again using DuckDB/TulipaIO. You can also export the data from DuckDB and continue your analysis with other tools.\nDuckDB connection: You might create new Analysis tables. They can be used for the next steps or for a possible dashboard connected to the DuckDB connection.\nCreate plots: Optionally create plots.\nExport solution: Optionally export all the tables from the DuckDB connection to files, and/or create and save plots.\nOutput files: External. Whatever outputs you have produced and want to export to other formats. For instance, CSV/Parquet files with the full variables and constraints tables can be exported from the corresponding DuckDB tables.\nDashboard: A possible dashboard connecting directly to the DuckDB connection.","category":"page"},{"location":"20-user-guide/50-schemas/#minimum-data","page":"Analysis Workflow","title":"Minimum data and using defaults","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Since TulipaEnergyModel is at a late stage in the workflow, its input data requirements are stricter. Therefore, the input data required by the Tulipa model must follow the schema in the follow section.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Dealing with defaults is hard. A missing value might represent two different things to different people. That is why we require the tables to be complete. However, we also understand that it is not reasonable to expect people to fill a lot of things that they don't need for their models. Therefore, we have created the function populate_with_defaults! to fill the remaining columns of your tables with default values.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"To know the defaults, check the Table Schemas below.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"warning: Beware implicit assumptions\nWhen data is missing and you automatically fill it with defaults, beware of your assumptions on what that means. For instance, maybe you expect the default capacity to be \"unlimited\", or maybe you expect it to be 0. Check what are the default values and decide if you want to use them or not. If you think a default does not make sense, open an issue, or a discussion thread.","category":"page"},{"location":"20-user-guide/50-schemas/#Example-of-using-populate_with_defaults!","page":"Analysis Workflow","title":"Example of using populate_with_defaults!","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Below we have the minimum amount of data (essentially, nothing), that is necessary to start Tulipa.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"using TulipaEnergyModel, TulipaIO, DuckDB, DataFrames\n\ndata = Dict(\n    # Basic asset data\n    \"asset\" => DataFrame(\n        :asset => [\"some_producer\", \"some_consumer\"],\n        :type => [\"producer\", \"consumer\"],\n    ),\n    \"asset_both\" => DataFrame(\n        :asset => [\"some_producer\", \"some_consumer\"],\n        :commission_year => [2030, 2030],\n        :milestone_year => [2030, 2030],\n    ),\n    \"asset_commission\" => DataFrame(\n        :asset => [\"some_producer\", \"some_consumer\"],\n        :commission_year => [2030, 2030],\n    ),\n    \"asset_milestone\" => DataFrame(\n        :asset => [\"some_producer\", \"some_consumer\"],\n        :milestone_year => [2030, 2030],\n    ),\n\n    # Basic flow data\n    \"flow\" => DataFrame(:from_asset => [\"some_producer\"], :to_asset => [\"some_consumer\"]),\n    \"flow_both\" => DataFrame(\n        :from_asset => String[],\n        :to_asset => String[],\n        :commission_year => Int[],\n        :milestone_year => Int[],\n    ),\n    \"flow_commission\" => DataFrame(\n        :from_asset => [\"some_producer\"],\n        :to_asset => [\"some_consumer\"],\n        :commission_year => [2030],\n    ),\n    \"flow_milestone\" => DataFrame(\n        :from_asset => [\"some_producer\"],\n        :to_asset => [\"some_consumer\"],\n        :milestone_year => [2030],\n    ),\n\n    # Basic time information\n    \"year_data\" => DataFrame(:year => [2030]),\n    \"rep_periods_data\" => DataFrame(:year => [2030, 2030], :rep_period => [1, 2]),\n    \"timeframe_data\" => DataFrame(:year => 2030, :period => 1:365),\n    \"rep_periods_mapping\" =>\n        DataFrame(:year => 2030, :period => 1:365, :rep_period => mod1.(1:365, 2)),\n)","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"And here we load this data into a DuckDB connection.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"connection = DBInterface.connect(DuckDB.DB)\n\n# Loading the minimum data in the connection\nfor (table_name, table) in data\n    DuckDB.register_data_frame(connection, table, table_name)\nend\n\n# Table `asset`:\nDuckDB.query(connection, \"FROM asset\") |> DataFrame","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Now we run populate_with_defaults! to fill the remaining columns with default values:","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"TulipaEnergyModel.populate_with_defaults!(connection)\n\nDuckDB.query(connection, \"FROM asset\") |> DataFrame","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"You can see that the table above has been modified to include many more columns.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Finally, the problem can be solved:","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"energy_problem = TulipaEnergyModel.run_scenario(\n    connection;\n    output_folder = mktempdir(),\n    show_log = false,\n)\n\nDuckDB.query(connection, \"FROM var_flow LIMIT 5\") |> DataFrame","category":"page"},{"location":"20-user-guide/50-schemas/#groups-of-tables","page":"Analysis Workflow","title":"Groups of tables","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"After creating a connection and loading data in a way that follows the schema (see the previous section on minimum data), then Tulipa will create tables to handle the model data and various internal tables. There are different groups of tables, which we explain below. See the Workflow overview to see where they pop up.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Required by TulipaEnergyModel. These are described in the Table Schemas.\ncluster: Tables created by TulipaClustering.\ninput: Tables expected by TulipaEnergyModel.\nCreated by TulipaEnergyModel.\nvariables: Variable indices. These tables are prefixed by var_ in the DuckDB connection.\nconstraints: Constraints indices. These tables are prefixed by cons_ in the DuckDB connection.\nexpressions: Expressions indices. These tables are prefixed by expr_ in the DuckDB connection.\nresolution: Unrolled partition blocks of assets and flows. These tables are prefixed by either asset_time_resolution_ or flow_time_resolution_.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"Additionally, we create various temporary tables, which are prefixed by t_.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"warning: Names and prefixes might change\nThe tables created by TulipaEnergyModel might change in name or prefix unless explicitly noted. Once Tulipa 1.0 is released, we might change this policy.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"You probably don't have to navigate these tables yourself, but if you want more information, you can list them all from DuckDB using the duckdb_tables() table. Here are 10 random tables:","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"DuckDB.query(\n    connection,\n    \"SELECT table_name\n    FROM duckdb_tables()\n    WHERE table_name NOT LIKE 't_%'\n    ORDER BY random() LIMIT 10\"\n) |> DataFrame","category":"page"},{"location":"20-user-guide/50-schemas/#table-schemas","page":"Analysis Workflow","title":"Table Schemas","text":"","category":"section"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"The optimization model parameters with the input data must follow the schema below for each table.","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"The schemas below are in input-schemas.json. You can also view the schemas after loading the package by typing TulipaEnergyModel.schema in the Julia console. Here is the complete list of model parameters in the schemas per table (or CSV file):","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"info: Optional tables/files and their defaults\nThe following tables/files are allowed to be missing: \"assets_rep_periods_partitions\", \"assets_timeframe_partitions\", \"assets_timeframe_profiles\", \"flows_rep_periods_partitions\", \"group_asset\", \"profiles_timeframe\".For the partitions tables/files, the default value are specification = uniform and partition = 1 for each asset/flow and year\nFor the profiles tables/files, the default value is a flat profile of value 1.0 p.u.\nIf no group table/file is available there will be no group constraints in the model","category":"page"},{"location":"20-user-guide/50-schemas/","page":"Analysis Workflow","title":"Analysis Workflow","text":"\"\"\"\nThe output of the following code is a Markdown text with the following structure:\n\nTABLE_NAME\n=========\n\nPARAMETER_NAME\n\n  •  Description: Lorem ipsum\n  •  Type: SQL type of the parameter\n  •  Default: a value or \"No default\"\n  •  Unit of measure: a value or \"No unit\"\n  •  Constraints: a table or \"No constraints\"\n\"\"\"\n\nusing Markdown, JSON\nusing OrderedCollections: OrderedDict\n\ninput_schemas = JSON.parsefile(\"../../../src/input-schemas.json\"; dicttype = OrderedDict)\n\nlet buffer = IOBuffer()\n    for (i,(table_name, fields)) in enumerate(input_schemas)\n        write(buffer, \"## Table $i : `$table_name`\\n\\n\")\n        for (field_name, field_info) in fields\n            _description = get(field_info, \"description\", \"No description provided\")\n            _type = get(field_info, \"type\", \"Unknown type\")\n            _unit = get(field_info, \"unit_of_measure\", \"No unit\")\n            _default = get(field_info, \"default\", \"No default\")\n            _constraints_values = get(field_info, \"constraints\", nothing)\n\n            write(buffer, \"**`$field_name`**\\n\\n\")\n            write(buffer, \"- Description: $_description\\n\\n\")\n            write(buffer, \"- Type: `$_type`\\n\")\n            write(buffer, \"- Unit of measure: `$_unit` \\n\")\n            write(buffer, \"- Default: `$_default`\\n\")\n\n            if _constraints_values === nothing\n                write(buffer, \"- Constraints: No constraints\\n\")\n            elseif isa(_constraints_values, OrderedDict)\n                write(buffer, \"| Constraints | Value |\\n| --- | --- |\\n\")\n                for (key, value) in _constraints_values\n                    write(buffer, \"| $key | `$value` |\\n\")\n                end\n                write(buffer, \"\\n\")\n            else\n                write(buffer, \"- Constraints: `$(string(_constraints_values))`\\n\")\n            end\n        end\n    end\n    Markdown.parse(String(take!(buffer)))\nend\n","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Tutorial-3:-Flexible-Time-Resolution","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/#Introduction","page":"Tutorial 3: Flexible Time Resolution","title":"Introduction","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Tulipa allows mixing multiple time resolutions within the same problem.\nFor instance, by:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"energy carrier - electricity high, gas medium, heat low\ngeographic area - local high, neighboring areas decreasing with distance\ntime horizon - short-term high, long-term low","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"This is a useful feature for scaling large problems to make them solvable or to solve problems faster while iteratively tuning data - without losing granular detail in the area of interest.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"More information is in the section Flexible Time Resolution.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"For more nitty gritty nerdy details, you can read this reference.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Gao, Z., Gazzani, M., Tejada-Arango, D. A., Siqueira, A. S., Wang, N., Gibescu, M., & Morales-España, G. (2025). Fully flexible temporal resolution for energy system optimization. Applied Energy, 396, 126267. https://doi.org/10.1016/j.apenergy.2025.126267","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Hydrogen-sector-on-6-hour-resolution","page":"Tutorial 3: Flexible Time Resolution","title":"Hydrogen sector on 6 hour resolution","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Defining flexible temporal resolution requires the files assets_rep_periods_partitions and flows_rep_periods_partitions, so let's create them together.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"tip: Tip\nThe schemas of the files is described in the section Inputs.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Working in the folder tutorial-3:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Create a new file called assets_rep_periods_partitions.csv\nCopy this text into the file:\nasset,partition,rep_period,specification,year\nelectrolizer,6,1,uniform,2030\nCreate a new file called flows_rep_periods_partitions.csv\nCopy this text into the file:\nfrom_asset,to_asset,partition,rep_period,specification,year\nelectrolizer,h2_demand,6,1,uniform,2030","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"note: Note\nIf no partition or resolution is defined for an asset or flow, then the default values are uniform and 1.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Instantiate","page":"Tutorial 3: Flexible Time Resolution","title":"Instantiate","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Please instantiate your enviroment by typing the following command in the Julia REPL:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"# guaranteed to be run in the current directory\nusing Pkg: Pkg\nPkg.activate(\".\")\nPkg.instantiate()","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Run-the-workflow","page":"Tutorial 3: Flexible Time Resolution","title":"Run the workflow","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"In my_workflow.jl you can simply change the name of your input directory and run your code.\nFrom the Basics Tutorial, it should look something like this:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"# Guarantee to run in the current directory\nusing Pkg: Pkg\nPkg.activate(\".\")\n\n# Load the packages\nimport TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nusing DuckDB\nusing DataFrames\nusing Plots\n\n# Define the directories\ninput_dir = \"my-awesome-energy-system/tutorial-3\"\noutput_dir = \"my-awesome-energy-system/tutorial-3/results\"\n\n# Create the connection and read the case study files\nconnection = DBInterface.connect(DuckDB.DB)\nTIO.read_csv_folder(connection, input_dir)\n\n# Add the defaults\nTEM.populate_with_defaults!(connection)\n\n# You can print the tables you have created to see if everything matches and is filled in as intended\nTIO.get_table(connection, \"assets_rep_periods_partitions\")\nTIO.get_table(connection, \"flows_rep_periods_partitions\")\n\n\n# Optimize the model\nenergy_problem =\n    TEM.run_scenario(connection; output_folder=output_dir)\n","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"From the statistics at the end, what are the number of constraints, variables, and objective function?","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"  - Model created!\n    - Number of variables: 89060\n    - Number of constraints for variable bounds: 80300\n    - Number of structural constraints: 108040\n  - Model solved!\n    - Termination status: OPTIMAL\n    - Objective value: 1.4718768475318682e8","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Explore-the-results","page":"Tutorial 3: Flexible Time Resolution","title":"Explore the results","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Explore the flow that goes from the electrolizer to the h2_demand:\nNotice there are 1460 values (8760h/6h).","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"\nflows = TIO.get_table(connection, \"var_flow\")\n\nfrom_asset = \"electrolizer\"\nto_asset = \"h2_demand\"\nyear = 2030\nrep_period = 1\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    flows,\n)\n\nplot(\n    filtered_flow.time_block_start,\n    filtered_flow.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    marker=:circle,\n    markersize=2,\n    linetype=:steppost, # try: stepmid, steppost, or steppre\n    xlims=(168 * 2, 168 * 3),\n    dpi=600,\n)\n","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Explore the h2_balance duals in the results:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"balance = TIO.get_table(connection, \"cons_balance_consumer\")\n\nasset = \"h2_demand\"\nyear = 2030\nrep_period = 1\n\nfiltered_asset = filter(\n    row ->\n        row.asset == asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    balance,\n)","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"What do you notice?","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"How is the resolution of the Consumer Balance Constraint defined?","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Update the flows_rep_periods_partitions file:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"from_asset,to_asset,partition,rep_period,specification,year\nelectrolizer,h2_demand,6,1,uniform,2030\nsmr_ccs,h2_demand,6,1,uniform,2030","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Run again and explore the results once more...","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Change-the-specification","page":"Tutorial 3: Flexible Time Resolution","title":"Change the specification","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"The parameter specification allows three values: uniform,math, or explicit.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Some examples on how to set it up are in the docs for the TulipaEnergyModel._parse_rp_partition function.","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"What is the equialent of a partition of 6 in a uniform specification in a math specification?","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/#Compare-with-the-hourly-case-from-the-Assets-and-Flows-tutorial","page":"Tutorial 3: Flexible Time Resolution","title":"Compare with the hourly case from the Assets & Flows tutorial","text":"","category":"section"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"If you want to compare results of two models, you can create a new connection, a new energy problem and compare result. One thing that could be interesting to consider is changing partitions in flows_rep_periods_partitions and assets_rep_periods_partitions to 1. Once changed, we can solve a new energy problem as such:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"conn_hourly = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-3\"\nTIO.read_csv_folder(conn_hourly, input_dir)\nTEM.populate_with_defaults!(conn_hourly)\nhourly_energy_problem = TEM.run_scenario(conn_hourly)","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Notice that we change the name of the connection and the name of the energy problem (also, we are not exporting the results, but it can be done in a new folder, if needed).","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Compare the number of constraints, variables, and objective function between the two problems:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"EnergyProblem:\n  - Model created!\n    - Number of variables: 96360\n    - Number of constraints for variable bounds: 87600\n    - Number of structural constraints: 122640\n  - Model solved!\n    - Termination status: OPTIMAL\n    - Objective value: 1.4854146333461973e8","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"What do you notice? Is it what you where expecting?","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"Let's plot the flows together, for a specific time period in the year:","category":"page"},{"location":"10-tutorials/14-fully-flexible-time/","page":"Tutorial 3: Flexible Time Resolution","title":"Tutorial 3: Flexible Time Resolution","text":"flows = TIO.get_table(connection, \"var_flow\")\nfrom_asset = \"electrolizer\"\nto_asset = \"h2_demand\"\nyear = 2030\nrep_period = 1\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    flows,\n)\n\nplot(\n    filtered_flow.time_block_start,\n    filtered_flow.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    marker=:circle,\n    markersize=2,\n    linetype=:steppost, # try: stepmid, steppost, or steppre\n    xlims=(2200, 2400),\n    dpi=600,\n)\n\nhourly_flows = TIO.get_table(conn_hourly, \"var_flow\")\n\nhourly_filtered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    hourly_flows,\n)\n\nplot!(\n    hourly_filtered_flow.time_block_start,\n    hourly_filtered_flow.solution;\n    label=string(from_asset, \" -> \", to_asset, \" (hourly)\"),\n)","category":"page"},{"location":"10-tutorials/11-setting-up/#tutorials-setup","page":"Setting up","title":"Setting up","text":"","category":"section"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"In this pre-tutorial, you will learn (a bit) about:","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Creating a VS Code project\nSetting up a workflow file for Julia\nRetrieving the data necessary for the following tutorials","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"These are simply some set-up steps to get you ready for the rest of the tutorials. Do not skip these steps!","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Let's get started!","category":"page"},{"location":"10-tutorials/11-setting-up/#vscode-project","page":"Setting up","title":"Create a VS Code project","text":"","category":"section"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Make sure you have Julia installed, as well as the Julia extension in VS Code.","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Open VS Code and create a new project\n File > Open Folder > Create a new folder > Select\nOpen a Julia REPL\nCTRL + SHIFT + P > ENTER\nRun the code below in your Julia REPL to create a new environment and add the necessary packages (only necessary when creating a new project environment):","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"using Pkg: Pkg       # Julia package manager\nPkg.activate(\".\")    # Creates and activates the project in the new folder - notice it creates Project.toml and Manifest.toml in your folder for reproducibility\nPkg.add(\"TulipaEnergyModel\")\nPkg.add(\"TulipaIO\")\nPkg.add(\"DuckDB\")\nPkg.add(\"DataFrames\")\nPkg.add(\"Plots\")\nPkg.instantiate()","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"tip: Tip\nIf you already had an installed version of the packages, then consider updating them using the update function in Pkg, for instance, Pkg.update(\"TulipaEnergyModel\").","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Create a Julia file called my_workflow.jl\nPaste this code in the file. Running it will load the necessary packages:","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"import TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nusing DuckDB\nusing DataFrames\nusing Plots","category":"page"},{"location":"10-tutorials/11-setting-up/#tutorial-data-folders","page":"Setting up","title":"Set up data and folders","text":"","category":"section"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"Download the folders\nGo to main repo website: https://github.com/TulipaEnergy/TulipaEnergyModel.jl/\nClick on Tags\nDownload the Zip file of the version you have installed (usually the latest)\nThe data is located in the subfolders: docs > src > 10-tutorials > my-awesome-energy-system\nMove the 'my-awesome-energy-system' folder into your VS Code project.\n  To find the folder where you created your project, right click on any file in VS code (e.g. 'my_workflow.jl') and click \"Reveal in File Explorer\"","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"The workflow.jl and 'my-awesome-energy-system' folder should now both be present in your VS Code project.","category":"page"},{"location":"10-tutorials/11-setting-up/","page":"Setting up","title":"Setting up","text":"info: What parameters can I use?\nCheck out the docs: TulipaEnergyModel Inputs and the input-schemas.json file.","category":"page"},{"location":"30-concepts/#concepts","page":"Concepts","title":"Concepts","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Pages = [\"30-concepts.md\"]\nDepth = [2, 3]","category":"page"},{"location":"30-concepts/#concepts-summary","page":"Concepts","title":"Summary","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"TulipaEnergyModel.jl uses two fundamental building blocks as the foundation of the optimization model:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Assets: representation of a physical asset that can produce, consume, store, balance, or convert energy. Some examples of what these assets can represent are:\nProducer: e.g., wind turbine, solar panel\nConsumer: e.g., electricity demand, heat demand\nStorage: e.g., battery, pumped-hydro storage\nBalancing Hub: e.g., an electricity network that serves as a connection among other energy assets\nConversion: e.g., power plants, electrolyzers\nFlows: representation of the connections among assets, e.g., pipelines, transmission lines, or simply the energy production that goes from one asset to another.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In a nutshell, the model guarantees a balance of energy for the various types of assets while considering the flow limits. It considers a set of representative periods (e.g., days or weeks) for a given timeframe (e.g., a year) the user wants to analyze. Therefore, the model has two types of temporal (time) constraints to consider the different chronology characteristics of the assets:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Rep-period Constraints: These constraints limit the asset or flow within a representative period. The rep-period constraints help to characterize the short-term operational dynamics of the assets. So far, the model considers balance and flow limitations within the representative period, as well as unit commitment and ramping. In the future, reserve constraints will also be included.\nOver-clustered-year Constraints: These constraints combine the information of the representative periods and create limitations between them to recover chronological information across the whole timeframe. The over-clustered-year constraints help to characterize the long-term operational dynamics of the assets (e.g., seasonality). So far, the model uses this type of constraint to model seasonal storage. Future developments will include, for example, maximum or minimum production/consumption for a year (or any timeframe).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Are you into the math, objective function terms, and constraints?\nThe mathematical formulation shows an overview of all the constraints and the variables in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Another essential concept in the model is the flexible time resolution, which allows for each asset to be considered in a single timestep (e.g., 1, 2, 3...) or in a range of timesteps (e.g., 1:3, meaning that the asset's variable represents the value of timesteps 1, 2, and 3). This concept allows the modeling of different dynamics depending on the asset; for instance, electricity assets can be modeled hourly, whereas hydrogen assets can be modeled in a 6-hour resolution (avoiding creating unnecessary constraints and variables).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The following sections explain these concepts in more detail.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Want to know more about the references used in this section?\nPlease visit the scientific references section for links to the papers that support this section.","category":"page"},{"location":"30-concepts/#flex-asset-connection","page":"Concepts","title":"Flexible Connection of Energy Assets","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In energy system modeling, it is becoming common to have hybrid assets like storage + renewable (e.g., battery + solar), electrolyzer + renewable (e.g., electrolyzer + wind), or renewable + hydro (e.g., solar + hydro) that are located at the same site and share a common connection point to the grid. The standard method of modeling these assets requires extra variables and constraints for them to function correctly. For example, flows from the grid are not allowed, as they either avoid charging from the grid or require green hydrogen production. Therefore, hybrid connections typically require an additional node to regulate this connection with the grid.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The representation of the energy system in TulipaEnergyModel.jl is based on Graph Theory, which deals with the connection between vertices by edges. This representation provides a more flexible framework to model energy assets in the system as vertices and flows between energy assets as edges. By connecting assets directly to each other (i.e., without having a node in between), we reduce the number of variables and constraints needed to represent hybrid configurations, thus reducing the model size.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Consider the following example to demonstrate the benefits of using a graph theory approach. In the classic connection approach, the nodes play a crucial role in modeling. For instance, every asset must be connected to a node with balance constraints. When a storage asset and a renewable asset are in a hybrid connection like the one described before, a connection point is needed to connect the hybrid configuration to the rest of the system. Therefore, to consider the hybrid configuration of a storage asset and a renewable asset, we must introduce a node (i.e., a connection point) between these assets and the external power grid (i.e., a balance point), as shown in the following figure:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Classic connection)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this system, the phs storage asset charges and discharges from the connection point, while the wind turbine produces power that goes directly to the connection point. This connection point is connected to the external power grid through a transmission line that leads to a balance hub that connects to other assets. Essentially, the connection point acts as a balancing hub point for the assets in this hybrid configuration. Furthermore, these hybrid configurations impose an extra constraint to avoid storage charges from the power grid.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's consider the modeling approach in TulipaEnergyModel.jl. As nodes are no longer needed to connect assets, we can connect them directly to each other, as shown in the figure below:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Flexible connection)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"By implementing this approach, we can reduce the number of variables and constraints involved. For example, the balance constraint in the intermediate node and the extra constraint to avoid the storage charging from the power grid are no longer needed. Additionally, we can eliminate the variable determining the flow between the intermediate node and the power grid, because the flow from phs to balance can directly link to the external grid. The section comparison of different modeling approaches shows the quantification of these reductions.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"This example of a phs and a wind asset is useful for illustrating the advantages of this modeling approach and will be reused in the following sections. However, please keep in mind that there are other applications of hybrid configurations, such as battery-solar, hydro-solar, and electrolyzer-wind.","category":"page"},{"location":"30-concepts/#Additional-explanation-on-transport-flows","page":"Concepts","title":"Additional explanation on transport flows","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In TulipaEnergyModel.jl, flows can be both input/output flows and transport flows (i.e., where you model a transmission asset). In the above illustrative example, wind-balance is an energy output flow, representing the production from wind directly sent to balance. In this case, the flow has a direction from wind to balance. However, in principle, any flow can be a transport flow and by definition in TulipaEnergyModel.jl, transport flows are bidirectional.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's zoom in on the phs-wind-balance triangle and see what happens in the figure below. To the left, all three flows have transformed into transport flows, and they are now bidirectional. Flows can go towards wind, which can be counter-intuitive: what does it mean to have a producer receiving energy? Translating into a standard method may help the thinking, we are essentially modeling the case to the right. The producer cannot receive energy, but transport flows can pass through an extra node with a unidirectional flow from the producer. We reduce this unnecessary node, but the modeling problem is not changed.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Flexible connection with transport flows)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"warning: Be careful with the definition of flows\nAlthough transport flows are bidirectional, they must be defined in a single direction. For example, a producer like wind can only have outgoing flows. Thus, the flow between wind and balance must be specified as the flow from wind to balance, with its sign allowed to be free.\nBy having transport flows, we now model a different problem because flows can pass through wind following the direction from balance to wind to phs. wind is essentially a hub asset. However, this does not affect the unidirectional nature of charging by the flow from wind to phs and discharging by the flow from phs to balance, which remain fixed by the definition of the flows.","category":"page"},{"location":"30-concepts/#flex-time-res","page":"Concepts","title":"Flexible Time Resolution","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"One of the core features of TulipaEnergyModel.jl is that it can handle different time resolutions on the assets and the flows. Typically, the time resolution in an energy model is hourly, like in the following figure where we have a 6-hour energy system:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Hourly Time Resolution)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Therefore, for this simple example, we can determine the number of constraints and variables in the optimization problem:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Number of variables: 42 since we have six connections among assets (i.e., 6 flows x 6 hours = 36 variables) and one storage asset (i.e., 1 storage level x 6 h = 6 variables)\nNumber of constraints: 72, which are:\n24 from the maximum output limit of the assets that produce, convert, or discharge energy (i.e., H2, wind, ccgt, and phs) for each hour (i.e., 4 assets x 6 h = 24 constraints)\n6 from the maximum input limit of the storage or charging limit for the phs\n6 from the maximum storage level limit for the phs\n12 from the import and export limits for the transmission line between the balance hub and the demand\n24 from the energy balance on the consumer, hub, conversion, and storage assets (i.e., demand, balance, ccgt, and phs) for each hour (i.e., 4 assets x 6 h = 24 constraints)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Depending on the input data and the level of detail you want to model, hourly resolution in all the variables might not be necessary. TulipaEnergyModel.jl can have different time resolutions for each asset and flow to simplify the optimization problem and approximate hourly representation. This feature is useful for large-scale energy systems that involve multiple sectors, as detailed granularity is not always necessary due to the unique temporal dynamics of each sector. For instance, we can use hourly resolution for the electricity sector and six-hour resolution for the hydrogen sector. We can couple multiple sectors, each with its own temporal resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's explore the flexibility of time resolution with a few examples.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The following table shows the user input data for the definition of asset time resolution. Please note that the values presented in this example are just for illustrative purposes and do not represent a realistic case.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_asset_file = \"../../test/inputs/Variable Resolution/assets-rep-periods-partitions.csv\" # hide\nassets = CSV.read(input_asset_file, DataFrame, header = 1) # hide\nassets = assets[assets.asset .!= \"wind\", :] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The table shows that the H2 producer and the phs storage have a uniform definition of 6 hours. This definition means we want to represent the H2 production profile and the storage level of the phs every six hours.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The same time resolution can be specified for the flows, for example (again, the values are for illustrative purposes and do not represent a realistic case):","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"input_flow_file = \"../../test/inputs/Variable Resolution/flows-rep-periods-partitions.csv\" # hide\nflows_partitions = CSV.read(input_flow_file, DataFrame, header = 1) # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The table shows a uniform definition for the flow from the hydrogen producer (H2) to the conversion asset (ccgt) of 6 hours, from the wind producer (wind) to the storage (phs) of 3 hours, and from the balance hub (balance) to the consumer (demand) of 3 hours, too. In addition, the flow from the wind producer (wind) to the balance hub (balance) is defined using the math specification of 1x2+1x4, meaning that there are two time blocks, one of two hours (i.e., 1:2) and another of four hours (i.e., 3:6). Finally, the flow from the storage (phs) to the balance hub (balance) is defined using the math specification of 1x4+1x2, meaning that there are two time blocks, one of four hours (i.e., 1:4) and another of two hours (i.e., 5:6).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The following figure illustrates these definitions on the example system.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Variable Time Resolution)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"So, let's recap:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The hydrogen producer (H2) is in a 6-hour resolution represented by the range 1:6, meaning that the balance of the hydrogen produced is for every 6 hours.\nThe flow from the hydrogen producer to the ccgt power plant (H2,ccgt) is also in a 6-hour resolution 1:6.\nThe flow from the ccgt power plant to the balance hub (ccgt, balance) has hourly resolution [1,2,3,4,5,6].\nThe ccgt is a conversion plant that takes hydrogen to produce electricity. Since both sectors have different time resolutions, the energy balance in the conversion asset is defined in the lowest resolution connecting to the asset. In this case, the energy balance in the ccgt is defined every 6 hours, i.e., in the range 1:6.\nThe wind producer has an hourly profile of electricity production, so the resolution of the asset is hourly.\nThe wind producer output has two connections, one to the balance hub and the other to the pumped-hydro storage (phs) with different resolutions:\nThe flow from the wind producer to the phs storage (wind, phs) has a uniform resolution of two blocks from hours 1 to 3 (i.e., 1:3) and from hours 4 to 6 (i.e., 4:6).\nThe flow from the wind producer to the balance hub (wind, balance) has a variable resolution of two blocks, too, but from hours 1 to 2 (i.e., 1:2) and from hours 3 to 6 (i.e., 3:6).\nThe phs is in a 6-hour resolution represented by the range 1:6, meaning the storage balance is determined every 6 hours.\nThe flow from the phs to the balance (phs, balance) represents the discharge of the phs. This flow has a variable resolution of two blocks from hours 1 to 4 (i.e., 1:4) and from hours 5 to 6 (i.e., 5:6), which differs from the one defined for the charging flow from the wind asset.\nThe demand consumption has hourly input data with one connection to the balance hub:\nThe flow from the balance hub to the demand (balance, demand) has a uniform resolution of 3 hours; therefore, it has two blocks, one from hours 1 to 3 (i.e., 1:3) and the other from hours 4 to 6 (i.e., 4:6).\nThe balance hub integrates all the different assets with their different resolutions. The lowest resolution of all connections determines the balance equation for this asset. Therefore, the resulting resolution is into two blocks, one from hours 1 to 4 (i.e., 1:4) and the other from hours 5 to 6 (i.e., 5:6).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"tip: Fully flexible temporal resolution\nThis example demonstrates that different time resolutions can be assigned to each asset and flow in the model. Furthermore, the resolutions do not need to be multiples of one another or evenly distributed and they can vary throughout the time horizon.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The complete input data for this example can be found in the variable resolution example.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Due to the flexible resolution, we must explicitly state how the constraints are constructed. For each constraint, three things need to be considered:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Whether it is type power or type energy.\ntype power: highest resolution\ntype energy: lowest resolution (multiplied by durations)\nHow the resolution is determined (regardless of whether it is highest or lowest): the incoming flows, the outgoing flows, or a combination of both.\nHow the related parameters are treated. We use two methods of aggregation, sum or mean.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Below is the table outlining the details for each type of constraint.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"tip: Before reading the table consider this:\nTo calculte the resolution of the constraints we use the min function to determine which is the highest resolution in the constraint, and the max function to determine the lowest resolution in the constraint. For example, the consumer balance is defined as power type, and it involves the inputs and outputs, then the constraint resolution must be the minimum resolution among them to ensure it is on the highest resolution. Then, if you have an input of 1h resolution and an output of 2h resolution; then the resolution of the constraint must be 1h (i.e., min(1h,2h)).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Name Variables involved Profile involved Constraint type Resolution of the constraints Profile aggregation\nConsumer Balance inputs, outputs demand power min(incoming flows, outgoing flows) mean\nStorage Balance inputs, outputs, storage level inflows energy max(asset, min(incoming flows, outgoing flows)) sum\nHub Balance inputs, outputs - power min(incoming flows, outgoing flows) -\nConversion Balance inputs, outputs [1] - energy max(incoming flows, outgoing flows) -\nProducers Capacity Constraints outputs availability power min(outgoing flows) mean\nStorage Capacity Constraints (outgoing) outputs - power min(outgoing flows) -\nConversion Capacity Constraints (outgoing) outputs - power min(outgoing flows) -\nConversion Capacity Constraints (incoming) inputs - power min(incoming flows) -\nStorage Capacity Constraints (incoming) inputs - power min(incoming flows) -\nTransport Capacity Constraints (upper bounds) flow availability power if it connects two hubs or demands then max(hub a,hub b), otherwise its own mean\nTransport Capacity Constraints (lower bounds) flow availability power if it connects two hubs or demands then max(hub a,hub b), otherwise its own mean\nMaximum Energy Limits (outgoing) outputs max_energy energy Determine by timeframe partitions. The default value is for each period in the timeframe sum\nMinimum Energy Limits (outgoing) outputs min_energy energy Determine by timeframe partitions. The default value is for each period in the timeframe sum\nMaximum Output Flow with Unit Commitment outputs, units_on availability power min(outgoing flows, units_on) mean\nMinimum Output Flow with Unit Commitment outputs, units_on availability power min(outgoing flows, units_on) mean\nMaximum Ramp Up Flow with Unit Commitment outputs, units_on availability power min(outgoing flows, units_on) mean\nMaximum Ramp Down Flow with Unit Commitment outputs, units_on availability power min(outgoing flows, units_on) mean\nMaximum Ramp Up Flow without Unit Commitment outputs availability power min(outgoing flows) mean\nMaximum Ramp Down Flow without Unit Commitment outputs availability power min(outgoing flows) mean\nDC-OPF Constraint flow, electricity_angle - power min(neighboring assets, flow) -\nFlows relationships flow 1, flow 2 - energy max(flow1, flow2) -","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"[1]: Only inputs or outputs with conversion coefficient geq 0 are considered to determine the resolution of the conversion balance constraint.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For this basic example, we can describe the balance and capacity constraints in the model. For the sake of simplicity, we consider only the rep-period constraints, the representative period index is dropped from the equations, and there are no investment variables in the equations.","category":"page"},{"location":"30-concepts/#Energy-Balance-Constraints","page":"Concepts","title":"Energy Balance Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In the following sections, we lay out all the balance constraints of this example.","category":"page"},{"location":"30-concepts/#Storage-Balance","page":"Concepts","title":"Storage Balance","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"As shown in the table, the resolution of the storage balance is energy, which is calculated by max(asset, min(incoming flows, outgoing flows)). The resolutions of the incoming and outgoing flows of the storage are 1:3, 4:6, 1:4, and 5:6, resulting in a minimum resolution of 2. The resolution of the storage is 6. Then, max(asset, min(incoming flows, outgoing flows)) becomes max(6, min(3, (4, 2))) which results in 6, and thus this balance is for every 6 hours. The charging and discharging flows are multiplied by their durations to account for the energy in the range 1:6.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textstorage_balance_textphs16 \n qquad v^textrep-period-storage_textphs16 = 3 cdot p^texteff_(textwindtextphs) cdot v^textflow_(textwindtextphs)13 + 3 cdot p^texteff_(textwindtextphs) cdot v^textflow_(textwindtextphs)46 \n qquad quad - frac4p^texteff_(textphstextbalance) cdot v^textflow_(textphstextbalance)14 - frac2p^texteff_(textphstextbalance) cdot v^textflow_(textphstextbalance)56 \nendaligned","category":"page"},{"location":"30-concepts/#Consumer-Balance","page":"Concepts","title":"Consumer Balance","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The flows coming from the balancing hub are defined every 3 hours. Then, min(incoming flows, outgoing flows) becomes min(3, -) = 3, and thus balanced every 3 hours. The input demand is aggregated as the mean of the hourly values in the input data.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textconsumer_balance_textdemand13 \n qquad v^textflow_(textbalancetextdemand)13 = p^textpeak demand_textdemand cdot fracsum_b=1^3 p^textdemand profile_textdemandb3 \n textconsumer_balance_textdemand46 \n qquad v^textflow_(textbalancetextdemand)46 = p^textpeak demand_textdemand cdot fracsum_b=4^6 p^textdemand profile_textdemandb3 \nendaligned","category":"page"},{"location":"30-concepts/#Hub-Balance","page":"Concepts","title":"Hub Balance","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The hub balance is quite interesting because it integrates several flow resolutions. Remember that we didn't define any specific time resolution for this asset. Therefore, the highest resolution of all incoming and outgoing flows in the horizon implies that the hub balance must be imposed for all 6 blocks since min(incoming flows, outgoing flows) becomes min(1,2,3,4) = 1","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n texthub_balance_textbalance11 \n qquad v^textflow_(textbalancetextdemand)13 = v^textflow_(textccgttextbalance) 11 + v^textflow_(textwindtextbalance)12 + v^textflow_(textphstextbalance)14 \n texthub_balance_textbalance22 \n qquad v^textflow_(textbalancetextdemand)13 = v^textflow_(textccgttextbalance) 22 + v^textflow_(textwindtextbalance)12 + v^textflow_(textphstextbalance)14 \n texthub_balance_textbalance33 \n qquad v^textflow_(textbalancetextdemand)13 = v^textflow_(textccgttextbalance) 33 + v^textflow_(textwindtextbalance)36 + v^textflow_(textphstextbalance)14 \n texthub_balance_textbalance44 \n qquad v^textflow_(textbalancetextdemand)46 = v^textflow_(textccgttextbalance) 44 + v^textflow_(textwindtextbalance)36 + v^textflow_(textphstextbalance)14\n texthub_balance_textbalance55 \n qquad v^textflow_(textbalancetextdemand)46 = v^textflow_(textccgttextbalance) 55 + v^textflow_(textwindtextbalance)36 + v^textflow_(textphstextbalance)56 \n texthub_balance_textbalance66 \n qquad v^textflow_(textbalancetextdemand)46 = v^textflow_(textccgttextbalance) 66 + v^textflow_(textwindtextbalance)36 + v^textflow_(textphstextbalance)56 \nendaligned","category":"page"},{"location":"30-concepts/#Conversion-Balance","page":"Concepts","title":"Conversion Balance","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The flows connected to the CCGT conversion unit have different resolutions, too. In this case, the hydrogen imposes the lowest resolution; therefore, the energy balance in this asset is also every 6 hours.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textconversion_balance_textccgt16 \n qquad 6 cdot p^texteff_(textH2textccgt) cdot v^textflow_(textH2textccgt)16 = frac1p^texteff_(textccgttextbalance) sum_b=1^6 v^textflow_(textccgttextbalance)b  \nendaligned","category":"page"},{"location":"30-concepts/#Capacity-Constraints","page":"Concepts","title":"Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"All capacity constraints are defined in the highest resolution to guarantee that the flows are below the limits of each asset capacity.","category":"page"},{"location":"30-concepts/#Storage-Capacity-Constraints","page":"Concepts","title":"Storage Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Since the storage unit only has one input and output, the capacity limit constraints are in the same resolution as the individual flows. Therefore, the constraints for the outputs of the storage (i.e., discharging capacity limit) are:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_output_flows_limit_textphs14 \n qquad v^textflow_(textphstextbalance)14 leq p^textinit capacity_textphs \n textmax_output_flows_limit_textphs56 \n qquad v^textflow_(textphstextbalance)56 leq p^textinit capacity_textphs \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"And the constraints for the inputs of the storage (i.e., charging capacity limit) are:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_input_flows_limit_textphs13 \n qquad v^textflow_(textwindtextphs)13 leq p^textinit capacity_textphs \n textmax_input_flows_limit_textphs46 \n qquad v^textflow_(textwindtextphs)46 leq p^textinit capacity_textphs \nendaligned","category":"page"},{"location":"30-concepts/#Conversion-Capacity-Constraints","page":"Concepts","title":"Conversion Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Similarly, each outflow is limited to the ccgt capacity for the conversion unit.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_output_flows_limit_textccgtb \n qquad v^textflow_(textccgttextbalance)b leq p^textinit capacity_textccgt quad forall b in 16 \nendaligned","category":"page"},{"location":"30-concepts/#Producer-Capacity-Constraints","page":"Concepts","title":"Producer Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The wind producer asset is interesting because the output flows are in different resolutions, i.e., 1:2, 3:6, 1:3, and 4:6. The highest resolution is 1:2, 3, and 4:6. Therefore, the constraints are as follows:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_output_flows_limit_textwind12 \n qquad v^textflow_(textwindtextbalance)12 + v^textflow_(textwindtextphs)13 leq fracp^textinit capacity_textwind2 cdot sum_b=1^2 p^textavailability profile_textwindb \n textmax_output_flows_limit_textwind3 \n qquad v^textflow_(textwindtextbalance)36 + v^textflow_(textwindtextphs)13 leq p^textinit capacity_textwind cdot p^textavailability profile_textwind3 \n textmax_output_flows_limit_textwind46 \n qquad v^textflow_(textwindtextbalance)36 + v^textflow_(textwindtextphs)46 leq fracp^textinit capacity_textwind3 cdot sum_b=4^6 p^textavailability profile_textwindb \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Since the flow variables v^textflow_(textwind textbalance)12 and v^textflow_(textwind textbalance)13 represent power, the first constraint sets the upper bound of the power for both timestep 1 and 2, by assuming an average capacity across these two timesteps. The same applies to the other two constraints.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The hydrogen (H2) producer capacity limit is straightforward, since both the asset and the flow definitions are in the same time resolution:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_output_flows_limit_textH216 \n qquad v^textflow_(textH2textccgt)16 leq p^textinit capacity_textH2 cdot p^textavailability profile_textH216 \nendaligned","category":"page"},{"location":"30-concepts/#Transport-Capacity-Constraints","page":"Concepts","title":"Transport Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For the connection from the hub to the demand, there are associated transmission capacity constraints, which are in the same resolution as the flow:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_transport_flows_limit_(textbalancetextdemand)13 \n qquad v^textflow_(textbalancetextdemand)13 leq p^textinit export capacity_(textbalancetextdemand) \n textmax_transport_flows_limit_(textbalancetextdemand)46 \n qquad v^textflow_(textbalancetextdemand)46 leq p^textinit export capacity_(textbalancetextdemand) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmin_transport_flows_limit_(textbalancetextdemand)13 \n qquad v^textflow_(textbalancetextdemand)13 geq - p^textinit import capacity_(textbalancetextdemand) \n textmin_transport_flows_limit_(textbalancetextdemand)46 \n qquad v^textflow_(textbalancetextdemand)46 geq - p^textinit import capacity_(textbalancetextdemand) \nendaligned","category":"page"},{"location":"30-concepts/#Storage-Level-limits","page":"Concepts","title":"Storage Level limits","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Since the system has a storage asset, we must limit the maximum storage level. The phs time resolution is defined for every 6 hours, so we only have one constraint.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textmax_storage_level_limit_textphs16 \n qquad v^textrep-period-storage_textphs16 leq p^textinit storage capacity_textphs\nendaligned","category":"page"},{"location":"30-concepts/#comparison","page":"Concepts","title":"Comparison of Different Modeling Approaches","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"This section quantifies the advantages of the flexible connection and flexible time resolution in the TulipaEnergyModel.jl modeling approach. So, let us consider three different approaches based on the same example:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Classic approach with hourly resolution: This approach needs an extra asset, node, to create the hybrid operation of the phs and wind assets.\nFlexible connection with hourly resolution: This approach uses the flexible connection to represent the hybrid operation of the phs and wind assets.\nFlexible connection and flexible time: This approach uses both features, the flexible connection and the flexible time resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"tip: Tip\nThe flexibility of TulipaEnergyModel.jl allows any of these three modeling approaches.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The table below shows the constraints and variables for each approach over a 6-hour horizon. These results show the potential of flexible connections and time resolution for reducing the size of the optimization model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Modeling approach Nº Variables Nº Constraints Objective Function\nClassic approach with hourly resolution 48 84 28.4365\nFlexible connection with hourly resolution 42 72 28.4365\nFlexible connection and time resolution 16 29 28.4587","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"By comparing the classic approach with the other methods, we can analyze their differences:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The flexible connection with hourly resolution reduces 6 variables (125) and 12 constraints (approx 14). Notice that we include the 6 extra constraints related to not allowing charging from the grid, although these constraints can also be modeled as bounds. Finally, the objective function value is the same, since we use an hourly time resolution in both cases.\nThe combination of features reduces 32 variables (approx 67) and 55 constraints (approx 65) with an approximation error of approx 0073.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The level of reduction and approximation error will depend on the case study. Some cases that would benefit from this feature include:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Coupling different energy sectors with various dynamics. For instance, methane, hydrogen, and heat sectors can be represented in energy models with lower resolutions (e.g., 4, 6, or 12h) than the electricity sector, usually modeled in higher resolutions (e.g., 1h, 30 min).\nHaving high resolutions for all assets in a large-scale case study may not be necessary. For example, if analyzing a European case study focusing on a specific country like The Netherlands, hourly details for distant countries (such as Portugal and Spain) may not be required. However, one would still want to consider their effect on The Netherlands without causing too much computational burden. In such cases, flexible time resolution can maintain hourly details in the focus country, while reducing the detail in distant countries by increasing their resolution (to two hours or more). This reduction allows a broader scope without over-burdening computation.","category":"page"},{"location":"30-concepts/#flex-time-res-uc","page":"Concepts","title":"Flexible Time Resolution in the Unit Commitment and Ramping Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In the previous section, we have seen how the flexible temporal resolution is handled for the model's flow capacity and balance constraints. Here, we show how flexible time resolution is applied when considering the model's unit commitment and ramping constraints. Let's consider the example in the folder test/inputs/UC-ramping to explain how all these constraints are created in TulipaEnergyModel.jl when having the flexible time resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-case-study)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The example demonstrates various assets that supply demand. Each asset has different input data files, which activates different sets of constraints based on the method. For example, the gas producer has ramping constraints but not unit commitment constraints, while the ocgt conversion has unit commitment constraints but not ramping constraints. Lastly, the ccgt and smr assets both have unit commitment and ramping constraints. Moreover, ccgt, wind, solar, and ocgt are investable, meaning that the investment variable will only appear on the constraints related to those assets.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_dir = \"../../test/inputs/UC-ramping\" # hide\nassets_data = CSV.read(joinpath(input_dir, \"asset-both.csv\"), DataFrame) # hide\ngraph_assets = CSV.read(joinpath(input_dir, \"asset.csv\"), DataFrame) # hide\nasset_milestone = CSV.read(joinpath(input_dir, \"asset-milestone.csv\"), DataFrame) # hide\nassets = leftjoin(graph_assets, assets_data, on=:asset) # hide\nassets = leftjoin(assets, asset_milestone, on=[:asset, :milestone_year]) # hide\nfiltered_assets = assets[assets.type .== \"producer\" .|| assets.type .== \"conversion\", [\"asset\", \"type\", \"capacity\", \"initial_units\", \"investable\", \"unit_commitment\",  \"ramping\", \"max_ramp_up\", \"max_ramp_down\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The assets-rep-periods-partitions file defines the time resolution for the assets in the partition column. For instance, here we can see that the time resolutions are 3h for the ccgt and 6h for the smr. These values mean that the unit commitment variables (e.g., units_on) in the model have three and six hours resolution, respectively.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"assets_partitions_data = CSV.read(joinpath(input_dir, \"assets-rep-periods-partitions.csv\"), DataFrame, header = 1) # hide\nfiltered_assets_partitions = assets_partitions_data[!, [\"asset\", \"specification\", \"partition\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The flows-rep-periods-partitions file defines the time resolution for the flows. In this example, we have that the flows from the gas asset to the ccgt and from the ccgt asset to the demand are in a 2h resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"flows_partitions_data = CSV.read(joinpath(input_dir, \"flows-rep-periods-partitions.csv\"), DataFrame, header = 1) # hide\nfiltered_flows_partitions = flows_partitions_data[!, [\"from_asset\", \"to_asset\", \"specification\", \"partition\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The default value for the assets and flows partitions is 1 hour. This means that assets and flows not in the previous tables are considered on an hourly basis in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"warning: Not every combination of resolutions is viable\nIt's not recommended to set up the input data partitions in such a way that the flow variables have a lower resolution than the units_on. This is because doing so will result in constraints that fix the value of the units_on in the timestep block where the flow is defined, leading to unnecessary extra variable constraints in the model. For instance, if the units_on are hourly and the flow is every two hours, then a non-zero flow in the timestep block 1:2 will require the units_on in timestep blocks 1:1 and 2:2 to be the same and equal to one. Therefore, the time resolution of the units_on should always be lower than or equal to the resolution of the flow in the asset.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Remember that the section mathematical formulation shows the unit commitment and ramping constraints in the model considering an uniform time resolution as a reference.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"With this information, we can analyze the constraints in each of the following cases:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Ramping in assets with multiple outputs\nUnit commitment in assets with constant time resolution\nUnit commitment and ramping in assets with flexible time resolution that are multiples of each other\nUnit commitment and ramping in assets with flexible time resolution that are not multiples of each other","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"We will analyze each case in the following sections, considering the constraints resolution defined in the summary table in the flexible time resolution section. For the sake of simplicity, we only show the asset a and timestep block b_k index and the constraints as they appear in the .lp file of the example, i.e., with all the coefficients and RHS values calculated from the input parameters. The .lp file can be exported using the keyword argument model_file_name = \"model.lp\" in the run_scenario function.","category":"page"},{"location":"30-concepts/#Ramping-in-Assets-with-Multiple-Outputs","page":"Concepts","title":"Ramping in Assets with Multiple Outputs","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In the case of the gas asset, there are two output flows above the minimum operating point with different time resolutions. The ramping constraints follow the highest time resolution of the two flows at each timestep block. Since the highest resolution is always defined by the hourly output of the v^textflow_(textgasocgt)b_k, the ramping constraints are also hourly. The figure below illustrates this situation.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-gas-asset)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now take a look at the resulting constraints in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_ramp_up(gas): The first constraint considers the ramping up of output flows of the gas asset from the first hour to the second (b_k = 22 to b_k = 11). Note that since the v^textflow_(textgasccgt)b_k is defined in in blocks of 2 hours, we only need to consider the difference of the v^textflow_(textgasocgt)b_k variable in this constraint. However, the second constraint takes the difference between the output flows from b_k = 33 to b_k = 22. For this constraint, we need to consider the difference in both v^textflow_(textgasocgt)b_k and v^textflow_(textgasccgt)b_k.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Info\nThe duration parameter in the right hand side (RHS) of this constraint, textRHS = p^textcapacity_textgas cdot p^textmax ramp up_textgas cdot p^textduration_b_k, is defined by the flow duration with the highest resolution, i.e., one hour, which is the duration of the v^textflow_(textgasocgt)b_k. We need to multiply by duration since the ramp input values are given as rates, i.e., p.u./h or p.u./min, so the RHS in the constraint must be multiplied by the duration to match the flow units. So, using the data for this example we have: textRHS = 1800 textMW cdot 083 textpuh cdot 1 texth = 1494 textMW","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 22 - v^textflow_(textgasocgt)11 + v^textflow_(textgasocgt)22 leq 1494 \n b_k = 33 - v^textflow_(textgasocgt)22 + v^textflow_(textgasocgt)33 - v^textflow_(textgasccgt)12 + v^textflow_(textgasccgt)34 leq 1494 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For the maximum ramp down we have similiar constraints as the ones shown above.","category":"page"},{"location":"30-concepts/#Unit-Commitment-in-Assets-with-Constant-Time-Resolution","page":"Concepts","title":"Unit Commitment in Assets with Constant Time Resolution","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The ocgt asset includes both the v^textflow_(textocgtdemand)b_k and the asset time resolution, which defines the resolution of the units_on variable, with a default setting of one hour. As a result, the unit commitment constraints are also set on an hourly basis. This is the conventional method for representing these types of constraints in power system models. The figure below illustrates this situation.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-ocgt-asset)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now take a look at the resulting constraints in the model. Because everything is based on an hourly timestep, the equations are simple and easy to understand.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"limit_units_on(ocgt): The upper bound of the units_on is the investment variable of the asset","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 11 v^textunits on_textocgt11 leq v^textinv_textocgt \n b_k = 22 v^textunits on_textocgt22 leq v^textinv_textocgt \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"min_output_flow(ocgt): The minimum operating point is 10 MW, so the asset must produce an output flow greater than this value when the unit is online.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 11 v^textflow_(textocgtdemand)11 geq 10 cdot v^textunits on_textocgt11  \n b_k = 22 v^textflow_(textocgtdemand)22 geq 10 cdot v^textunits on_textocgt22  \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_output_flow(ocgt): The capacity is 100 MW, so the asset must produce an output flow lower than this value when the unit is online.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 11 v^textflow_(textocgtdemand)11 leq 100 cdot v^textunits on_textocgt11 \n b_k = 22 v^textflow_(textocgtdemand)22 leq 100 cdot v^textunits on_textocgt22 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For the maximum ramp down we have similiar constraints as the ones shown above.","category":"page"},{"location":"30-concepts/#Unit-Commitment-and-Ramping-in-Assets-with-Flexible-Time-Resolution-that-are-Multiples-of-Each-Other","page":"Concepts","title":"Unit Commitment and Ramping in Assets with Flexible Time Resolution that are Multiples of Each Other","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this case, the smr asset has an output v^textflow_(textsmrdemand)b_k in a hourly basis, but its time resolution (i.e., partition) is every six hours. Therefore, the unist_on variables are defined in timestep block of every six hours. As a result, the unit commitment and ramping constraints are set on highest resolution of both, i.e., the hourly resolution of the v^textflow_(textsmrdemand)b_k. The figure below illustrates this situation.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-smr-asset)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now take a look at the resulting constraints in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"limit_units_on(smr): The units_on variables are defined every 6h; therefore, the upper bound of the variable is also every 6h. In addition, the smr is not investable and has one existing unit that limits the commitment variables.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 16  v^textunits on_textsmr16  leq 1 \n b_k = 712 v^textunits on_textsmr712 leq 1 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"min_output_flow(smr): The minimum operating point is 150 MW, so the asset must produce an output flow greater than this value when the unit is online. Since the units_on variables are defined every 6h, the first six constraints show that the minimum operating point is multiplied by the variable in block 1:6. The next six constraints are multiplied by the units_on in block 7:12, and so on.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 11 v^textflow_(textsmrdemand)11 geq 150 cdot v^textunits on_textsmr16 \n b_k = 22 v^textflow_(textsmrdemand)22 geq 150 cdot v^textunits on_textsmr16 \n  \n b_k = 66 v^textflow_(textsmrdemand)66 geq 150 cdot v^textunits on_textsmr16  \n b_k = 77 v^textflow_(textsmrdemand)77 geq 150 cdot v^textunits on_textsmr712 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_output_flow(smr): The capacity is 200 MW, so the asset must produce an output flow lower than this value when the unit is online. Similiar to the minimum operating point constraint, here the units_on for the timestep block 1:6 are used in the first six constraints, the units_on for the timestep block 7:12 are used in the next six constraints, and so on.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 11 v^textflow_(textsmrdemand)11 leq 200 cdot v^textunits on_textsmr16  \n b_k = 22 v^textflow_(textsmrdemand)22 leq 200 cdot v^textunits on_textsmr16  \n  \n b_k = 66 v^textflow_(textsmrdemand)66 leq 200 cdot v^textunits on_textsmr16  \n b_k = 77 v^textflow_(textsmrdemand)77 leq 200 cdot v^textunits on_textsmr712 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_ramp_up(smr): The ramping capacity is 20MW, so the change in the output flow above the minimum operating point needs to be below that value when the asset is online. For constraints from 2:2 to 6:6, the units_on variable is the same, i.e., units_on at timestep block 1:6. The ramping constraint at timestep block 7:7 shows the units_on from the timestep block 1:6 and 7:12 since the change in the flow includes both variables. Note that if the units_on variable is zero in the timestep block 1:6, then the ramping constraint at timestep block 7:7 allows the asset to go from zero flow to the minimum operating point plus the ramping capacity (i.e., 150 + 20 = 170).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 22 - v^textflow_(textsmrdemand)11 + v^textflow_(textsmrdemand)22 leq 20 cdot v^textunits on_textsmr16 \n b_k = 33 - v^textflow_(textsmrdemand)22 + v^textflow_(textsmrdemand)33 leq 20 cdot v^textunits on_textsmr16 \n  \n b_k = 66 - v^textflow_(textsmrdemand)55 + v^textflow_(textsmrdemand)66 leq 20 cdot v^textunits on_textsmr16 \n b_k = 77 - v^textflow_(textsmrdemand)66 + v^textflow_(textsmrdemand)77 leq - 150 cdot v^textunits on_textsmr16 + 170 cdot v^textunits on_textsmr712 \n b_k = 88 - v^textflow_(textsmrdemand)77 + v^textflow_(textsmrdemand)88 leq 20 cdot v^textunits on_textsmr712 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For the maximum ramp down we have similiar constraints as the ones shown above.","category":"page"},{"location":"30-concepts/#Unit-Commitment-and-Ramping-in-Assets-with-Flexible-Time-Resolution-that-are-NOT-Multiples-of-Each-Other","page":"Concepts","title":"Unit Commitment and Ramping in Assets with Flexible Time Resolution that are NOT Multiples of Each Other","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this case, the ccgt asset has an output v^textflow_(textccgtdemand)b_k on a two-hour basis, but its time resolution (i.e., partition) is every three hours. Therefore, the unist_on variables are defined in a timestep block every three hours. This setup means that the flow and unit commitment variables are not multiples of each other. As a result, the unit commitment and ramping constraints are defined on the highest resolution, meaning that we also need the intersections of both resolutions. The figure below illustrates this situation.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-ccgt-asset)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now take a look at the resulting constraints in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"limit_units_on(ccgt): The units_on variables are defined every 3h; therefore, the upper bound of the variable is also every 3h. In addition, the ccgt is investable and has one existing unit that limits the commitment variables.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n  b_k = 13  v^textunits on_textccgt13 leq 1 + v^textinv_textccgt \n  b_k = 46  v^textunits on_textccgt46 leq 1 + v^textinv_textccgt \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"min_output_flow(ccgt): The minimum operating point is 50 MW, so the asset must produce an output flow greater than this value when the unit is online. Here, we can see the impact of the constraints of having different temporal resolutions that are not multiples of each other. For instance, the constraint is defined for all the intersections, so 1:2, 3:3, 4:4, 5:6, etc., to ensure that the minimum operating point is correctly defined considering all the timestep blocks of the flow and the units_on variables.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 12 v^textflow_(textccgtdemand)12 geq 50 cdot v^textunits on_textccgt13 \n b_k = 33 v^textflow_(textccgtdemand)34 geq 50 cdot v^textunits on_textccgt13 \n b_k = 44 v^textflow_(textccgtdemand)34 geq 50 cdot v^textunits on_textccgt46 \n b_k = 56 v^textflow_(textccgtdemand)56 geq 50 cdot v^textunits on_textccgt46 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_output_flows(ccgt): The capacity is 200 MW, so the asset must produce an output flow lower than this value when the unit is online. The situation is similar as in the minimum operating point constraint, we have constraints for all the intersections of the resolutions to ensure the correct definition of the maximum capacity.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 12 v^textflow_(textccgtdemand)12 leq 200 cdot v^textunits on_textccgt13 \n b_k = 33 v^textflow_(textccgtdemand)34 leq 200 cdot v^textunits on_textccgt13 \n b_k = 44 v^textflow_(textccgtdemand)34 leq 200 cdot v^textunits on_textccgt46 \n b_k = 56 v^textflow_(textccgtdemand)56 leq 200 cdot v^textunits on_textccgt46 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"max_ramp_up(ccgt): The ramping capacity is 120MW, so the change in the output flow above the minimum operating point needs to be below that value when the asset is online. When the time resolutions of the flow and units_on are not multiples of each other, we encounter some counterintuitive constraints. For example, consider the constraint at timestep block 4:4. This constraint only involves units_on variables because the flow above the minimum operating point at timestep block 4:4 differs from the previous timestep block 3:3 only in terms of the units_on variables. As a result, the ramping-up constraint establishes a relationship between the units_on variable at 1:3 and 4:6. This means that if the unit is on at timestep 1:3, then it must also be on at timestep 4:6. However, this is redundant because there is already a flow variable defined for 3:4 that ensures this, thanks to the minimum operating point and maximum capacity constraints. Therefore, although this constraint is not incorrect, it is unnecessary due to the flexible time resolutions that are not multiples of each other.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n b_k = 33 - v^textflow_(textccgtdemand)12 + v^textflow_(textccgtdemand)34 leq 120 cdot v^textunits on_textccgt13 \n b_k = 44 0 leq - 50 cdot v^textunits on_textccgt13 + 170 cdot v^textunits on_textccgt46 \n b_k = 56 - v^textflow_(textccgtdemand)34 + v^textflow_(textccgtdemand)56 leq 120 cdot v^textunits on_textccgt46 \n b_k = 78 - v^textflow_(textccgtdemand)56 + v^textflow_(textccgtdemand)78 leq - 50 cdot v^textunits on_textccgt46 + 170 cdot v^textunits on_textccgt79 \n b_k = 99 - v^textflow_(textccgtdemand)78 + v^textflow_(textccgtdemand)910 leq 120 cdot v^textunits on_textccgt79 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For the maximum ramp down we have similiar constraints as the ones shown above.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"warning: Avoiding redundant constraints\nThe time resolutions of the unit commitment constraints do not have to be multiples of each other. However, using multiples of each other can help avoid extra redundant constraints.","category":"page"},{"location":"30-concepts/#Unit-Commitment-and-Ramping-Case-Study-Results","page":"Concepts","title":"Unit Commitment and Ramping Case Study Results","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now optimize the model for the data in the example test/inputs/UC-ramping and explore the results. The first result is the unit commitment of the assets with this method, i.e., ocgt, ccgt, and smr. One of the characteristics of having flexible time resolution on the unit commitment variables (e.g., units_on) is that it allows us to consider implicitly minimum up/down times in a simplified manner. For instance, the ccgt asset can only increase the number of units every 3h, and the smr can only start up again after 6h.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-results)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's now examine the hourly production balance in the results. We can see that the assets with a unit commitment method only produce electricity (e.g., flow to the demand asset) when they are on (units_on >= 1). In addition, the smr has a slow flow change due to its ramping limits.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: unit-commitment-balance)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this example, we demonstrated the use of unit commitment and ramping constraints with flexible time resolution in the model, and we illustrated what the results look like. The flexible time resolution applied to the unit commitment variables aids in minimizing the number of binary/integer variables in the model and simplifies the representation of the assets' minimum up and down times.","category":"page"},{"location":"30-concepts/#storage-modeling","page":"Concepts","title":"Storage Modeling","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Energy storage systems can be broadly classified into two categories: seasonal and non-seasonal storage. Seasonal storage refers to assets that can store energy for more extended periods, usually spanning months or even years. Examples of such assets include hydro reservoirs, hydrogen storage in salt caverns, or empty gas fields. On the other hand, non-seasonal storage refers to assets that can store energy only for a few hours, such as batteries or small pumped-hydro storage units.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Both storage categories can be represented in TulipaEnergyModel.jl using the representative periods approach:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Non-seasonal storage: When the storage capacity of an asset is lower than the total length of representative periods, like in the case of a battery with a storage capacity of 4 hours and representative periods of 24-hour timesteps, rep-period constraints should be applied.\nSeasonal storage: When the storage capacity of an asset is greater than the total length of representative periods, like in the case of a hydroplant with a storage capacity of a month and representative periods of 24-hour timesteps, over-clustered-year constraints should be applied.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The equations of rep-period and over-clustered-year constraints for energy storage are available in the mathematical formulation. An example is shown in the following section to explain these concepts. In addition, the section seasonal and non-seasonal storage setup shows how to set the parameters in the model to consider each type in the storage assets.","category":"page"},{"location":"30-concepts/#Example-to-Model-Seasonal-and-Non-seasonal-Storage","page":"Concepts","title":"Example to Model Seasonal and Non-seasonal Storage","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"We use the example in the folder test/inputs/Storage to explain how all these concepts come together in TulipaEnergyModel.jl.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's first look at this feature's most relevant input data in the input files. Here, we show only the storage assets and the appropriate columns for this example, but all the input data can be found in the previously mentioned folder.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_dir = \"../../test/inputs/Storage\" # hide\nassets_data = CSV.read(joinpath(input_dir, \"asset-both.csv\"), DataFrame) # hide\ngraph_assets = CSV.read(joinpath(input_dir, \"asset.csv\"), DataFrame) # hide\nassets = leftjoin(graph_assets, assets_data, on=:asset) # hide\nfiltered_assets = assets[assets.type .== \"storage\", [\"asset\", \"type\", \"capacity\", \"capacity_storage_energy\",  \"is_seasonal\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The is_seasonal parameter determines whether or not the storage asset uses the over-clustered-year constraints. The phs is the only storage asset with this type of constraint and over-clustered-year-storage level variable (i.e., v^textover-clustered-year-storage_textphsp), and has 100MW capacity and 4800MWh of storage capacity (i.e., 48h discharge duration). The battery will only consider rep-period constraints with rep-period-storage level variables (i.e., v^textrep-period-storage_textbatterykb_k), and has 10MW capacity with 20MWh of storage capacity (i.e., 2h discharge duration).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The rep-periods-data file has information on the representative periods in the example. We have three representative periods, each with 24 timesteps and hourly resolution, representing a day. The figure below shows the availability profile of the renewable energy sources in the example.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"rp_file = \"../../test/inputs/Storage/rep-periods-data.csv\" # hide\nrp = CSV.read(rp_file, DataFrame, header = 1) # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: availability-profiles)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The rep-periods-mapping relates each representative period with the periods in the timeframe. We have seven periods in this case, meaning the timeframe is a week. Each value in the file indicates the weight of each representative period in the timeframe period. Notice that each period is composed of a linear combination of the representative periods. For more details on obtaining the representative periods and the weights, please look at TulipaClustering.jl. For the sake of readability, we show here the information in the file in tabular form:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"map_file = \"../../test/inputs/Storage/rep-periods-mapping.csv\" # hide\nmap = CSV.read(map_file, DataFrame, header = 1) # hide\nunstacked_map = unstack(map, :period, :rep_period, :weight) # hide\nrename!(unstacked_map, [\"period\", \"k=1\", \"k=2\", \"k=3\"]) # hide\nunstacked_map[!,[\"k=1\", \"k=2\", \"k=3\"]] = convert.(Float64, unstacked_map[!,[\"k=1\", \"k=2\", \"k=3\"]]) # hide\nunstacked_map # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The file assets-timeframe-partitions has the information on how often we want to evaluate the over-clustered-year constraints that combine the information of the representative periods. In this example, the file is missing in the folder, meaning that the default of a uniform distribution of one period will be use in the model, see model parameters section. This assumption implies that the model will check the over-clustered-year-storage level every day of the week timeframe.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Info\nFor the sake of simplicity, we show how using three representative days can recover part of the chronological information of one week. The same method can be applied to more representative periods to analyze the seasonality across a year or longer timeframe.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Now let's solve the example and explore the results:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DuckDB, TulipaIO, TulipaEnergyModel\n\ninput_dir = \"../../test/inputs/Storage\" # hide\n# input_dir should be the path to the Storage example\nconnection = DBInterface.connect(DuckDB.DB)\nread_csv_folder(connection, input_dir; schemas = TulipaEnergyModel.schema_per_table_name)\nenergy_problem = run_scenario(connection)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Since the battery is not seasonal, it only has results for the rep-period-storage level of each representative period, as shown in the following figure:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Battery-rep-period-storage-level)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Since the phs is defined as seasonal, it has results for only the over-clustered-year-storage level. Since we defined the period partition as 1, we get results for each period (i.e., day). We can see that the over-clustered-year constraints in the model keep track of the storage level through the whole timeframe definition (i.e., week).","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: PHS-over-clustered-year-storage-level)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this example, we have demonstrated how to partially recover the chronological information of a storage asset with a longer discharge duration (such as 48 hours) than the representative period length (24 hours). This feature enables us to model both short- and long-term storage in TulipaEnergyModel.jl.","category":"page"},{"location":"30-concepts/#flex-time-res-dc-opf","page":"Concepts","title":"Flexible Time Resolution in the Direct Current Optimal Power Flow Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this section, we show how flexible time resolution is applied when considering the model's direct current optimal power flow (DC-OPF) constraint. Let's consider the example in the folder test/inputs/Power-flow to explain how this constraint is created in TulipaEnergyModel.jl when having the flexible time resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The following example demonstrates the impact of the DC-OPF constraints on system behavior. In this setup, demand can be met by two sources: ccgtand hub. The hub itself can receive energy from both ccgt and electricity imports. In the absence of power flow constraints, the model may choose to satisfy 100% of the demand directly via the ccgt to demand flow. However, when DC-OPF constraints are enforced, all three transport flows — ccgt to demand, ccgt to hub, and hub to demand must comply with the physical laws governing power flow. As a result, it becomes infeasible to supply the entire demand solely through the ccgt to demand path. Instead, the solution must account for the distribution of flows in accordance with the DC-OPF model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: power-flow-example)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The assets-rep-periods-partitions file defines the time resolution for the assets in the partition column. Here we set the time resolution to 8h for the ccgt, 4h for the demand, 2h for the hub, and 1h for the import.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_dir = \"../../test/inputs/Power-flow\" # hide\nassets_partitions_data = CSV.read(joinpath(input_dir, \"assets-rep-periods-partitions.csv\"), DataFrame, header = 1) # hide\nfiltered_assets_partitions = assets_partitions_data[!, [\"asset\", \"specification\", \"partition\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Do you still remember what resolution of the assets is used for?\nThe resolutions of the assets determine the resolution of the unit commitment variables (when UC constraints are applied), storage level variables, and electricity angle variables (when DC-OPF constraints are applied).\nIt is important to note that these resolutions do not dictate the resolution of the balance constraints. Instead, the resolution of balance constraints is derived from the rules outlined in the table under the section flexible time resolution.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The flows-rep-periods-partitions file defines the time resolution for the flows, as shown below.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_dir = \"../../test/inputs/Power-flow\" # hide\nflows_partitions_data = CSV.read(joinpath(input_dir, \"flows-rep-periods-partitions.csv\"), DataFrame, header = 1) # hide\nfiltered_flows_partitions = flows_partitions_data[!, [\"from_asset\", \"to_asset\", \"specification\", \"partition\"]] # hide","category":"page"},{"location":"30-concepts/#The-Core-Model","page":"Concepts","title":"The Core Model","text":"","category":"section"},{"location":"30-concepts/#DC-OPF-Constraints","page":"Concepts","title":"DC-OPF Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The DC-OPF constraint is applied to every transport flow that utilizes the DC-OPF method. The resolution at which this constraint is enforced is determined by the highest resolution among the flow itself and its adjacent (neighboring) assets. To illustrate how this works in practice, we now examine each relevant flow individually.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The resolution of the DC-OPF constraint for flow ccgt to hub is 2h:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textDC-OPF_(textccgt texthub)12 \n qquad v^textflow_(textccgttexthub)12 = fracp^textpower system basep^textreactance_textccgttexthub (v^textelectricity angle_textccgt18 - v^textelectricity angle_texthub12) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The resolution of the DC-OPF constraint for flow ccgt to demand is 4h:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textDC-OPF_(textccgt textdemand)14 \n qquad v^textflow_(textccgttextdemand)14 = fracp^textpower system basep^textreactance_textccgttextdemand (v^textelectricity angle_textccgt18 - v^textelectricity angle_textdemand14) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The resolution of the DC-OPF constraint for flow hub to demand is 2h:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textDC-OPF_(texthub textdemand)12 \n qquad v^textflow_(texthubtextdemand)12 = fracp^textpower system basep^textreactance_texthubtextdemand (v^textelectricity angle_texthub12 - v^textelectricity angle_textdemand14) \nendaligned","category":"page"},{"location":"30-concepts/#Consumer-Balance-Constraints","page":"Concepts","title":"Consumer Balance Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For demand, consumer balance applies. This constraint operates at the highest resolution among all incoming and outgoing flows connected to the asset. In this case, demand receives two incoming flows: ccgt to demand in 4h and hub to demand in 2h. As a result, the consumer balance is enforced in 2h resolution, which is the highest of the two.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textconsumer_balance_textdemand12 \n qquad v^textflow_(textccgttextdemand)14 + v^textflow_(texthubtextdemand)12 leq p^textpeak demand_textdemand cdot fracsum_b=1^2 p^textdemand profile_textdemandb2 \nendaligned","category":"page"},{"location":"30-concepts/#Hub-Balance-Constraints","page":"Concepts","title":"Hub Balance Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"For hub, hub balance applies. This constraint also operates at the highest resolution among all incoming and outgoing flows connected to the asset. In this case, hub receives two incoming flows: ccgt to hub in 2h and import to hub in 2h, and an outgoing flow hub to demand in 2h. As a result, the hub balance is enforced in 2h resolution, which is the highest of the three.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n texthub_balance_textdemand12 \n qquad v^textflow_(textccgttexthub)12 + v^textflow_(textimporttexthub)12 = v^textflow_(texthubtextdemand)12  \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The abovementioned constraints are functioning as intended, resulting in a feasible optimization problem.","category":"page"},{"location":"30-concepts/#Model-Feasibility-Issues","page":"Concepts","title":"Model Feasibility Issues","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Model feasibility can be compromised in two key ways:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Incorrect flow resolutions — If the temporal resolutions of flows are not aligned with those of their neighboring assets, or if they violate resolution consistency rules, the model may become infeasible or produce redundant variables.\nPoorly defined problem topology — If the graph structure (i.e., the set of assets and their connecting flows) is not well-constructed — such as having insufficient connectivity at key assets like hubs — the model may lack the necessary degrees of freedom to satisfy constraints, particularly under DC-OPF formulations.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Let's first elaborate on the first case.","category":"page"},{"location":"30-concepts/#Incorrect-Flow-Resolutions:-Why-Enforce-the-Flow-Resolution-This-Way?","page":"Concepts","title":"Incorrect Flow Resolutions: Why Enforce the Flow Resolution This Way?","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"This raises a valid question. To explore this further, let’s consider a scenario with an even higher resolution. Suppose we now set the resolution of the flow from ccgt to hub to 1h. According to the modeling rules, this means the DC-OPF constraint must also be enforced at 1h resolution, as it must match the highest resolution among the flow and its neighboring assets.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textDC-OPF_(textccgt texthub)11 \n qquad v^textflow_(textccgttexthub)11 = fracp^textpower system basep^textreactance_textccgttexthub (v^textelectricity angle_textccgt18 - v^textelectricity angle_texthub12) \n textDC-OPF_(textccgt texthub)22 \n qquad v^textflow_(textccgttexthub)22 = fracp^textpower system basep^textreactance_textccgttexthub (v^textelectricity angle_textccgt18 - v^textelectricity angle_texthub12) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Interestingly, in this setup, the right-hand sides (RHS) of the DC-OPF equations remain the same across time steps. This leads to the creation of two separate flow variables v^textflow_(textccgttexthub)11 and v^textflow_(textccgttexthub)22.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"However, since the RHS values are identical, one of these variables becomes redundant. This redundancy highlights a key modeling insight: not every combination of resolutions is viable or meaningful. Introducing unnecessarily high resolution without corresponding variation in the system can lead to inefficient formulations.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"warning: The flow resolution must be defined as the highest between the resolutions of its adjacent (neighboring) assets!\nHigher resolution can improve temporal accuracy but may lead to formulation inefficiencies, such as redundant variables or unnecessarily large problem sizes, as illustrated in the previous example.\nLower resolution, on the other hand, may result in an infeasible model if it fails to capture the necessary dynamics or violates resolution consistency rules (e.g., with neighboring assets or constraints).","category":"page"},{"location":"30-concepts/#Poorly-Defined-Problem-Topology:-Why-Include-Import?","page":"Concepts","title":"Poorly Defined Problem Topology: Why Include Import?","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"It is considered good modeling practice to connect the hub asset to more than two flows.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Without DC-OPF constraints, having only two flows connected to the hub is not ideal but still valid. In such cases, the hub simply acts as a passive energy transfer point.\nWith DC-OPF constraints, however, having only two flows connected to the hub (e.g., ccgt to hub and hub to demand, without import) becomes incorrect. Let's show the issue below.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Firstly of all, we list the hub balance and the two DC-OPF constraints for 1:2 and 3:4 as follows.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n texthub_balance_textdemand12 \n qquad v^textflow_(textccgttexthub)12 = v^textflow_(texthubtextdemand)12  \n texthub_balance_textdemand34 \n qquad v^textflow_(textccgttexthub)34 = v^textflow_(texthubtextdemand)34  \n textDC-OPF_(textccgt texthub)12 \n qquad v^textflow_(textccgttexthub)12 = fracp^textpower system basep^textreactance_textccgttexthub (v^textelectricity angle_textccgt18 - v^textelectricity angle_texthub12) \n textDC-OPF_(textccgt texthub)34 \n qquad v^textflow_(textccgttexthub)34 = fracp^textpower system basep^textreactance_textccgttexthub (v^textelectricity angle_textccgt18 - v^textelectricity angle_texthub34) \n textDC-OPF_(texthub textdemand)12 \n qquad v^textflow_(texthubtextdemand)12 = fracp^textpower system basep^textreactance_texthubtextdemand (v^textelectricity angle_texthub12 - v^textelectricity angle_textdemand14) \n textDC-OPF_(texthub textdemand)34 \n qquad v^textflow_(texthubtextdemand)34 = fracp^textpower system basep^textreactance_texthubtextdemand (v^textelectricity angle_texthub34 - v^textelectricity angle_textdemand14) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Next, we substitute the DC-OPF constraints into the hub balance. After some algebraic rearrangements, we obtain the following simplified expression:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n qquad v^textelectricity angle_texthub12 = v^textelectricity angle_texthub34\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Guess what? We have identified one redundant variable. Now, by examining the following two DC-OPF constraints more closely, we may uncover additional issues:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textDC-OPF_(texthub textdemand)12 \n qquad v^textflow_(texthubtextdemand)12 = fracp^textpower system basep^textreactance_texthubtextdemand (v^textelectricity angle_texthub12 - v^textelectricity angle_textdemand14) \n textDC-OPF_(texthub textdemand)34 \n qquad v^textflow_(texthubtextdemand)34 = fracp^textpower system basep^textreactance_texthubtextdemand (v^textelectricity angle_texthub34 - v^textelectricity angle_textdemand14) \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"We now actually have:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n qquad v^textflow_(texthubtextdemand)12 = v^textflow_(texthubtextdemand)34\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Leading to somewhere? Let's list the consumer balance:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textconsumer_balance_textdemand12 \n qquad v^textflow_(textccgttextdemand)14 + v^textflow_(texthubtextdemand)12 leq p^textpeak demand_textdemand cdot fracsum_b=1^2 p^textdemand profile_textdemandb2 \n textconsumer_balance_textdemand34 \n qquad v^textflow_(textccgttextdemand)14 + v^textflow_(texthubtextdemand)34 leq p^textpeak demand_textdemand cdot fracsum_b=3^4 p^textdemand profile_textdemandb2 \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Although the LHS of the two DC-OPF constraints are identical, their RHS differ. This discrepancy implies that the same variables are being forced to satisfy two conflicting conditions simultaneously. As a result, the model becomes infeasible.","category":"page"},{"location":"30-concepts/#flex-time-res-mimo","page":"Concepts","title":"Flexible Time Resolution in Assets with Multiple Input and Multiple Output (MIMO) and Flows Relationships","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In this section, we show how flexible time resolution is applied when considering assets with Multiple Inputs and Multiple Outputs (MIMO) and flows relationship constraints. Let's consider the example in the folder test/inputs/MIMO to explain how these constraints are created in TulipaEnergyModel.jl when having the flexible time resolution. Here is a representation of the energy system in the example.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: mimo-example)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The example has two sources of energy biomass and gas_market, three conversion assets power_plant, chp_backpressure, and chp_extraction, two demands of energy represented by electricity_demand and heat_demand, and finally a by-product CO2 emmisions that goes to the asset atmosphere. The table below shows the type of each asset. Notice that the biomass asset is modeled as a storage and the atmosphere as a consumer. We will return to these definitions later in this section, but bear with us and keep this in mind.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"using DataFrames # hide\nusing CSV # hide\ninput_dir = \"../../test/inputs/MIMO\" # hide\nassets_data = CSV.read(joinpath(input_dir, \"asset.csv\"), DataFrame, header = 1) # hide\nfiltered_assets_data = assets_data[!, [\"asset\", \"type\", \"capacity\", \"consumer_balance_sense\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Notice that the heat_demand and the atmosphere are modeled as consumer assets with a sense geq, meaning that the sum","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"As for the flexible time resolution, the flows-rep-periods-partitions file defines them for the flows in the energy system, as shown below. Here, the flows that go to the atmosphere have a uniform 24h resolution (i.e., daily); this will reduce the number of variables we need to account for the CO2 emissions and consider only one variable per day. The flows going out of the gas_market are every two hours, and the ones from the biomass every three hours. Why? Because we want to showcase in this example the fully flexible resolution in the model, however, in a real-life case study, the resolution will often be related to the energy carrier's dynamics or another expert's criteria to reduce the number of constraints.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"flows_partitions_data = CSV.read(joinpath(input_dir, \"flows-rep-periods-partitions.csv\"), DataFrame, header = 1) # hide\nfiltered_flows_partitions = flows_partitions_data[!, [\"from_asset\", \"to_asset\", \"specification\", \"partition\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"info: Do you still remember what resolution of the flows is used for?\nThe assets and flows resolution determine the resolution of the model constraints considering the rules outlined in the table under the section flexible time resolution.","category":"page"},{"location":"30-concepts/#Constraints-for-Flows-Relationships","page":"Concepts","title":"Constraints for Flows Relationships","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Thanks to the flexible asset connection in the model, any asset can have multiple inputs and outputs, as illustrated in the figure at the beginning of this section. By default, the flows corresponding to these inputs and outputs are independent of each other within the model. However, there are situations where these flows are related to each other. For example, by-products like CO2 emissions depend on the fuel consumption. Another instance is the residual heat produced by power plants, such as small modular reactors, when generating electricity. Additionally, combined heat and power (CHP) technologies can yield residual heat during electricity production and may have a more complex operational feasible region when generating both electricity and heat.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"To model these interactions, we use a linear combination of flow variables known as flow relationships. These are outlined in the constraints found in the formulation section. The relationships are defined in the flows_relationships file located in the example folder. In this section, we present these relationships in accordance with the constraints established in the model.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"flows_relationships_data = CSV.read(joinpath(input_dir, \"flows-relationships.csv\"), DataFrame, header = 1) # hide\nflows_relationships_data[!, :flow_1] = \"(\" .* string.(flows_relationships_data.flow_1_from_asset) .* \", \" .* string.(flows_relationships_data.flow_1_to_asset) .* \")\" # hide\nflows_relationships_data[!, :flow_2] = \"(\" .* string.(flows_relationships_data.flow_2_from_asset) .* \", \" .* string.(flows_relationships_data.flow_2_to_asset) .* \")\" # hide\nfiltered_flows_relationships = flows_relationships_data[!, [\"flow_1\", \"sense\", \"constant\", \"ratio\", \"flow_2\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The table illustrates that the power_plant asset has three flow relationships: one connecting electricity and heat outputs, and two relating to CO2 emissions released into the atmosphere, which vary depending on the fuel used for energy production. For the chp_backpressure asset, there are two relationships: one representing the fixed ratio between electricity and heat, and another concerning CO2 emissions. Lastly, the chp_extraction asset features a fixed ratio for CO2 emissions, along with a set of inequalities that define the feasible operating region for heat and electricity production. The following figure displays this feasible region:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"(Image: chp-extraction)","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"\"\"\"                                                                                        #hide\n# To reproduce the chp extraction plot in Julia, use the following script                  #hide\nusing Plots                                                                                #hide\nfunction plot_chp_extraction(                                                              #hide\n    cb,                                                                                    #hide\n    upper_cv_slope,                                                                        #hide\n    lower_cv_slope,                                                                        #hide\n    upper_cv_intercept,                                                                    #hide\n    lower_cv_intercept,                                                                    #hide\n    max_heat,                                                                              #hide\n)                                                                                          #hide\n    plot(;                                                                                 #hide\n        dpi = 300,                                                                         #hide\n        xlabel = \"Heat (Q)\",                                                               #hide\n        ylabel = \"Electricity (P)\",                                                        #hide\n        title = \"CHP Extraction\",                                                          #hide\n        xlim = (0, round(max_heat) + 1),                                                   #hide\n        ylim = (0, round(upper_cv_intercept) + 5),                                         #hide\n    )                                                                                      #hide\n    heat_1 = [lower_cv_intercept / (cb - lower_cv_slope), max_heat]                        #hide\n    elec_1 = [cb * heat_1[1], cb * heat_1[2]]                                              #hide\n    heat_2 = [0, max_heat]                                                                 #hide\n    elec_2 = [                                                                             #hide\n        upper_cv_intercept + upper_cv_slope * heat_2[1],                                   #hide\n        upper_cv_intercept + upper_cv_slope * heat_2[2],                                   #hide\n    ]                                                                                      #hide\n    heat_3 = [0, lower_cv_intercept / (cb - lower_cv_slope)]                               #hide\n    elec_3 = [                                                                             #hide\n        lower_cv_intercept + lower_cv_slope * heat_3[1],                                   #hide\n        lower_cv_intercept + lower_cv_slope * heat_3[2],                                   #hide\n    ]                                                                                      #hide\n    heat_4 = [max_heat, max_heat]                                                          #hide\n    elec_4 = [cb * heat_4[2], upper_cv_intercept + upper_cv_slope * heat_4[2]]             #hide\n    plot!(heat_1, elec_1; label = \"\")                                                      #hide\n    plot!(heat_2, elec_2; label = \"\")                                                      #hide\n    plot!(heat_3, elec_3; label = \"\")                                                      #hide\n    plot!(heat_4, elec_4; label = \"\")                                                      #hide\n    heat_filling = [0, lower_cv_intercept / (cb - lower_cv_slope), max_heat]               #hide\n    elec_filling_lb = [upper_cv_intercept + lower_cv_slope * heat_filling[i] for i in 1:3] #hide\n    elec_filling_ub = [                                                                    #hide\n        lower_cv_intercept + lower_cv_slope * heat_filling[1],                             #hide\n        lower_cv_intercept + lower_cv_slope * heat_filling[2],                             #hide\n        cb * heat_filling[3],                                                              #hide\n    ]                                                                                      #hide\n    return plot!(                                                                          #hide\n        heat_filling,                                                                      #hide\n        elec_filling_lb;                                                                   #hide\n        linewidth = 0,                                                                     #hide\n        fillrange = elec_filling_ub,                                                       #hide\n        fillalpha = 0.1,                                                                   #hide\n        c = :grey,                                                                         #hide\n        label = \"Feasible operating region\",                                               #hide\n        fg_legend = :false,                                                                #hide\n    )                                                                                      #hide\nend                                                                                        #hide\ncb = 1.8                                                                                   #hide\nupper_cv_slope = -0.15                                                                     #hide\nlower_cv_slope = -0.15                                                                     #hide\nupper_cv_intercept = 35                                                                    #hide\nlower_cv_intercept = 15                                                                    #hide\nmax_heat = 13.61                                                                           #hide\nplot_chp_extraction(                                                                       #hide\n    cb,                                                                                    #hide\n    upper_cv_slope,                                                                        #hide\n    lower_cv_slope,                                                                        #hide\n    upper_cv_intercept,                                                                    #hide\n    lower_cv_intercept,                                                                    #hide\n    max_heat,                                                                              #hide\n)                                                                                          #hide\nsavefig(\"chp-extraction.png\")                                                              #hide\n\"\"\"                                                                                        #hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"That looks cool 🤓 but, wait a minute! What about the flexible temporal resolution?","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"It's straightforward: When it comes to the constraints created by the flow relationships, the resulting resolution follows the highest resolution of the flows involved in the relationship. In simpler terms, this means it is determined by max(flow1 resolution, flow2 resolution). Consequently, the resulting constraints are considered as energy constraints. Where do I find this information? Remember, the table in the section titled flexible time resolution summarizes all the rules 😉 .Now, let’s examine each relationship (x in mathcalX) closely:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_1 = flow1(powerplant, electricitydemand) and flow2(powerplant, heatdemand): both flows have an hourly resolution (i.e., deafult value) since they don't have any definition in the flows-rep-periods-partitions file. Therefore, the flows relationship constraint is also hourly.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_1 1 11 \n v^textflow_(textpower_planttextelectricity_demand)111 =  40 cdot v^textflow_(textpower_planttextheat_demand)111 \n textflows_relationship_x_1 1 22 \n v^textflow_(textpower_planttextelectricity_demand)122 =  40 cdot v^textflow_(textpower_planttextheat_demand)122 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_2 = flow1(powerplant, atmosphere) and flow2(gasmarket, power_plant): The first flow has an uniform resolution of 24h and the second flow has an uniform resolution of 2h in their definitions. Therefore, the flows relationship constraint is in the highest resolution of both, i.e., every 24h. In addition, the constraint accounts for the durations, so each flow variable is then multiply by the it.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_2 1 124 \n 24 cdot v^textflow_(textpower_planttextatmosphere)1124 =  01575 cdot sum_b=1^12 2 cdot v^textflow_(textgas_markettextpower_plant)1(2b-1)(2b)\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_3 = flow1(powerplant, atmosphere) and flow2(biomass, powerplant): The first flow has an uniform resolution of 24h and the second flow has an uniform resolution of 3h in their definitions. Therefore, the flows relationship constraint is in the highest resolution of both, i.e., every 24h. In addition, the constraint accounts for the durations, so each flow variable is then multiply by the it.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_3 1 124 \n 24 cdot v^textflow_(textpower_planttextatmosphere)1124 =  015 cdot sum_b=1^8 3 cdot v^textflow_(textbiomasstextpower_plant)1(3b-2)(3b)\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_4 = flow1(chpbackpressure, electricitydemand) and flow2(chpbackpressure, heatdemand): both flows have an hourly resolution (i.e., deafult value). Therefore, the flows relationship constraint is also hourly.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_4 1 11 \n v^textflow_(textchp_backpressuretextelectricity_demand)111 =  20 cdot v^textflow_(textchp_backpressuretextheat_demand)111 \n textflows_relationship_x_4 1 22 \n v^textflow_(textchp_backpressuretextelectricity_demand)122 =  20 cdot v^textflow_(textchp_backpressuretextheat_demand)122 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_5 = flow1(chpbackpressure, atmosphere) and flow2(chpbackpressure, electricity_demand): The first flow has an uniform resolution of 24h and the second flow has an uniform resolution of 1h in their definitions. Therefore, the flows relationship constraint is in the highest resolution of both, i.e., every 24h. In addition, the constraint accounts for the durations, so each flow variable is then multiply by the it.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_5 1 124 \n 24 cdot v^textflow_(textchp_backpressuretextatmosphere)1124 =  018 cdot sum_b=1^24 v^textflow_(textchp_backpressuretextelectricity_demand)1bb\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_6 = flow1(chpextraction, electricitydemand) and flow2(chpextraction, heatdemand): both flows have an hourly resolution (i.e., deafult value). Therefore, the flows relationship constraint is also hourly.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_6 1 11 \n v^textflow_(textchp_extractiontextelectricity_demand)111 geq  18 cdot v^textflow_(textchp_extractiontextheat_demand)111 \n textflows_relationship_x_6 1 22 \n v^textflow_(textchp_extractiontextelectricity_demand)122 geq  18 cdot v^textflow_(textchp_extractiontextheat_demand)122 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_7 = flow1(chpextraction, electricitydemand) and flow2(chpextraction, heatdemand): both flows have an hourly resolution (i.e., deafult value). Therefore, the flows relationship constraint is also hourly.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_7 1 11 \n v^textflow_(textchp_extractiontextelectricity_demand)111 leq  35 - 015 cdot v^textflow_(textchp_extractiontextheat_demand)111 \n textflows_relationship_x_7 1 22 \n v^textflow_(textchp_extractiontextelectricity_demand)122 leq  35 - 015 cdot v^textflow_(textchp_extractiontextheat_demand)122 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_8 = flow1(chpextraction, electricitydemand) and flow2(chpextraction, heatdemand): both flows have an hourly resolution (i.e., deafult value). Therefore, the flows relationship constraint is also hourly.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_8 1 11 \n v^textflow_(textchp_extractiontextelectricity_demand)111 geq  15 - 015 cdot v^textflow_(textchp_extractiontextheat_demand)111 \n textflows_relationship_x_8 1 22 \n v^textflow_(textchp_extractiontextelectricity_demand)122 geq  15 - 015 cdot v^textflow_(textchp_extractiontextheat_demand)122 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_9 = flow1(chpextraction, heatdemand) and flow2(chpextraction, electricitydemand): both flows have an hourly resolution (i.e., deafult value). Therefore, the flows relationship constraint is also hourly. This constraint reprsents a simple limit for the maximum heat flow.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_9 1 11 \n v^textflow_(textchp_extractiontextheat_demand)111 leq  1361 \n textflows_relationship_x_9 1 22 \n v^textflow_(textchp_extractiontextheat_demand)122 leq  1361 \n \nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Relationship x_10 = flow1(chpextraction, atmosphere) and flow2(chpextraction, electricity_demand): The first flow has an uniform resolution of 24h and the second flow has an uniform resolution of 1h in their definitions. Therefore, the flows relationship constraint is in the highest resolution of both, i.e., every 24h. In addition, the constraint accounts for the durations, so each flow variable is then multiply by the it.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textflows_relationship_x_10 1 124 \n 24 cdot v^textflow_(textchp_extractiontextatmosphere)1124 =  0108 cdot sum_b=1^24 v^textflow_(textchp_extractiontextelectricity_demand)1bb\nendaligned","category":"page"},{"location":"30-concepts/#The-Conversion-Coefficient-and-the-Conversion-Balance-Constraints","page":"Concepts","title":"The Conversion Coefficient and the Conversion Balance Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The conversion coefficient is a key parameter in the conversion balance constraints, especially for assets with MIMO and flexible temporal resolution. Remember that only flows with conversion coefficient greater than zero are considered to determine the resolution of the conversion balance constraint. So, let's explore each conversion asset in the example.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"power_plant: This asset has two inputs and three outputs. However, the outputs to heat_demand and the atmosphere have a conversion coefficient of zero, as shown in the table below. This indicates that the constraint's resolution will be determined by the flows coming from the biomass and gas_market, alongside the output flow to electricity_demand. Therefore, the resolution for the conversion balance of this asset is: max(3h, 2h, 1h) = 3h.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"flows_commission_data = CSV.read(joinpath(input_dir, \"flow-commission.csv\"), DataFrame, header = 1) # hide\nfunction filtered_asset(asset_to_filter::String) #hide\n  return (flows_commission_data[!,\"from_asset\"] .== asset_to_filter) .||  #hide\n         (flows_commission_data[!,\"to_asset\"] .== asset_to_filter)        #hide\nend #hide\nasset_to_filter = \"power_plant\" #hide\ncolumns_to_filter = [\"from_asset\", \"to_asset\", \"conversion_coefficient\"] #hide\nfiltered_flows_commission_data = flows_commission_data[filtered_asset(asset_to_filter), columns_to_filter] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"chp_backpressure: This asset has one input and three outputs. However, the output to atmosphere has a conversion coefficient of zero, as shown in the table below. This indicates that the constraint's resolution will be determined by the flow coming from the gas_market, alongside the outputs flows to electricity_demand and heat_demand. Therefore, the resolution for the conversion balance of this asset is: max(2h, 1h, 1h) = 2h.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"asset_to_filter = \"chp_backpressure\" #hide\nfiltered_flows_commission_data = flows_commission_data[filtered_asset(asset_to_filter), columns_to_filter] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"chp_extraction: This asset has one input and three outputs. However, the output to atmosphere has a conversion coefficient of zero, as shown in the table below. This indicates that the constraint's resolution will be determined by the flow coming from the gas_market, alongside the outputs flows to electricity_demand and heat_demand. Therefore, the resolution for the conversion balance of this asset is: max(2h, 1h, 1h) = 2h.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"asset_to_filter = \"chp_extraction\" #hide\nfiltered_flows_commission_data = flows_commission_data[filtered_asset(asset_to_filter), columns_to_filter] # hide","category":"page"},{"location":"30-concepts/#The-Capacity-Coefficient-and-the-Maximum-Capacity-Constraints","page":"Concepts","title":"The Capacity Coefficient and the Maximum Capacity Constraints","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"The capacity_coefficient determines which output flows of an asset will be included in the capacity constraints for that asset. This parameter is particularly important when an asset has outputs that are by-products, such as CO2 emissions. For example, all outputs from conversion assets to the atmosphere have a coefficient of zero (as shown in the table below), indicating that they will not be considered in the capacity constraints.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"asset_to_filter = \"atmosphere\" #hide\ncolumns_to_filter = [\"from_asset\", \"to_asset\", \"capacity_coefficient\"] #hide\nfiltered_flows_commission_data = flows_commission_data[filtered_asset(asset_to_filter), columns_to_filter] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Remember that the capacity constraints resolution are defined in the lowest resolution of the output flows since it is a power constraint. Notice that all the conversion assets have three outputs electricity_demand, heat_demand, and atmosphere. Therefore, the resolution for the output capacity constraint of those assets is: min(1h, 1h, 24h) = 1h.","category":"page"},{"location":"30-concepts/#The-Atmosphere-as-a-Consumer-Asset","page":"Concepts","title":"The Atmosphere as a Consumer Asset","text":"","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"From the following table, you can see that the atmosphere asset is modeled as a consumer assets with a sense geq, meaning that the sum of all inputs needs to be greater than the peak_demand, i.e., greater than zero in this case.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"assets_milestone_data = CSV.read(joinpath(input_dir, \"asset-milestone.csv\"), DataFrame, header = 1) # hide\ndf_joined = leftjoin(assets_data, assets_milestone_data, on = :asset) #hide\nconsumers = assets_data[!,\"type\"] .== \"consumer\" #hide\nfiltered_df_joined = df_joined[consumers, [\"asset\", \"consumer_balance_sense\", \"peak_demand\"]] # hide","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"In addition, the resolution of all the flows comming into the atmosphere asset is 24h, i.e., daily, meaning that the resolution of the consumer balance for this asset is also 24h:","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"beginaligned\n textconsumer_balance_textatmosphere 1 124 \n v^textflow_(textpower_planttextatmosphere)1124 + v^textflow_(textchp_backpressuretextatmosphere)1124 + v^textflow_(textchp_extractiontextatmosphere)1124 geq 0\nendaligned","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Notice that the flows are defined as power (i.e., instantaneous value); therefore, the result of all the flows going to the atmosphere will represent the average CO2 emissions within the day. To compute the total daily emissions, multiply the flow by the duration (i.e., 24h) and then get the total daily value.","category":"page"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"As explained in the modeling greenhouse gas emissions section, you can alternatively model the atmosphere as a storage asset and account for the total emissions as the storage level of the asset.","category":"page"},{"location":"20-user-guide/20-how-to-use/#how-to-use","page":"How to Use","title":"How to Use","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Pages = [\"20-how-to-use.md\"]\nDepth = [2, 3]","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"This section assumes users have already followed the Tutorials and are looking for specific instructions for certain features.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Running-a-Scenario","page":"How to Use","title":"Running a Scenario","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"To run a scenario, use the function:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"run_scenario(connection)\nrun_scenario(connection; output_folder)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"The connection should have been created and the data loaded into it using TulipaIO. See the Workflow Tutorial for a complete guide on how to achieve this. The output_folder is optional if the user wants to export the output.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Finding-an-input-parameter","page":"How to Use","title":"Finding an input parameter","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"tip: Are you looking for an input parameter?\nPlease visit the Model Parameters section for a description and location of all model input parameters.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Running-automatic-tests","page":"How to Use","title":"Running automatic tests","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"To run the automatic tests on your installation of TulipaEnergyModel:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Enter package mode (press \"]\")","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"pkg> test TulipaEnergyModel\n# This takes a minute or two...","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"All tests should pass. (If you have an error in your analysis, it is probably not caused by TulipaEnergyModel.)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"warning: Admin rights on your local machine\nEnsure you have admin rights on the folder where the package is installed; otherwise, an error will appear during the tests.","category":"page"},{"location":"20-user-guide/20-how-to-use/#input","page":"How to Use","title":"Input and Output","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Tulipa runs from tables in DuckDB, which can be loaded from many formats (CSV, Parquet, etc). See the workflow tutorial for more information on inputting data.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Input","page":"How to Use","title":"Input","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Tulipa runs from strictly defined files that follow the Schemas. See the workflow section for more information on how to work with the schema.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"You can check the test/inputs folder for examples of different predefined energy systems and features. Moreover, Tulipa's Offshore Bidding Zone Case Study can be found in https://github.com/TulipaEnergy/Tulipa-OBZ-CaseStudy. It shows how to start from user-friendly files and transform the data into the input files in the Schemas through different functions.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Output","page":"How to Use","title":"Output","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Outputs are sent from Tulipa to DuckDB and can be exported to various file formats.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"To save the solution to CSV files, you can use export_solution_to_csv_files. See the Workflow Tutorial for an example showcasing this function.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Setting-the-solver-and-its-parameters","page":"How to Use","title":"Setting the solver and its parameters","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"By default, the model is solved using the HiGHS optimizer (or solver). To change this, you can give the functions run_scenario or create_model! a different optimizer.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"warning: Warning\nHiGHS is the only open source solver that we recommend. GLPK and Cbc are not (fully) tested for Tulipa.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Here is an example running the Tiny case using the GLPK optimizer:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"using DuckDB, TulipaIO, TulipaEnergyModel, GLPK\n\ninput_dir = \"../../test/inputs/Tiny\" # you path will be different\nconnection = DBInterface.connect(DuckDB.DB)\nread_csv_folder(connection, input_dir; schemas = TulipaEnergyModel.schema_per_table_name)\nenergy_problem = run_scenario(connection; optimizer = GLPK.Optimizer)\n#OR create_model!(energy_problem; optimizer = GLPK.Optimizer)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nNotice that you need to add the GLPK package and run using GLPK before running GLPK.Optimizer.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In both cases above, the GLPK optimizer uses its default parameters, which you can query using default_parameters. To change any optimizer parameters, you can pass a dictionary to the optimizer_parameters keyword argument. The example below changes the maximum allowed runtime for GLPK to 1 second, which will probably cause it to fail to converge in time.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"# change the optimizer parameters\nparameter_dict = Dict(\"tm_lim\" => 1) # list optimizer parameters as comma-separated parameter=>value pairs\nenergy_problem = run_scenario(connection; optimizer = GLPK.Optimizer, optimizer_parameters = parameter_dict)\n#OR create_model!(energy_problem; optimizer = GLPK.Optimizer, optimizer_parameters = parameter_dict)\nenergy_problem.termination_status","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"If direct_model = false you can change the optimizer and parameters after creating the model (but before solving it) using the JuMP commands demonstrated below. For more information on direct_model, see Speed improvements in the model creation.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"# create the model and solve with the default optimizer and optimizer parameters\nenergy_problem = EnergyProblem(connection)\ncreate_model!(energy_problem)\nsolve_model(energy_problem)\n\n# change the solver and parameters and resolve:\nparameter_dict = Dict(\"tm_lim\" => 1) # list optimizer parameters as comma-separated parameter=>value pairs\n\nJuMP.set_optimizer(energy_problem.model, GLPK.Optimizer) # change the optimizer\nfor (k, v) in optimizer_parameters\n    JuMP.set_attribute(energy_problem.model, k, v) # change the optimizer_parameters\nend\n\nsolve_model(energy_problem) # solve the model with new optimizer & optimizer_parameters","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For the complete list of parameters, check your chosen optimizer.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"You can also pass these parameters via a file using the read_parameters_from_file function.","category":"page"},{"location":"20-user-guide/20-how-to-use/#infeasible","page":"How to Use","title":"Exploring infeasibility","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"If your model is infeasible, you can try exploring the infeasibility with JuMP.compute_conflict! and JuMP.copy_conflict.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"warning: Check your solver options!\nNot all solvers support this functionality; please check your specific solver.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Use energy_problem.model for the model argument. For instance:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"if energy_problem.termination_status == INFEASIBLE\n  compute_conflict!(energy_problem.model)\n  iis_model, reference_map = copy_conflict(energy_problem.model)\n  print(iis_model)\nend","category":"page"},{"location":"20-user-guide/20-how-to-use/#need-for-speed","page":"How to Use","title":"Speeding up model creation","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/#Disable-names-of-variables-and-constraints","page":"How to Use","title":"Disable names of variables and constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"If you want to speed-up model creation, consider disabling the naming of variables and constraints. Of course, removing the names will make debugging difficult (or impossible) - so enable/disable naming as needed for your analysis.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"# Disable names while using run_scenario\nrun_scenario(connection; enable_names = false)\n\n# OR while using create_model!\ncreate_model!(energy_problem; enable_names = false)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more information, see the JuMP documentation for Disable string names.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Create-a-direct-model","page":"How to Use","title":"Create a direct model","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"If you want to reduce memory usage, consider using direct_model = true. This restricts certain actions after model creation, such as changing the optimizer.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"# Create direct model with run_scenario\nrun_scenario(connection; direct_model = true)\n\n# OR while using create_model!\ncreate_model!(energy_problem; direct_model = true)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more information, see the JuMP documentation for direct_model.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Activating-specific-constraints","page":"How to Use","title":"Activating specific constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/#Storage-constraints","page":"How to Use","title":"Storage constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/#seasonal-setup","page":"How to Use","title":"Seasonal and non-seasonal storage","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Section Storage Modeling explains the main concepts for modeling seasonal and non-seasonal storage in TulipaEnergyModel.jl. To define if an asset is one type or the other then consider the following:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Seasonal storage: When the storage capacity of an asset is greater than the total length of representative periods, we recommend using the over-clustered-year constraints. To apply these constraints, you must set the input parameter is_seasonal to true.\nNon-seasonal storage: When the storage capacity of an asset is lower than the total length of representative periods, we recommend using the rep-period constraints. To apply these constraints, you must set the input parameter is_seasonal to false.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nIf the input data covers only one representative period for the entire year, for example, with 8760-hour timesteps, and you have a monthly hydropower plant, then you should set the is_seasonal parameter for that asset to false. This is because the length of the representative period is greater than the storage capacity of the storage asset.","category":"page"},{"location":"20-user-guide/20-how-to-use/#storage-investment-setup","page":"How to Use","title":"The energy storage investment method","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Energy storage assets have a unique characteristic wherein the investment is based not solely on the capacity to charge and discharge, but also on the energy capacity. Some storage asset types have a fixed duration for a given capacity, which means that there is a predefined ratio between energy and power. For instance, a battery of 10MW/unit and 4h duration implies that the energy capacity is 40MWh. Conversely, other storage asset types don't have a fixed ratio between the investment of capacity and storage capacity. Therefore, the energy capacity can be optimized independently of the capacity investment, such as hydrogen storage in salt caverns. To define if an energy asset is one type or the other then consider the following parameters:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Investment energy method: To use this method, set the parameter storage_method_energy to true. In addition, it is necessary to define:\ninvestment_cost_storage_energy: To establish the cost of investing in the storage capacity (e.g., kEUR/MWh/unit).\nfixed_cost_storage_energy: To establish the fixed cost of energy storage capacity (e.g., kEUR/MWh/unit).\ninvestment_limit_storage_energy: To define the potential of the energy capacity investment (e.g., MWh). Missing values mean that there is no limit.\ninvestment_integer_storage_energy: To determine whether the investment variables of storage capacity are integers of continuous.\nFixed energy-to-power ratio method: To use this method, set the parameter storage_method_energy to false. In addition, it is necessary to define the parameter energy_to_power_ratio to establish the predefined duration of the storage asset or ratio between energy and power. Note that all the investment costs should be allocated in the parameter investment_cost.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In addition, the parameter capacity_storage_energy defines the energy per unit of storage capacity invested in (e.g., MWh/unit).","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more details on the constraints that apply when selecting one method or the other, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#storage-binary-method-setup","page":"How to Use","title":"Control simultaneous charging and discharging","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Depending on the configuration of the energy storage assets, it may or may not be possible to charge and discharge them simultaneously. For instance, a single battery cannot charge and discharge at the same time, but some pumped hydro storage technologies have separate components for charging (pump) and discharging (turbine) that can function independently, allowing them to charge and discharge simultaneously. To account for these differences, the model provides users with three options for the use_binary_storage_method parameter:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"binary: the model adds a binary variable to prevent charging and discharging simultaneously.\nrelaxed_binary: the model adds a binary variable that allows values between 0 and 1, reducing the likelihood of charging and discharging simultaneously. This option uses a tighter set of constraints close to the convex hull of the full formulation, resulting in fewer instances of simultaneous charging and discharging in the results.\nIf no value is set, i.e., missing value, the storage asset can charge and discharge simultaneously.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more details on the constraints that apply when selecting this method, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#unit-commitment-setup","page":"How to Use","title":"Unit Commitment constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"The unit commitment constraints are only applied to producer and conversion assets. The unit_commitment parameter must be set to true to include the constraints. Additionally, the following parameters should be set in that same file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"unit_commitment_method: It determines which unit commitment method to use. The current version of the code only includes the basic version. Future versions will add more detailed constraints as additional options.\nunits_on_cost: Objective function coefficient on units_on variable. (e.g., no-load cost or idling cost in kEUR/h/unit)\nunit_commitment_integer: It determines whether the unit commitment variables are considered as integer or not (true or false)\nmin_operating_point: Minimum operating point or minimum stable generation level defined as a portion of the capacity of asset (p.u.)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more details on the constraints that apply when selecting this method, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#ramping-setup","page":"How to Use","title":"Ramping constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"The ramping constraints are only applied to producer and conversion assets. The ramping parameter must be set to true to include the constraints. Additionally, the following parameters should be set in that same file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"max_ramp_up: Maximum ramping up rate as a portion of the capacity of asset (p.u./h)\nmax_ramp_down:Maximum ramping down rate as a portion of the capacity of asset (p.u./h)","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For more details on the constraints that apply when selecting this method, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#max-min-outgoing-energy-setup","page":"How to Use","title":"Outgoing energy constraints (maximum or minimum)","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For the model to add constraints for a maximum or minimum energy limit for an asset throughout the model's timeframe (e.g., a year), we need to establish a couple of parameters:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"is_seasonal = true. This parameter enables the model to use the over-clustered-year constraints.\nmax_energy_timeframe_partition neq missing or min_energy_timeframe_partition neq missing. This value represents the peak energy that will be then multiplied by the profile for each period in the timeframe.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nThese parameters are defined per period, and the default values for profiles are 1.0 p.u. per period. If the periods are determined daily, the energy limit for the whole year will be 365 times maxor min_energy_timeframe_partition.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"(optional) profile_type and profile_name in the timeframe files. If there is no profile defined, then by default it is 1.0 p.u. for all periods in the timeframe.\n(optional) define a period partition in timeframe partition files. If there is no partition defined, then by default the constraint is created for each period in the timeframe, otherwise, it will consider the partition definition in the file.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"tip: Tip\nIf you want to set a limit on the maximum or minimum outgoing energy for a year with representative days, you can use the partition definition to create a single partition for the entire year to combine the profile.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Example:-Setting-Energy-Limits","page":"How to Use","title":"Example: Setting Energy Limits","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Let's assume we have a year divided into 365 days because we are using days as periods in the representatives from TulipaClustering.jl. Also, we define the max_energy_timeframe_partition = 10 MWh, meaning the peak energy we want to have is 10MWh for each period or period partition. So depending on the optional information, we can have:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Profile Period Partitions Example\nNone None The default profile is 1.p.u. for each period and since there are no period partitions, the constraints will be for each period (i.e., daily). So the outgoing energy of the asset for each day must be less than or equal to 10MWh.\nDefined None The profile definition and value will be in the timeframe profiles files. For example, we define a profile that has the following first four values: 0.6 p.u., 1.0 p.u., 0.8 p.u., and 0.4 p.u. There are no period partitions, so constraints will be for each period (i.e., daily). Therefore the outgoing energy of the asset for the first four days must be less than or equal to 6MWh, 10MWh, 8MWh, and 4MWh.\nDefined Defined Using the same profile as above, we now define a period partition in the timeframe partitions file as uniform with a value of 2. This value means that we will aggregate every two periods (i.e., every two days). So, instead of having 365 constraints, we will have 183 constraints (182 every two days and one last constraint of 1 day). Then the profile is aggregated with the sum of the values inside the periods within the partition. Thus, the outgoing energy of the asset for the first two partitions (i.e., every two days) must be less than or equal to 16MWh and 12MWh, respectively.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Group-constraints","page":"How to Use","title":"Group constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"A group of assets refers to a set of assets that share certain constraints. For example, the investments of a group of assets may be capped at a maximum value, which represents the potential of a specific area that is restricted in terms of the maximum allowable MW due to limitations on building licenses.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Groups are useful to represent several common constraints.","category":"page"},{"location":"20-user-guide/20-how-to-use/#group-setup","page":"How to Use","title":"Creating Groups","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In order to define the groups in the model, the following steps are necessary:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Create a group file by defining the name property and its parameters in the group_asset table (or CSV file).\nAssign assets to the group by setting the name in the group parameter/column of the asset file.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nA missing value in the parameter group means that the asset does not belong to any group.","category":"page"},{"location":"20-user-guide/20-how-to-use/#investment-group-setup","page":"How to Use","title":"Group Investment constraints (maximum or minimum)","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"The mathematical formulation of the maximum and minimum investment limit for group constraints is available here.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"invest_method = true. This parameter enables the model to use the investment group constraints.\nmin_investment_limit neq missing or max_investment_limit neq missing. This value represents the limits that will be imposed on the investment that belongs to the group.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nA missing value in the parameters min_investment_limit and max_investment_limit means that there is no investment limit.\nThese constraints are applied to the investments each year. The model does not yet have investment limits to a group's available invested capacity.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Example:-Group-of-Assets","page":"How to Use","title":"Example: Group of Assets","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Let's explore how the groups are set up in the test case called Norse. First, let's take a look at the group-asset.csv file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"using DataFrames # hide\nusing CSV # hide\ninput_asset_file = \"../../../test/inputs/Norse/group-asset.csv\" # hide\nassets = CSV.read(input_asset_file, DataFrame, header = 1) # hide","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In the given data, there are two groups: renewables and ccgt. Both groups have the invest_method parameter set to true, indicating that investment group constraints apply to both. For the renewables group, the min_investment_limit parameter is missing, signifying that there is no minimum limit imposed on the group. However, the max_investment_limit parameter is set to 40000 MW, indicating that the total investments of assets in the group must be less than or equal to this value. In contrast, the ccgt group has a missing value in the max_investment_limit parameter, indicating no maximum limit, while the min_investment_limit is set to 10000 MW for the total investments in that group.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Let's now explore which assets are in each group. To do so, we can take a look at the asset.csv file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"input_asset_file = \"../../../test/inputs/Norse/asset.csv\" # hide\nassets = CSV.read(input_asset_file, DataFrame) # hide\nassets = assets[.!ismissing.(assets.group), [:asset, :type, :group]] # hide","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Here we can see that the assets Asgard_Solar and Midgard_Wind belong to the renewables group, while the assets Asgard_CCGT and Midgard_CCGT belong to the ccgt group.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nIf the group has a min_investment_limit, then assets in the group have to allow investment (investable = true) for the model to be feasible. If the assets are not investable then they cannot satisfy the minimum constraint.","category":"page"},{"location":"20-user-guide/20-how-to-use/#multi-year-setup","page":"How to Use","title":"Multi-year investments","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"warning: The workflow of feature is under construction\nThis section describes the existing workflow but we are working to make it more user friendly.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"It is possible to simutaneously model different years, which is especially relevant for modeling multi-year investments. Multi-year investments refer to making investment decisions at different points in time, such that a pathway of investments can be modeled. This is particularly useful when long-term scenarios are modeled, but modeling each year is not practical. Or in a business case, investment decisions are supposed to be made in different years which has an impact on the cash flow.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Filling-the-input-data","page":"How to Use","title":"Filling the input data","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In order to set up a model with year information, the following steps are necessary. The below illustrative example uses assets, but flows follow the same idea.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Year-data","page":"How to Use","title":"Year data","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Fill in all the years in year-data.csv file by defining the year property and its parameters. Differentiate milestone years and non-milestone years.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Milestone years are the years you would like to model. For example, if you want to model operation and/or investments in 2030, 2040, and 2050. These 3 years are then milestone years.\nNon-milestone years are the commission years of existing units. For example, you want to consider a existing wind unit that has been commissioned in 2020, then 2020 is a non-milestone year.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nA year can both be a year that you want to model and that there are existing units invested, then this year is a milestone year.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Asset-basic-data","page":"How to Use","title":"Asset basic data","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Fill in the parameters in the asset.csv file. These parameters are for the assets across all the years, i.e., not dependent on years. Examples are lifetime (both technical_lifetime and economic_lifetime) and capacity of a unit.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"You need to choose a investment_method for the asset, between none, simple, and compact. In addition, you also have to make it explicit on which assets you would like to invest in, by setting the investable parameter in asset-milestone.csv, and which assets you would like to decommission, by setting the decommissionable parameter in asset-both.csv. More information on investable and decommissionable are given in the next sections.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Below is an overview of the important set-ups regarding the investment methods.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Operation mode: choose none. Set investable and decommissionable to false to make sure neither investments nor decommissioning occur.\nSimple investment method: choose simple. Set investable and decommissionable manually. Make sure milestone_year = commission_year in asset-both.csv. Any missing or redundant rows will throw an error.\nCompact investment method: choose compact. Set investable and decommissionable manually. Make sure to have more than one commission year for a milestone year in asset-both.csv, and the matching profiles. Otherwise the compact method will work the same as the simple method.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: More about the investment methods\nThe compact method can only be applied to producer assets and conversion assets. Transport assets and storage assets can only use simple or none method.\nFor more details on the constraints that apply when selecting these methods, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Asset-milestone-year-data","page":"How to Use","title":"Asset milestone year data","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Fill in the parameters related to the milestone year. Whether the model allows investment at a milestone year for an asset is set by the investable parameter in asset-milestone.csv. You can only invest in milestone years.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Asset-commission-year-data","page":"How to Use","title":"Asset commission year data","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Fill in the parameters related to the commission year, e.g., investment costs and fixed costs.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Existing-capacities-and-decommissioning","page":"How to Use","title":"Existing capacities and decommissioning","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Existing capacities and decommissioning are taken care of in asset-both.csv","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In the milestone_year column, fill in all the milestone years. In the commission_year column, fill in the commission years of the existing assets that are still available in this milestone_year and put the existing units in the column initial_units.\nWhether the model allows decommissioning at a milestone_year for an asset that has been commissioned in a commission_year is set by the parameter decommissionable.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Let's explain further using an example. To do so, we take a look at the asset-both.csv file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"using DataFrames # hide\nusing CSV # hide\ninput_asset_file = \"../../../test/inputs/Multi-year Investments/asset-both.csv\" # hide\nassets_data = CSV.read(input_asset_file, DataFrame) # hide\nassets_data = assets_data[:, [:asset, :milestone_year, :commission_year, :decommissionable, :initial_units]] # hide","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"battery has 1.09 existing units in 2030 and 2.02 existing units in 2050. Both units can be decommissioned.\nccgt has 1 existing units in 2030 and 2050. Neither can be decommissioned.\ndemand is a consumer, so is has no initial units and you only have data where milestone_year = commission_year.\nens has 1 existing units in 2030 and 2050. Neither can be decommissioned.\nocgt has no existing units.\nsolar has no existing units.\nwind has 0.07 existing units, commissioned in 2020, and still available in 2030 but not in 2050. Another 0.02 existing units, commissioned in 2030, available in 2030 and 2050. There are no initial units commissioned in 2050.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nWe only consider the existing units which are still available in the milestone years.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Profiles-information","page":"How to Use","title":"Profiles information","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Important to know that you can use different profiles for assets that are commissioned in different years, which is the power of the compact method. You fill in the profile names in assets-profiles.csv for relevant years. In profiles-rep-periods.csv, you relate the profile names with the modeled years.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Let's explain further using an example. To do so, we can take a look at the assets-profiles.csv file:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"input_asset_file = \"../../../test/inputs/Multi-year Investments/assets-profiles.csv\" # hide\nassets_profiles = CSV.read(input_asset_file, DataFrame, header = 1) # hide\nassets_profiles = assets_profiles[:, :] # hide","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"We have 3 profiles for wind commissioned in 2020, 2030, and 2050, respectively. Imagine these are 3 wind turbines with different efficiencies due to the year of manufacture.","category":"page"},{"location":"20-user-guide/20-how-to-use/#Economic-representation","page":"How to Use","title":"Economic representation","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For economic representation, the following parameters need to be set up:","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"[optional] discount year and discount rate in the model-parameters-example.toml file: model-wide discount year and rate. By default, the model will use a discount rate of 0, and a discount year of the first milestone year. In other words, the costs will be discounted to the cost of the first milestone year.\ndiscount_rate: technology-specific discount rates.\neconomic_lifetime: used for discounting the costs.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Info\nSince the model explicitly discounts, all the inputs for costs should be given in the costs of the relevant year. For example, to model investments in 2030 and 2050, the investment_cost should be given in 2030 costs and 2050 costs, respectively.\nFor more details on the formulas for economic representation, please visit the mathematical formulation section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#coefficient-for-capacity-constraints","page":"How to Use","title":"Flow Coefficient in Capacity constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Capacity constraints apply to all the outputs and inputs to assets according to the equations in the capacity constraints section of the mathematical formulation. The coefficient p^textcapacity coefficient_fy in the capacity constraints can be set to model situations or processes where the flows in the capacity constraint are multiplied by a constant factor.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For instance, a hydro reservoir (i.e., storage asset) with two outputs, one for electricity production and another for water spillage. The electricity output flow must be in the capacity constraints. However, the water spillage is an output that can be excluded from the capacity constraint. In that case, the coefficient for the capacity constraint of the water output can be zero and therefore not included in that constraint.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Another situation comes from industrial processes where the sum of both outputs must be below the capacity, but one of the outputs can be above the capacity if only produced in that flow. For example,","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"textflow process A + 08 cdot textflow process B leq textC","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"In that case the sum must be always below the total capacity textC, but if you only produce flow through B then you can produce 125 cdot textC and still satisfy this constraint.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"To set up this parameter you need to fill in the information for the capacity_coefficient in the flow_commission table, see more in the model parameters section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#coefficient-for-conversion-constraints","page":"How to Use","title":"Using the coefficient for flows in the conversion constraints","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Conversion constraints apply to all the outputs and inputs of a conversion asset according to the equations in the conversion balance constraints section of the mathematical formulation. The coefficient p^textconversion coefficient_fy in that constraint can be set to model situations or processes where the flows in the conversion balance constraint are multiplied by a constant factor.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For instance, CO2 emissions modeled as an extra output of a gas-fired power plant that produces electricity. Here, the conversion is from gas (input) into electricity (output) through an efficiency parameter of the asset. However, the CO2 emissions are also an output of the asset, therefore by default they are considered in the conversion balance, unless we set the conversion_coefficient to zero.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"To set up this parameter you need to fill in the information for the conversion_coefficient in the flow_commission table, see more in the model parameters section.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"info: Conversion coefficient and flexible time resolution\nAs explained in the flexible time resolution section, the resolution of the conversion balance constraint is determined by the highest resolution of the input and output flows because it is treated as an energy constraint. Nevertheless, for consistency, only the flows with a conversion_coefficient greater than zero are included in the definition of the constraint's resolution.","category":"page"},{"location":"20-user-guide/20-how-to-use/#flow-relationships","page":"How to Use","title":"Defining Flows Relationships","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Two flows in the model can be related using the flows relationships constraints section of the mathematical formulation. The parameters in this constraint, i.e., the constant, sense, and ratio, and the flows in the relationship are defined in the flows_relationships table, see more in the model parameters section.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"There will be a set of constraints for each row in the flows_relationships table, meaning that the same flows can have different sets of constraints to describe different relationships between them. One example is the Combined Heat and Power (CHP) extraction plants, which rely on a set of inequality constraints between the electricity and heat outputs to define a feasible operating region. For more details about this example, refer to the multiple inputs and outputs example in the concepts section.","category":"page"},{"location":"20-user-guide/20-how-to-use/#greenhouse-gas-emissions","page":"How to Use","title":"Modeling Greenhouse Gas Emissions (e.g., CO2)","text":"","category":"section"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Since the model provides a general definition of assets, specific definitions for different greenhouse gas emissions, such as CO2 or methane, do not exist. Instead, these emissions can be modeled as outputs of an asset. Through the concept of flows relationships, any input (e.g., fuel consumption) or output (e.g., electricity) of the asset can be linked to an output flow that represents greenhouse gas emissions (e.g., CO2). In this context, the fixed ratio in the relationship equation serves as the emission factor.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Thanks to the flexible temporal resolution in the model, the output flow representing greenhouse gases can have a high resolution, such as daily, monthly, or even yearly. This flexibility allows for varying resolutions based on modeling needs and helps in reducing the number of variables in the model.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"Additionally, you can use either a consumer or a storage asset to represent the aggregation of a particular greenhouse gas, such as total CO2 emissions in the system. Both options are viable, and the choice depends on what the modeler finds more convenient for their analysis.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For instance, using a storage asset means that the storage level will represent the total accumulated emissions at each defined time block (or period), which can then be restricted by maximum and minimum storage levels to account for limits on total emissions. Alternatively, if you use a consumer asset, you can define the consumer's output as geq 0, allowing you to track total emissions by post-processing all emission flows over a specified duration. This latter approach involves fewer variables since no storage level is created, but it does require post-processing to obtain the desired results. Ultimately, both methods have their pros and cons, and it is up to the modeler to decide which is best suited for their case study.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"For an example of implementing CO2 emissions as a consumer asset, refer to the multiple inputs and outputs example in the concepts section.","category":"page"},{"location":"20-user-guide/20-how-to-use/","page":"How to Use","title":"How to Use","text":"warning: By-products should not be part of the capacity constraint\nIt is important to note that by-products like emissions should not be included in the capacity constraint of the asset. Therefore, the capacity_coefficient should be set to zero to prevent the asset's output flow from limiting its energy output.","category":"page"},{"location":"10-tutorials/13-assets/#Tutorial-2:-Assets-and-Flows","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"","category":"section"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Tulipa uses Assets and Flows as generalized components to build energy systems.","category":"page"},{"location":"10-tutorials/13-assets/#Explore-the-files","page":"Tutorial 2: Assets and Flows","title":"Explore the files","text":"","category":"section"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Take a look at the files in the my-awesome-energy-system/tutorial-2 folder.","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Do you notice any changes compared to the files you worked with in tutorial 1?","category":"page"},{"location":"10-tutorials/13-assets/#Run-the-workflow","page":"Tutorial 2: Assets and Flows","title":"Run the workflow","text":"","category":"section"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"In my_workflow.jl you can simply change the name of your input directory and run your code.\nFrom the Basics Tutorial, it should look something like this:","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"# Guarantee to run in the current directory\nusing Pkg: Pkg\nPkg.activate(\".\")\n\n# Load the packages\nimport TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nusing DuckDB\nusing DataFrames\nusing Plots\n\n# Define the directories - notice we now select tutorial 2 for both the input and output directory\ninput_dir = \"my-awesome-energy-system/tutorial-2\"\noutput_dir = \"my-awesome-energy-system/tutorial-2/results\"\n\n# Create the connection and read the input files\nconnection = DBInterface.connect(DuckDB.DB)\nTIO.read_csv_folder(connection, input_dir)\n\n# Add the defaults\nTEM.populate_with_defaults!(connection)\n\n# Run the model\nenergy_problem =\n    TEM.run_scenario(connection; output_folder=output_dir)","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error.","category":"page"},{"location":"10-tutorials/13-assets/#Explore-the-results","page":"Tutorial 2: Assets and Flows","title":"Explore the results","text":"","category":"section"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Explore the flow that goes from the hub to the e_demand:","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"flows = TIO.get_table(connection, \"var_flow\")\n\nfrom_asset = \"hub\"\nto_asset = \"e_demand\"\nyear = 2030\nrep_period = 1\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    flows,\n)\n\nplot(\n    filtered_flow.time_block_start,\n    filtered_flow.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    dpi=600,\n)","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Explore the congestion using the duals in the results:","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"transport = TIO.get_table(connection, \"cons_transport_flow_limit_simple_method\")\n\nnames(transport)\n\nfilter(\n    row ->\n        row.dual_max_transport_flow_limit_simple_method != 0.0,\n    transport,\n)","category":"page"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"info: Test Your Knowledge\nCan you explain the values you get from the column dual_max_transport_flow_limit_simple_method? Hint: consider what is currently defining the capacity to transport the flow between the assets you see in the table","category":"page"},{"location":"10-tutorials/13-assets/#Challenge:-Add-a-Battery","page":"Tutorial 2: Assets and Flows","title":"Challenge: Add a Battery","text":"","category":"section"},{"location":"10-tutorials/13-assets/","page":"Tutorial 2: Assets and Flows","title":"Tutorial 2: Assets and Flows","text":"Try adding a battery (a short-term storage asset) that can only charge from the solar PV and discharges to the e_demand consumer.","category":"page"},{"location":"20-user-guide/55-outputs/#outputs","page":"Output Variables","title":"Output Variables","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Tulipa's user workflow is a work-in-progress. For now, you can export the complete raw solution to CSV files using TulipaEnergyModel.export_solution_to_csv_files. Below is a description of the exported data. Files may be missing if the associated features were not included in the analysis.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Pages = [\"55-outputs.md\"]\nDepth = [2, 3]","category":"page"},{"location":"20-user-guide/55-outputs/#Output-Tables-Format","page":"Output Variables","title":"Output Tables Format","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"There are two types of outputs:","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Variables: All tables/files starting with var_show the values of variables in the optimal solution, with leading columns specifying the indices of each solution value.\nDuals: All tables/files starting with cons_ show the dual value in the optimal solution for each constraint, with leading columns specifying the indices of each dual value. Remember that the dual represents the incremental change in the optimal solution per unit increase in the right-hand-side (bound) of the constraint - which in a minimal cost optimisation corresponds to an increase in cost.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"note: Units\nTulipaEnergyModel is inherently unitless, meaning the units are directly taken from the input data. For example, if all costs are given in thousands of euros, then the objective function is also in thousands of euros. So a \"change in the objective function\" would mean a €1k increase/decrease.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Each output table has three types of columns:","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Indices: Parameters on which the output variable or dual is indexed, including:\nasset: Unique name of the asset.\nfrom_asset: For a flow, the origin asset.\nto_asset: For a flow, the terminal asset.\nyear: Equivalent to milestone_year. (Will be fixed in future release.)\nmilestone_year: Year of investment and operation decisions.\ncommission_year: Commissioning year of an asset (used for unique asset identification).\nrep_period: Number of the representative period.\ntime_block_start: Start of the time block of the representative period.\ntime_block_end: End of the time block of the representative period.\nperiod_block_start: Start of the time block of the timeframe (mostly relevant for seasonal storage).\nperiod_block_end: Start of the time block of the timeframe (mostly relevant for seasonal storage).\nAssociated input parameters: Listed per table below\nSolution or dual_constraint_name: Value of the variable or dual in the solution, described below.","category":"page"},{"location":"20-user-guide/55-outputs/#Variable-Tables","page":"Output Variables","title":"Variable Tables","text":"","category":"section"},{"location":"20-user-guide/55-outputs/#var_assets_decommission_energy","page":"Output Variables","title":"var_assets_decommission_energy","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a storage asset that has storage_method_energy commissioned in commission_year, the optimal decommissioning (decrease) of asset energy capacity in milestone_year, expressed in the same units as capacity_storage_energy of asset.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameters: investment_integer_storage_energy, capacity_storage_energy","category":"page"},{"location":"20-user-guide/55-outputs/#var_assets_decommission","page":"Output Variables","title":"var_assets_decommission","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For an asset commissioned in commission_year, the optimal decommissioning (decrease) of asset capacity in milestone_year, expressed in the same units as capacity of asset.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameters: decommissionable, initial_units, investment_integer, capacity","category":"page"},{"location":"20-user-guide/55-outputs/#var_assets_investment_energy","page":"Output Variables","title":"var_assets_investment_energy","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a storage asset that has storage_method_energy, the optimal investment (increase) in asset energy capacity in milestone_year, expressed in the same units as capacity_storage_energy of asset.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameters: investable, investment_integer_storage_energy, capacity_storage_energy, investment_limit_storage_energy","category":"page"},{"location":"20-user-guide/55-outputs/#var_assets_investment","page":"Output Variables","title":"var_assets_investment","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For an asset, the optimal investment (increase) in asset capacity in milestone_year, expressed in the same units as capacity of asset.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameters: investable, investment_integer, capacity, investment_limit","category":"page"},{"location":"20-user-guide/55-outputs/#var_flow","page":"Output Variables","title":"var_flow","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a flow, the optimal flow (of energy) during a particular rep_period between time_block_start and time_block_end, expressed in the same units as capacity of flow.","category":"page"},{"location":"20-user-guide/55-outputs/#var_flows_decommission","page":"Output Variables","title":"var_flows_decommission","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a transport flow commissioned in commission_year, the optimal decommissioning (decrease) of flow capacity in milestone_year, expressed in the same units as capacity of flow.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameter: decommissionable, investment_integer, capacity","category":"page"},{"location":"20-user-guide/55-outputs/#var_flows_investment","page":"Output Variables","title":"var_flows_investment","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a transport flow, the optimal investment (increase) in flow capacity in milestone_year, expressed in the same units as capacity of flow.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameters: investable, investment_integer, capacity, investment_limit","category":"page"},{"location":"20-user-guide/55-outputs/#var_storage_level_over_clustered_year","page":"Output Variables","title":"var_storage_level_over_clustered_year","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a storage asset in a specific year and between period_start and period_end, the optimal storage level BETWEEN representative periods, expressed in the same units as capacity_storage_energy of asset.","category":"page"},{"location":"20-user-guide/55-outputs/#var_storage_level_rep_period","page":"Output Variables","title":"var_storage_level_rep_period","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For a storage asset in a specific year and between period_start and period_end, the optimal storage level WITHIN representative periods, expressed in the same units as capacity_storage_energy of asset.","category":"page"},{"location":"20-user-guide/55-outputs/#var_units_on","page":"Output Variables","title":"var_units_on","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"For an asset, the optimal dispatch (operation) during a particular rep_period between time_block_start and time_block_end, expressed in the same units as capacity of asset.","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameter: unit_commitment_integer","category":"page"},{"location":"20-user-guide/55-outputs/#Constraint-Dual-Tables","page":"Output Variables","title":"Constraint Dual Tables","text":"","category":"section"},{"location":"20-user-guide/55-outputs/#cons_balance_hub","page":"Output Variables","title":"cons_balance_hub","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_balance_hub: Dual of the constraint \"balance constraint for hubs\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_balance_consumer","page":"Output Variables","title":"cons_balance_consumer","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_balance_consumer: Dual of the constraint \"balance constraint for consumers\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_balance_conversion","page":"Output Variables","title":"cons_balance_conversion","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_balance_conversion: Dual of the constraint \"balance constraint for conversion assets\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_balance_storage_over_clustered_year","page":"Output Variables","title":"cons_balance_storage_over_clustered_year","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_balance_storage_over_clustered_year: Dual of the constraint \"over-clustered-year constraint for storage balance\".\ndual_max_storage_level_over_clustered_year_limit: Dual of the constraint \"over-clustered-year constraint for maximum storage level limit\"\ndual_min_storage_level_over_clustered_year_limit: Dual of the constraint \"over-clustered-year constraint for minimum storage level limit\"","category":"page"},{"location":"20-user-guide/55-outputs/#cons_balance_storage_rep_period","page":"Output Variables","title":"cons_balance_storage_rep_period","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_balance_storage_rep_period: Dual of the constraint \"rep-period constraint for storage balance\".\ndual_max_storage_level_rep_period_limit: Dual of the constraint \"rep-period constraint for maximimum storage level limit\"\ndual_min_storage_level_rep_period_limit: Dual of the constraint \"rep-period constraint for minimum storage level limit\"","category":"page"},{"location":"20-user-guide/55-outputs/#cons_capacity_incoming","page":"Output Variables","title":"cons_capacity_incoming","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_max_input_flows_limit: Dual of the constraint \"maximum input flows limit\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_capacity_outgoing","page":"Output Variables","title":"cons_capacity_outgoing","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_max_output_flows_limit: Dual of the constraint \"maximum output flows limit\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_limit_units_on","page":"Output Variables","title":"cons_limit_units_on","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_limit_units_on: Dual of the constraint \"limit to the units on variable\".","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated input parameter: unit_commitment_integer","category":"page"},{"location":"20-user-guide/55-outputs/#cons_max_output_flow_with_basic_unit_commitment","page":"Output Variables","title":"cons_max_output_flow_with_basic_unit_commitment","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_max_output_flow_with_basic_unit_commitment: Dual of the constraint \"maximum output flow above the minimum operating point\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_max_ramp_with_unit_commitment","page":"Output Variables","title":"cons_max_ramp_with_unit_commitment","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_max_ramp_up_with_unit_commitment: Dual of the constraint \"maximum ramp-up rate limit WITH unit commitment\".\ndual_max_ramp_down_with_unit_commitment: Dual of the constraint \"maximum ramp-down rate limit with unit commitment\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_min_output_flow_with_unit_commitment","page":"Output Variables","title":"cons_min_output_flow_with_unit_commitment","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_min_output_flow_with_unit_commitment: Dual of the constraint \"minimum output flow above the minimum operating point\".","category":"page"},{"location":"20-user-guide/55-outputs/#cons_transport_flow_limit","page":"Output Variables","title":"cons_transport_flow_limit","text":"","category":"section"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"dual_max_transport_flow_limit: Dual of the constraint \"maximum transport flow limit\".\ndual_min_transport_flow_limit: Dual of the constraint \"minimum transport flow limit\".","category":"page"},{"location":"20-user-guide/55-outputs/","page":"Output Variables","title":"Output Variables","text":"Associated parameter: var_flow_id: Unique flow ID used internally by TulipaEnergyModel.","category":"page"},{"location":"10-tutorials/30-workflow/#workflow-tutorial","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Tutorial for the OBZ case study as an example of the full workflow of Tulipa.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"warning: Not tested for multi-year\nAlthough we use years in the tutorial below, we haven't tried it on a multi-year case study. Your experience may vary.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"We are basing ourselves on the Tulipa data pipeline/workflow. To help us navigate this workflow, we'll reproduce the diagram from the link above here. For more details on the steps of the workflow, check the original link, or follow the tutorial.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"(Image: Tulipa Workflow. Textual explanation below.)","category":"page"},{"location":"10-tutorials/30-workflow/#Install-packages","page":"Tutorial 7: Workflow","title":"Install packages","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"To follow this tutorial, you need to install some packages:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Open julia in the folder that you will be working\nIn the julia terminal, press ]. You should see pkg>\nActivate you local environment using activate .\nInstall packages with add <Package1>,<Package2>, etc. You shouldn't need to specify the versions, if this tutorial is up-to-date.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"These are the installed packages and their versions:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using Pkg\nPkg.status()","category":"page"},{"location":"10-tutorials/30-workflow/#External-source","page":"Tutorial 7: Workflow","title":"External source","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"For this tutorial, we'll use the OBZ data. Download it from the Zenodo Link and store it in a folder.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Check https://github.com/TulipaEnergy/Tulipa-OBZ-CaseStudy for more information.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"These are the files that we are working with:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"# user_input_dir should point to the folder where the data was downloaded and extracted\nreaddir(user_input_dir)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"For the Tulipa workflow, we will need to transform some of this data into a specific format. This can be done externally in whatever tools you are already comfortable with, or through Julia via DuckDB and TulipaIO's convenience functions.","category":"page"},{"location":"10-tutorials/30-workflow/#Create-connection","page":"Tutorial 7: Workflow","title":"Create connection","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"First create a DuckDB connection.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"You can create a connection storing the DB locally, or keep everything in-memory only. Let's assume you want to store the DB, otherwise you can just remove the argument \"obz.db\".","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using DuckDB: DBInterface, DuckDB\n\n# We are staring from a fresh `obz.db` file\nrm(\"obz.db\", force=true) # hide\nconnection = DBInterface.connect(DuckDB.DB, \"obz.db\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"You will be performing various queries with DuckDB. To format them nicely, you can wrap the results in a DataFrame:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using DataFrames: DataFrame\n\nnice_query(str) = DataFrame(DuckDB.query(connection, str))","category":"page"},{"location":"10-tutorials/30-workflow/#Load-data","page":"Tutorial 7: Workflow","title":"Load data","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Once you are done manipulating the data externally, it is time to load it into the DuckDB connection.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"This doesn't have to be in Tulipa Format. It can be whatever data you prefer to manipulate via Julia/DuckDB, instead of externally.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"You can load data manually with DuckDB, but there is also a convenience function:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using TulipaIO: TulipaIO\n\nTulipaIO.read_csv_folder(\n    connection,\n    user_input_dir,\n    replace_if_exists = true,\n)\n\n# The first 5 tables\nnice_query(\"SELECT table_name FROM duckdb_tables() LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/#Data-processing-for-instance-data-with-DuckDB/TulipaIO","page":"Tutorial 7: Workflow","title":"Data processing for instance data with DuckDB/TulipaIO","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"As we mentioned before, you can process your data externally and then load it. But you can also use Julia and DuckDB to process the data.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"This step is required to prepare the data for TulipaClustering for the clustering of the profile data.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"We need a single profiles table with 4 columns:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"profile_name\nyear\ntimestep\nvalue","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Instead, we have the profiles data in the profiles table, which looks something like the following, but with many more columns:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT year, timestep, * LIKE 'NL_%' FROM profiles LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"The total number of columns in the profiles table:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT COUNT(*) FROM duckdb_columns() WHERE table_name = 'profiles'\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Notice that these are all hourly profiles for the whole year:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT year, MAX(timestep) FROM profiles GROUP BY year\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"So we will transform both this table to long format:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using TulipaClustering: TulipaClustering\n\nTulipaClustering.transform_wide_to_long!(connection, \"profiles\", \"pivot_profiles\")\n\nDuckDB.query(\n    connection,\n    \"CREATE OR REPLACE TABLE profiles AS\n    FROM pivot_profiles\n    ORDER BY profile_name, year, timestep\n    \"\n)\n\nnice_query(\"SELECT COUNT(*) FROM profiles\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Just to showcase this, let's plot all NL_* profiles in the first 72 hours of the year:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using Plots\n\nsubtable = DuckDB.query(\n    connection,\n    \"SELECT\n        timestep,\n        value,\n        profile_name,\n    FROM profiles\n    WHERE\n        profile_name LIKE 'NL_%'\n        AND year=2050\n        AND timestep <= 72 -- Just 72 hours\n    ORDER BY timestep\n    \",\n)\ndf = DataFrame(subtable)\nplot(df.timestep, df.value, group=df.profile_name)","category":"page"},{"location":"10-tutorials/30-workflow/#Cluster-into-representative-periods-using-TulipaClustering","page":"Tutorial 7: Workflow","title":"Cluster into representative periods using TulipaClustering","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Instead of working with the full time horizon of 8760 hours, we will cluster the profiles using TulipaClustering.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"You can tweak around the number of representative periods and period duration (and naturally other parameters). This is the configuration that we'll use:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using Distances: SqEuclidean\n\n## Data for clustering\nclustering_params = (\n    num_rep_periods = 3,    # number of representative periods\n    period_duration = 24,   # hours of the representative period\n    method = :k_means,\n    distance = SqEuclidean(),\n    ## Data for weight fitting\n    weight_type = :convex,\n    tol = 1e-2,\n)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"PS. We chose to define our clustering_params as a NamedTuple in Julia, but that is completely optional and you can use whatever structure suits your case.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using Random: Random\nRandom.seed!(123)\nTulipaClustering.cluster!(\n    connection,\n    clustering_params.period_duration,  # Required\n    clustering_params.num_rep_periods;  # Required\n    clustering_params.method,           # Optional\n    clustering_params.distance,         # Optional\n    clustering_params.weight_type,      # Optional\n    clustering_params.tol,              # Optional\n);","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"These are the tables created by TulipaClustering:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"rep_periods_data\nrep_periods_mapping\nprofiles_rep_periods\ntimeframe_data","category":"page"},{"location":"10-tutorials/30-workflow/#Prepare-data-for-TulipaEnergyModel's-format","page":"Tutorial 7: Workflow","title":"Prepare data for TulipaEnergyModel's format","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Now the fun part starts. We need to create specific tables for Tulipa using our current tables. Again, we remind you that you can create most of these files externally, i.e., you don't have to use DuckDB to join them here. However, defining the workflow in a programmatic way makes it easier to reproduce it in the future.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"We have to define a minimum set of columns for each table, and then the remaining columns will be filled with defaults. Some columns cannot contain missing values (such as the asset or year columns in most tables). For other columns, missing values will be filled with the columns' default.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"warning: Populating with defaults is an explicit step\nAs we'll see in the end of this section, populating the remaining columns with default values is an explicit step and can only be skipped if your data is already correct.","category":"page"},{"location":"10-tutorials/30-workflow/#Year-data","page":"Tutorial 7: Workflow","title":"Year data","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"This data is already correct in the case study and contains a single year.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"FROM year_data\")","category":"page"},{"location":"10-tutorials/30-workflow/#Assets","page":"Tutorial 7: Workflow","title":"Assets","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"First, let's join all assets' basic data. This table goes directly into the asset table for Tulipa.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE asset AS\n    SELECT\n        name AS asset,\n        type,\n        capacity,\n        capacity_storage_energy,\n        is_seasonal,\n    FROM (\n        FROM assets_consumer_basic_data\n        UNION BY NAME\n        FROM assets_conversion_basic_data\n        UNION BY NAME\n        FROM assets_hub_basic_data\n        UNION BY NAME\n        FROM assets_producer_basic_data\n        UNION BY NAME\n        FROM assets_storage_basic_data\n    )\n    ORDER BY asset\n    \",\n)\n\nnice_query(\"FROM asset ORDER BY random() LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Similarly, we join the assets' yearly data:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE t_asset_yearly AS\n    FROM (\n        FROM assets_consumer_yearly_data\n        UNION BY NAME\n        FROM assets_conversion_yearly_data\n        UNION BY NAME\n        FROM assets_hub_yearly_data\n        UNION BY NAME\n        FROM assets_producer_yearly_data\n        UNION BY NAME\n        FROM assets_storage_yearly_data\n    )\n    \",\n)\n\nnice_query(\"FROM t_asset_yearly ORDER BY random() LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Then, the t_asset_yearly table is used to create the three other asset tables that Tulipa requires:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE asset_commission AS\n    SELECT\n        name AS asset,\n        year AS commission_year,\n    FROM t_asset_yearly\n    ORDER by asset\n    \"\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE asset_milestone AS\n    SELECT\n        name AS asset,\n        year AS milestone_year,\n        peak_demand,\n        initial_storage_level,\n        storage_inflows,\n    FROM t_asset_yearly\n    ORDER by asset\n    \"\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE asset_both AS\n    SELECT\n        name AS asset,\n        year AS milestone_year,\n        year AS commission_year, -- Yes, it is the same year twice with different names because it's not a multi-year problem\n        initial_units,\n        initial_storage_units,\n    FROM t_asset_yearly\n    ORDER by asset\n    \"\n)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Here is an example of one of these tables:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"FROM asset_both WHERE initial_storage_units > 0 LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/#Flows","page":"Tutorial 7: Workflow","title":"Flows","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"We repeat the steps above for flows:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE flow AS\n    SELECT\n        from_asset,\n        to_asset,\n        carrier,\n        capacity,\n        is_transport,\n    FROM (\n        FROM flows_assets_connections_basic_data\n        UNION BY NAME\n        FROM flows_transport_assets_basic_data\n    )\n    ORDER BY from_asset, to_asset\n    \",\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE t_flow_yearly AS\n    FROM (\n        FROM flows_assets_connections_yearly_data\n        UNION BY NAME\n        FROM flows_transport_assets_yearly_data\n    )\n    \",\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE flow_commission AS\n    SELECT\n        from_asset,\n        to_asset,\n        year AS commission_year,\n        efficiency,\n    FROM t_flow_yearly\n    ORDER by from_asset, to_asset\n    \"\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE flow_milestone AS\n    SELECT\n        from_asset,\n        to_asset,\n        year AS milestone_year,\n        variable_cost AS operational_cost,\n    FROM t_flow_yearly\n    ORDER by from_asset, to_asset\n    \"\n)\n\nDuckDB.query(\n    connection,\n    \"CREATE TABLE flow_both AS\n    SELECT\n        t_flow_yearly.from_asset,\n        t_flow_yearly.to_asset,\n        t_flow_yearly.year AS milestone_year,\n        t_flow_yearly.year AS commission_year,\n        t_flow_yearly.initial_export_units,\n        t_flow_yearly.initial_import_units,\n    FROM t_flow_yearly\n    LEFT JOIN flow\n      ON flow.from_asset = t_flow_yearly.from_asset\n      AND flow.to_asset = t_flow_yearly.to_asset\n    WHERE flow.is_transport = TRUE -- flow_both must only contain transport flows\n    ORDER by t_flow_yearly.from_asset, t_flow_yearly.to_asset\n    \"\n)","category":"page"},{"location":"10-tutorials/30-workflow/#Assets-profiles","page":"Tutorial 7: Workflow","title":"Assets profiles","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"The assets_profiles table already exists, so we only need to create assets_timeframe_profiles. Since all the data is already in assets_storage_min_max_reservoir_level_profiles, we just copy it over.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE assets_timeframe_profiles AS\n    FROM assets_storage_min_max_reservoir_level_profiles\n    ORDER BY asset, commission_year, profile_name\n    \",\n)","category":"page"},{"location":"10-tutorials/30-workflow/#Partitions","page":"Tutorial 7: Workflow","title":"Partitions","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"The OBZ table uses only uniform time partitions, which makes it easy to create the necessary tables.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"For the assets_rep_periods_partitions, we simply have to copy the partition given by the assets' yearly data for each representative period given rep_periods_data.rep_period and attach a specification = 'uniform' to that table.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE assets_rep_periods_partitions AS\n    SELECT\n        t.name AS asset,\n        t.year,\n        t.partition AS partition,\n        rep_periods_data.rep_period,\n        'uniform' AS specification,\n    FROM t_asset_yearly AS t\n    LEFT JOIN rep_periods_data\n        ON t.year = rep_periods_data.year\n    ORDER BY asset, t.year, rep_period\n    \",\n)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"For the flows_rep_periods_partitions, we need to also compute the expected partition value, which will follow a simple formula. Given a flow (from_asset, to_asset), we look at the partition of both from_asset and to_asset. If the flow is a transport flow, we use the maximum between the partitions of from_asset and to_asset. Otherwise, we use the minimum between these two.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"DuckDB.query(\n    connection,\n    \"CREATE TABLE flows_rep_periods_partitions AS\n    SELECT\n        flow.from_asset,\n        flow.to_asset,\n        t_from.year,\n        t_from.rep_period,\n        'uniform' AS specification,\n        IF(\n            flow.is_transport,\n            greatest(t_from.partition::int, t_to.partition::int),\n            least(t_from.partition::int, t_to.partition::int)\n        ) AS partition,\n    FROM flow\n    LEFT JOIN assets_rep_periods_partitions AS t_from\n        ON flow.from_asset = t_from.asset\n    LEFT JOIN assets_rep_periods_partitions AS t_to\n        ON flow.to_asset = t_to.asset\n        AND t_from.year = t_to.year\n        AND t_from.rep_period = t_to.rep_period\n    \",\n)","category":"page"},{"location":"10-tutorials/30-workflow/#Timeframe-profiles","page":"Tutorial 7: Workflow","title":"Timeframe profiles","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"For the timeframe profiles, we'll use the other profiles table that we haven't touched yet: min_max_reservoir_levels. As with the other profiles, we will first pivot that table to have it in long format. However, we do not cluster these profiles, since the representative periods are already computed. Instead, we will create a temporary table (cte_split_profiles) that converts the timestep that goes from 1 to 8760 into two columns: period, from to 1 to 365 (days) and timestep, from 1 to 24 (hours).","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Finally, the timeframe profiles are computed with the average over period, i.e., each value of a given timeframe profile in a period is the average of 24 hours of the original profile.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"TulipaClustering.transform_wide_to_long!(\n    connection,\n    \"min_max_reservoir_levels\",\n    \"pivot_min_max_reservoir_levels\",\n)\n\nperiod_duration = clustering_params.period_duration\n\nDuckDB.query(\n    connection,\n    \"\n    CREATE TABLE profiles_timeframe AS\n    WITH cte_split_profiles AS (\n        SELECT\n            profile_name,\n            year,\n            1 + (timestep - 1) // $period_duration  AS period,\n            1 + (timestep - 1)  % $period_duration AS timestep,\n            value,\n        FROM pivot_min_max_reservoir_levels\n    )\n    SELECT\n        cte_split_profiles.profile_name,\n        cte_split_profiles.year,\n        cte_split_profiles.period,\n        AVG(cte_split_profiles.value) AS value, -- Computing the average aggregation\n    FROM cte_split_profiles\n    GROUP BY\n        cte_split_profiles.profile_name,\n        cte_split_profiles.year,\n        cte_split_profiles.period\n    ORDER BY\n        cte_split_profiles.profile_name,\n        cte_split_profiles.year,\n        cte_split_profiles.period\n    \",\n)","category":"page"},{"location":"10-tutorials/30-workflow/#obz-populate-with-defaults","page":"Tutorial 7: Workflow","title":"Populate with defaults","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Finally, in many cases, you will need to complete the missing columns with additional information. To simplify this process, we created the populate_with_defaults! function. Please read TulipaEnergyModel's populate with default section for a complete picture.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Here is the before of one of the tables:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"FROM asset_both LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using TulipaEnergyModel: TulipaEnergyModel as TEM\n\nTEM.populate_with_defaults!(connection)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"FROM asset_both LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/#Create-internal-tables-for-the-model-indices","page":"Tutorial 7: Workflow","title":"Create internal tables for the model indices","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"warning: If you skipped ahead\nIf you skipped ahead and have errors here, check out some of the previous steps. Notably, populating with defaults helps solve many issues with missing data and wrong types in the columns.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"info: More general option: run_scenario\nWe split the TulipaEnergyModel part in a few parts, however all these things could be achieved using run_scenario directly instead. We leave the details out of this tutorial to keep it more instructional.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"energy_problem = TEM.EnergyProblem(connection)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Purely out of curiosity, here is the total number of tables that we have:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT COUNT(*) as num_tables, FROM duckdb_tables()\")","category":"page"},{"location":"10-tutorials/30-workflow/#Create-model","page":"Tutorial 7: Workflow","title":"Create model","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Finally, we get to actually use the model.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"model_file_name = joinpath(@__DIR__, \"..\", \"..\", \"new-model.lp\") # hide\noptimizer_parameters = Dict(\n    \"output_flag\" => true,\n    \"mip_rel_gap\" => 0.0,\n    \"mip_feasibility_tolerance\" => 1e-5,\n)\nTEM.create_model!(energy_problem; model_file_name, optimizer_parameters)","category":"page"},{"location":"10-tutorials/30-workflow/#Solve-model","page":"Tutorial 7: Workflow","title":"Solve model","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Last, but not least important, we solve the model:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"TEM.solve_model!(energy_problem)","category":"page"},{"location":"10-tutorials/30-workflow/#Store-primal-and-dual-solution","page":"Tutorial 7: Workflow","title":"Store primal and dual solution","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"The primal and dual solutions are computed when saving the solution with save_solution!, as long as we don't change the default value of compute_duals. Here it is, explicitly:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"TEM.save_solution!(energy_problem; compute_duals = true)","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Now every variable indices table has a column solution, and every constraint has additional columns dual_*, depending on the constraints name.","category":"page"},{"location":"10-tutorials/30-workflow/#Examples-checking-the-primal-and-dual-solutions","page":"Tutorial 7: Workflow","title":"Examples checking the primal and dual solutions","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Select all variables of storage level at representative periods with value greater than 0 at the solution (show only first 5):","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT *\n    FROM var_storage_level_rep_period\n    WHERE solution > 0\n    LIMIT 5\n\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Select all indices related to the balance storage at representative periods when both min_storage_level_rep_period_limit and max_storage_level_rep_period_limit have duals equal to 0.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"SELECT *\n    FROM cons_balance_storage_rep_period\n    WHERE dual_max_storage_level_rep_period_limit = 0\n        AND dual_min_storage_level_rep_period_limit = 0\n    LIMIT 5\n\")","category":"page"},{"location":"10-tutorials/30-workflow/#Data-processing-for-plots-and-dashboard","page":"Tutorial 7: Workflow","title":"Data processing for plots and dashboard","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"This part of the workflow is open for you to do whatever you need. In principle, you can skip this step and go straight to exporting the solution, and then perform your analysis of the solution outside of the DuckDB/Julia environment.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Here is an example of data processing using DuckDB and Julia.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"The table","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"nice_query(\"\nCREATE TEMP TABLE analysis_inter_storage_levels AS\nSELECT\n    var.id,\n    var.asset,\n    var.period_block_start as period,\n    asset.capacity_storage_energy,\n    var.solution / (\n        IF(asset.capacity_storage_energy > 0, asset.capacity_storage_energy, 1)\n    ) AS SoC,\nFROM var_storage_level_over_clustered_year AS var\nLEFT JOIN asset\n    ON var.asset = asset.asset\n\")\nnice_query(\"FROM analysis_inter_storage_levels LIMIT 5\")","category":"page"},{"location":"10-tutorials/30-workflow/#Create-plots","page":"Tutorial 7: Workflow","title":"Create plots","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Now, using the analysis tables from above, we can create plots in Julia:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"using Plots\n\np = plot()\nassets = [\"ES_Hydro_Reservoir\", \"NO_Hydro_Reservoir\", \"FR_Hydro_Reservoir\"]\n\ndf = nice_query(\"SELECT asset, period, SoC\n    FROM analysis_inter_storage_levels\n    WHERE asset in ('ES_Hydro_Reservoir', 'NO_Hydro_Reservoir', 'FR_Hydro_Reservoir')\n\")\n\nplot!(\n    df.period,          # x-axis\n    df.SoC,             # y-axis\n    group = df.asset,   # each asset is a different plot\n    xlabel = \"Period\",\n    ylabel = \"Storage level [p.u.]\",\n    linewidth = 3,\n    dpi = 600,\n)","category":"page"},{"location":"10-tutorials/30-workflow/#step-export","page":"Tutorial 7: Workflow","title":"Export solution","text":"","category":"section"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Finally, we can export the solution to CSV files using the convenience function below:","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"if !isdir(\"obz-outputs\") # hide\nmkdir(\"obz-outputs\")\nTEM.export_solution_to_csv_files(\"obz-outputs\", energy_problem)\nend # hide\nreaddir(\"obz-outputs\")","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Using DuckDB directly it is also possible to export to other formats, such as Parquet.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"Finally, we close the connection. It should also be closed automatically if the connection variable goes out of scope.","category":"page"},{"location":"10-tutorials/30-workflow/","page":"Tutorial 7: Workflow","title":"Tutorial 7: Workflow","text":"close(connection)","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#Tutorial-6:-Multi-year-investments","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Let's explore the multi-year investments in Tulipa. We will talk about discount approaches and different investment methods. The latter is an example for different levels of detail in Tulipa.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#1.-Set-up","page":"Tutorial 6: Multi-year investments","title":"1. Set up","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Paste the code below that add the packages and instantiate your enviroment (if you don't have it already)","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"using Pkg: Pkg       # Julia package manager (like pip for Python)\nPkg.activate(\".\")    # Creates and activates the project in the new folder - notice it creates Project.toml and\n# Or enter package mode (type ']') and run 'pkg> activate .'\n# Manifest.toml in your folder for reproducibility\nPkg.add(\"TulipaEnergyModel\")\nPkg.add(\"TulipaIO\")\nPkg.add(\"DuckDB\")\nPkg.add(\"DataFrames\")\nPkg.add(\"Plots\")\nPkg.instantiate()","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Paste the code below that loads the packages in the file","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"import TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nusing DuckDB\nusing DataFrames\nusing Plots","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#2.-The-problem-and-explore-the-files","page":"Tutorial 6: Multi-year investments","title":"2. The problem & explore the files","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"We are modeling two milestone years 2030 and 2050. The system has some initial wind capacity built in 2020, the model can choose to invest in wind in both milestone years.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"There are two pairs of input-output files, we start with the simple one.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#3.-Discount-parameters","page":"Tutorial 6: Multi-year investments","title":"3. Discount parameters","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Run TEM","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"connection = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-6-simple-method\"\noutput_dir = \"my-awesome-energy-system/tutorial-6-simple-method/results\"\nTIO.read_csv_folder(connection, input_dir)\nTEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(\n        connection;\n        model_parameters_file = joinpath(@__DIR__, input_dir, \"model-parameters-example.toml\"),\n        output_folder = output_dir,\n)","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"There is a new file model-parameters-example.toml. It contains model-wide parameters, in this case:","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"discount_rate = energy_problem.model_parameters.discount_rate\ndiscount_year = energy_problem.model_parameters.discount_year","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Check discounting parameters calculated internally by TEM.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"df_objective = filter(:asset => ==(\"wind\"), TIO.get_table(connection, \"t_objective_assets\"))[:,\n    [:asset, :milestone_year, :investment_cost, :annualized_cost, :salvage_value,\n     :investment_year_discount, :weight_for_asset_investment_discount, :weight_for_operation_discounts]]\n\ndf_asset = filter(:asset => ==(\"wind\"), TIO.get_table(connection, \"asset\"))[:,\n    [:asset, :technical_lifetime, :economic_lifetime]]\n\ndf = leftjoin(df_objective, df_asset, on = :asset)","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#4.-Different-levels-of-details:-simple-method-vs-compact-method","page":"Tutorial 6: Multi-year investments","title":"4. Different levels of details: simple method vs compact method","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Remember that we have wind built in 2020 - does it have the same profiles as 2030? Let's check it out.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"plot()\nwind_profiles = filter(row -> occursin(\"wind\", row.profile_name) && row.year == 2030,\n    TIO.get_table(connection, \"profiles_rep_periods\"))\n\nfor pname in unique(wind_profiles.profile_name)\n    subdf = wind_profiles[wind_profiles.profile_name .== pname, :]\n    plot!(subdf.value, label=\"$(pname), year 2030\")\nend\nxlabel!(\"Time\")\nylabel!(\"Capacity factor\")","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"(Image: wind_profiles)","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"So...the wind built in 2020 has a worse profile. How does it play a role in the investment methods?","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#Simple-method","page":"Tutorial 6: Multi-year investments","title":"Simple method","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Let's try the simple method first.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"connection = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-6-simple-method\"\noutput_dir = \"my-awesome-energy-system/tutorial-6-simple-method/results\"\nTIO.read_csv_folder(connection, input_dir)\nTEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(\n        connection;\n        model_parameters_file = joinpath(@__DIR__, input_dir, \"model-parameters-example.toml\"),\n        output_folder = output_dir,\n    )","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Check initial capacity - under the simple method, we will not be able to differentiate units built in other years (than milestone years), they will simply be considered the same as the units built in the milestone year, which means that we will not use the 2020 profile.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"filter(row -> row.asset==\"wind\" && row.milestone_year == 2030, TIO.get_table(connection, \"asset_both\"))","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Check the objective value and investments.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"energy_problem.objective_value\nfilter(row -> row.asset==\"wind\", TIO.get_table(connection, \"var_assets_investment\"))","category":"page"},{"location":"10-tutorials/17-multi-year-investments/#Compact-method","page":"Tutorial 6: Multi-year investments","title":"Compact method","text":"","category":"section"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Now try the compact method.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"connection = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-6-compact-method\"\noutput_dir = \"my-awesome-energy-system/tutorial-6-compact-method/results\"\nTIO.read_csv_folder(connection, input_dir)\nTEM.populate_with_defaults!(connection)\nenergy_problem = TEM.run_scenario(\n        connection;\n        model_parameters_file = joinpath(@__DIR__, input_dir, \"model-parameters-example.toml\"),\n        output_folder = output_dir,\n    )","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"warning: Warning\nSince the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Check initial capacity - units built in different years are explicitly listed, meaning that their corresponding profiles are also considered.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"filter(row -> row.asset==\"wind\" && row.milestone_year == 2030, TIO.get_table(connection, \"asset_both\"))","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"Check the objective value and investments.","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"energy_problem.objective_value\nfilter(row -> row.asset==\"wind\", TIO.get_table(connection, \"var_assets_investment\"))","category":"page"},{"location":"10-tutorials/17-multi-year-investments/","page":"Tutorial 6: Multi-year investments","title":"Tutorial 6: Multi-year investments","text":"We use the worse but correct profile for wind built in 2020, leading to more required investments and hence higher costs.","category":"page"},{"location":"10-tutorials/12-basics/#basic-example","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"","category":"section"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Welcome to the first tutorial, here you will learn the basics of how to run TulipaEnergyModel. Good luck! 🌷","category":"page"},{"location":"10-tutorials/12-basics/#Load-data-and-run-Tulipa","page":"Tutorial 1: The Basics","title":"Load data and run Tulipa","text":"","category":"section"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"If you have not done so already, please follow the steps in the pre-tutorial first. You should have a VS Code project set up before starting this tutorial.","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Ensure you are using the necessary packages by running the lines below:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"import TulipaIO as TIO\nimport TulipaEnergyModel as TEM\nusing DuckDB\nusing DataFrames\nusing Plots","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"tip: Tip\nFollow along in this section, copy-pasting into your my_workflow.jl file.\nIn VS Code, you can press (CTRL+ENTER) to run the current line,\n(SHIFT+ENTER) to run the current line and go to the next line.\nTo run multiple lines together, you need to highlight the part you want to run first,\nand then hit (CTRL+ENTER) or (SHIFT+ENTER).\nOr paste everything and press the run arrow (top right in VS Code) to run the entire file.","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"We need to create a connection to DuckDB and point to the input and output folders:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"connection = DBInterface.connect(DuckDB.DB)\ninput_dir = \"my-awesome-energy-system/tutorial-1\"\noutput_dir = \"my-awesome-energy-system/tutorial-1/results\"","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Since the output directory does not exist yet, we need to create the 'results' folder inside our tutorial folder, otherwise it will error later.","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Let's use TulipaIO to read the files and list them:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"TIO.read_csv_folder(connection, input_dir)\n\nTIO.show_tables(connection)  # View all the table names in the DuckDB connection\n# If your output window isn't large enough, it'll be cut-off\n# Just expand the window and rerun the line","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Now try viewing a specific table:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"TIO.get_table(connection, \"asset\") # Or any other table name","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Add any missing columns and fill them with defaults:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"TEM.populate_with_defaults!(connection)\n\n# Explore the tables in DuckDB (again)\nTIO.get_table(connection, \"asset\")\n# Notice there are now a lot of new columns filled with default values","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Run, baby run!","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"energy_problem =\n    TEM.run_scenario(connection; output_folder=output_dir)","category":"page"},{"location":"10-tutorials/12-basics/#Explore-the-results","page":"Tutorial 1: The Basics","title":"Explore the results","text":"","category":"section"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Which files were created in the output folder?\nTake a minute to explore them.","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Because we specified an output folder to run_scenario, it automatically exported the CSVs.\nBut instead of exporting, you can also explore results in Julia!","category":"page"},{"location":"10-tutorials/12-basics/#Basic-Plots-in-Julia","page":"Tutorial 1: The Basics","title":"Basic Plots in Julia","text":"","category":"section"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Take a look at the electricity production from the \"wind\" asset that flows to the \"e_demand\" asset:","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"using DataFrames\nusing Plots\n\nflows = TIO.get_table(connection, \"var_flow\") # Put the \"var_flow\" table from DuckDB into a Julia dataframe called \"flows\"\n\nfrom_asset = \"wind\"\nto_asset = \"e_demand\"\nyear = 2030\nrep_period = 1\n\n\nfiltered_flow = filter(\n    row ->\n        row.from_asset == from_asset &&\n            row.to_asset == to_asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    flows,\n)\n\nplot(\n    filtered_flow.time_block_start,\n    filtered_flow.solution;\n    label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    dpi=600,\n)","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"For the prices, work with the dual of the constraint.","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"balance = TIO.get_table(connection, \"cons_balance_consumer\")\n\nasset = \"e_demand\"\nyear = 2030\nrep_period = 1\n\nfiltered_asset = filter(\n    row ->\n        row.asset == asset &&\n            row.year == year &&\n            row.rep_period == rep_period,\n    balance,\n)\n\nplot(\n    filtered_asset.time_block_start,\n    filtered_asset.dual_balance_consumer;\n    #label=string(from_asset, \" -> \", to_asset),\n    xlabel=\"Hour\",\n    ylabel=\"[MWh]\",\n    ylims=(0,200),\n    #xlims=(0, 168),\n    dpi=600,\n)","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"info: Test Your Knowledge\nInspect the prices in the plot. Notice how the prices mostly match the operational costs of the dispatchable assets. However, there is an outlier. Can you explain the prices of 153.8462€/MWh in the e_demand? Hint: consider the interlinkage between hydrogen and electricity demand","category":"page"},{"location":"10-tutorials/12-basics/","page":"Tutorial 1: The Basics","title":"Tutorial 1: The Basics","text":"Another important aspect to consider is that we are currently not allowing the model to invest in any of the technologies. It has to solve the energy problem with the currently allocated capacities. There is a column in the asset-milestone.csv file that requires true or false values for whether an asset is investable or not. Try changing the value in this column for the wind asset to true and run the model again. What differences do you see?","category":"page"},{"location":"20-user-guide/00-getting-started/#getting-started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Pages = [\"00-getting-started.md\"]\nDepth = [2, 3]","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Let's get you set up! This will only take a few minutes.","category":"page"},{"location":"20-user-guide/00-getting-started/#Installing-Julia-and-an-Editor","page":"Getting Started","title":"Installing Julia and an Editor","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"To use Tulipa, you first need to install the open-source Julia programming language.","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Then consider installing a user-friendly code editor, such as VSCode. Otherwise you will be working in the terminal/command prompt.","category":"page"},{"location":"20-user-guide/00-getting-started/#Installing-Tulipa","page":"Getting Started","title":"Installing Tulipa","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/#Starting-Julia","page":"Getting Started","title":"Starting Julia","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Choose one:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"In VSCode: Press CTRL+Shift+P and then Enter to start a Julia REPL.\nIn the terminal: Type julia and press Enter","category":"page"},{"location":"20-user-guide/00-getting-started/#Adding-Tulipa-and-dependencies","page":"Getting Started","title":"Adding Tulipa and dependencies","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"In Julia:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Press ] to enter package mode, then run:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"pkg> add TulipaEnergyModel  # The model builder\npkg> add TulipaIO           # For data handling","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"info: Info\nMake sure your project environment (folder where you are working) is not called TulipaEnergyModel or you will get a name conflict error when you try to add the package.","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Tulipa relies on DuckDB for data-handling:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"pkg> add DuckDB","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Press backspace to return to Julia mode","category":"page"},{"location":"20-user-guide/00-getting-started/#Using-packages-in-your-project","page":"Getting Started","title":"Using packages in your project","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Now that the packages are installed, you need to activate them in your project by running the code below.","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"using TulipaEnergyModel, TulipaIO, DuckDB","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"info: Info\nYou should always have this line at the top of your code, specifying any packages you want to use.","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"To check if the packages are installed and active, try accessing the documentation of a package:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Press ? to enter help mode, then:","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"# Search the documentation for a function from TulipaEnergyModel\nhelp?> save_solution!","category":"page"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"You should see the documentation for the save_solution! function. If Julia says it does not exist, that means TulipaEnergyModel is not in your environment (you need to activate it with add and using as described above).","category":"page"},{"location":"20-user-guide/00-getting-started/#Next-Step","page":"Getting Started","title":"Next Step","text":"","category":"section"},{"location":"20-user-guide/00-getting-started/","page":"Getting Started","title":"Getting Started","text":"Now that you're all set up, head over to our Beginner Tutorials to run your first analyses! 🌷","category":"page"},{"location":"20-user-guide/60-structures/#structures","page":"Internal Model Structures","title":"Internal Model Structures","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"Pages = [\"60-structures.md\"]\nDepth = [2, 3]","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The list of relevant structures used in this package are listed below:","category":"page"},{"location":"20-user-guide/60-structures/#energy-problem","page":"Internal Model Structures","title":"EnergyProblem","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The EnergyProblem structure is a wrapper around various other relevant structures. It hides the complexity behind the energy problem, making the usage more friendly, although more verbose.","category":"page"},{"location":"20-user-guide/60-structures/#Fields","page":"Internal Model Structures","title":"Fields","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"db_connection: A DuckDB connection to the input tables in the model.\nvariables: A dictionary of TulipaVariables containing the variables of the model.\nexpressions: A dictionary of TulipaExpressions containing the expressions of the model attached to tables.\nconstraints: A dictionary of TulipaConstraints containing the constraints of the model.\nprofiles: Holds the profiles per rep_period or over_clustered_year in dictionary format. See ProfileLookup.\nmodel_parameters: A ModelParameters structure to store all the parameters that are exclusive of the model.\nmodel: A JuMP.Model object representing the optimization model.\nsolved: A boolean indicating whether the model has been solved or not.\nobjective_value: The objective value of the solved problem (Float64).\ntermination_status: The termination status of the optimization model.","category":"page"},{"location":"20-user-guide/60-structures/#Constructor","page":"Internal Model Structures","title":"Constructor","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The EnergyProblem can also be constructed using the minimal constructor below.","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"EnergyProblem(connection): Constructs a new EnergyProblem object with the given connection that has been created and the data loaded into it using TulipaIO.","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"See the basic example tutorial to see how these can be used.","category":"page"},{"location":"20-user-guide/60-structures/#timeframe","page":"Internal Model Structures","title":"Timeframe","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The timeframe is the total period we want to analyze with the model. Usually this is a year, but it can be any length of time. A timeframe has two fields:","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"num_periods: The timeframe is defined by a certain number of periods. For instance, a year can be defined by 365 periods, each describing a day.\nmap_periods_to_rp: Indicates the periods of the timeframe that map into a representative period and the weight of the representative period to construct that period.","category":"page"},{"location":"20-user-guide/60-structures/#representative-periods","page":"Internal Model Structures","title":"Representative Periods","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The timeframe (e.g., a full year) is described by a selection of representative periods, for instance, days or weeks, that nicely summarize other similar periods. For example, we could model the year into 3 days, by clustering all days of the year into 3 representative days. Each one of these days is called a representative period. TulipaEnergyModel.jl has the flexibility to consider representative periods of different lengths for the same timeframe (e.g., a year can be represented by a set of 4 days and 2 weeks). To obtain the representative periods, we recommend using TulipaClustering.","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"A representative period has three fields:","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"weight: Indicates how many representative periods are contained in the timeframe; this is inferred automatically from map_periods_to_rp in the timeframe.\ntimesteps: The number of timesteps blocks in the representative period.\nresolution: The duration in time of each timestep.","category":"page"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"The number of timesteps and resolution work together to define the coarseness of the period. Nothing is defined outside of these timesteps; for instance, if the representative period represents a day and you want to specify a variable or constraint with a coarseness of 30 minutes. You need to define the number of timesteps to 48 and the resolution to 0.5.","category":"page"},{"location":"20-user-guide/60-structures/#time-blocks","page":"Internal Model Structures","title":"Time Blocks","text":"","category":"section"},{"location":"20-user-guide/60-structures/","page":"Internal Model Structures","title":"Internal Model Structures","text":"A time block is a range for which a variable or constraint is defined. It is a range of numbers, i.e., all integer numbers inside an interval. Time blocks are used for the periods in the timeframe and the timesteps in the representative period. Time blocks are disjunct (not overlapping), but do not have to be sequential.","category":"page"},{"location":"70-reference/#reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"70-reference/","page":"API Reference","title":"API Reference","text":"Pages = [\"70-reference.md\"]","category":"page"},{"location":"70-reference/#TulipaEnergyModel.DataValidationException","page":"API Reference","title":"TulipaEnergyModel.DataValidationException","text":"DataValidationException\n\nException related to data validation of the Tulipa Energy Model input data.\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.EnergyProblem","page":"API Reference","title":"TulipaEnergyModel.EnergyProblem","text":"EnergyProblem\n\nStructure to hold all parts of an energy problem. It is a wrapper around various other relevant structures. It hides the complexity behind the energy problem, making the usage more friendly, although more verbose.\n\nFields\n\ndb_connection: A DuckDB connection to the input tables in the model.\nvariables: A dictionary of TulipaVariables containing the variables of the model.\nexpressions: A dictionary of TulipaExpressions containing the expressions of the model attached to tables.\nconstraints: A dictionary of TulipaConstraints containing the constraints of the model.\nprofiles: Holds the profiles per rep_period or over_clustered_year in dictionary format. See ProfileLookup.\nmodel_parameters: A ModelParameters structure to store all the parameters that are exclusive of the model.\nmodel: A JuMP.Model object representing the optimization model.\nsolved: A boolean indicating whether the model has been solved or not.\nobjective_value: The objective value of the solved problem (Float64).\ntermination_status: The termination status of the optimization model.\n\nConstructor\n\nEnergyProblem(connection): Constructs a new EnergyProblem object with the given connection.\n\nThe constraints_partitions field is computed from the representative_periods, and the other fields are initialized with default values.\n\nSee the basic example tutorial to see how these can be used.\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.ModelParameters","page":"API Reference","title":"TulipaEnergyModel.ModelParameters","text":"ModelParameters(;key = value, ...)\nModelParameters(path; ...)\nModelParameters(connection; ...)\nModelParameters(connection, path; ...)\n\nStructure to hold the model parameters. Some values are defined by default and some required explicit definition.\n\nIf path is passed, it is expected to be a string pointing to a TOML file with a key = value list of parameters. Explicit keyword arguments take precedence.\n\nIf connection is passed, the default discount_year is set to the minimum of all milestone years. In other words, we check for the table year_data for the column year where the column is_milestone is true. Explicit keyword arguments take precedence.\n\nIf both are passed, then path has preference. Explicit keyword arguments take precedence.\n\nParameters\n\ndiscount_rate::Float64 = 0.0: The model discount rate.\ndiscount_year::Int: The model discount year.\npower_system_base::Float64 = 100.0: The power system base in MVA.\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.ProfileLookup","page":"API Reference","title":"TulipaEnergyModel.ProfileLookup","text":"Structure to hold the dictionaries of profiles.\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.TulipaConstraint","page":"API Reference","title":"TulipaEnergyModel.TulipaConstraint","text":"Structure to hold the JuMP constraints for the TulipaEnergyModel\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.TulipaExpression","page":"API Reference","title":"TulipaEnergyModel.TulipaExpression","text":"Structure to hold some JuMP expressions that are not attached to constraints but are attached to a table.\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.TulipaTabularIndex","page":"API Reference","title":"TulipaEnergyModel.TulipaTabularIndex","text":"TulipaTabularIndex\n\nAbstract structure for TulipaVariable, TulipaConstraint and TulipaExpression. All deriving types must satisfy:\n\nHave fields\nindices::DuckDB.QueryResult\ntable_name::String\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel.TulipaVariable","page":"API Reference","title":"TulipaEnergyModel.TulipaVariable","text":"Structure to hold the JuMP variables for the TulipaEnergyModel\n\n\n\n\n\n","category":"type"},{"location":"70-reference/#TulipaEnergyModel._append_variable_ids-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel._append_variable_ids","text":"_append_variable_ids(\n    connection,\n    constraint_table_name,\n    variables_to_append,\n)\n\nCreate table containing all rows of the given constraint (constraint_table_name) and their matching variable ids of the variables in variables_to_append\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._check_if_table_exists-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel._check_if_table_exists","text":"_check_if_table_exists(connection, table_name)\n\nCheck if table table_name exists in the connection.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._create_group_table_if_not_exist!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel._create_group_table_if_not_exist!","text":"_create_group_table_if_not_exist!(\n    connection,\n    table_name,\n    grouped_table_name,\n    group_by_columns,\n    array_agg_columns;\n    rename_columns = Dict(),\n    order_agg_by = \"id\",\n)\n\nCreate a grouped table grouping the table_name into the grouped_table_name. The group_by_columns are the columns that are used in the group by (e.g., asset, year, repperiod), and the `arrayaggcolumns` are the columns that are aggregated into arrays (e.g., id, timeblockstart, timeblock_end).\n\nIt is expected that the original table has an id column, which is used in the ordering of the array_agg_columns. Otherwise, please pass the argument order_agg_by with the column that should be used for this ordering.\n\nIf one of the columns has to be renamed, use the rename_columns dictionary.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._create_variables_from_indices!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel._create_variables_from_indices!","text":"_create_variables_from_indices!(\nmodel,\nvariables,\nname,\nkeys_from_row;\nlower_bound_from_row = row -> -Inf,\nupper_bound_from_row = row -> Inf,\ninteger_from_row = row -> false,\n\n)\n\nThis function creates variables by iterating over the variable indices, where each variable can have different properties determined by the index/row data.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._create_variables_from_specifications!-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel._create_variables_from_specifications!","text":"_create_variables_from_specifications!(model, variables, specifications)\n\nCreates variables based on a dictionary of specifications. Each specification should contain keysfromrow, lowerboundfromrow, upperboundfromrow, and integerfromrow functions.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._get_decommission_variable_specifications-Tuple{}","page":"API Reference","title":"TulipaEnergyModel._get_decommission_variable_specifications","text":"_get_decommission_variable_specifications()\n\nReturns a dictionary containing specifications for all decommission variables. Each specification includes the keys extraction function, bounds functions, and integer constraint function.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._get_investment_variable_specifications-Tuple{}","page":"API Reference","title":"TulipaEnergyModel._get_investment_variable_specifications","text":"_get_investment_variable_specifications()\n\nReturns a dictionary containing specifications for all investment variables. Each specification includes the keys extraction function, bounds functions, and integer constraint function.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._profile_aggregate-Tuple{Any, Tuple, Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel._profile_aggregate","text":"_profile_aggregate(profiles, tuple_key, time_block, agg_functions, default_value)\n\nAggregates the profiles[tuple_key] over the time_block using the agg_function function. If the profile does not exist, uses default_value instead of each profile value.\n\nprofiles should be a dictionary of profiles, and tuple_key should be either (profile_name, year, rep_period) for the profiles of representative periods or (profile_name, year) for the profiles over clustered years.\n\nIf profiles[tuple_key] exists, then this function computes the aggregation of V = profiles[tuple_key] over the range time_block using the aggregator agg_function, i.e., agg_function(V[time_block]). If it does not exist, then V[time_block] is substituted by a vector of the corresponding size and default_value.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel._sql_arguments_for_defaults-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel._sql_arguments_for_defaults","text":"create_str, select_str = _sql_arguments_for_defaults(connection, table_name, table_schema)\n\nReturns the strings to complement the table creation informing the name, type and possible default, and the select with coalescing and type casting.\n\nThe table_schema should be the complete schema, not only the type. For instance, TulipaEnergyModel.schema[table_name].\n\nFor each column of the table_name table, the creation string is like\n\nCOLUMN_NAME COLUMN_TYPE\n-- For a column with no default type\n\nor\n\nCOLUMN_NAME COLUMN_TYPE DEFAULT COLUMN_DEFAULT\n-- For a column with default type\n\nand the selection string is like\n\nCOLUMN_NAME::COLUMN_TYPE\n-- For an existing column with no default type\n\nor\n\nCOALESCE(COLUMN_NAME::COLUMN_TYPE, COLUMN_DEFAULT) AS COLUMN_NAME\n-- For an existing column with default type\n\nor\n\nCOLUMN_DEFAULT::COLUMN_TYPE AS COLUMN_NAME\n-- For a non-existing column, just use the default type\n\nThe name, type, and defaults are based on the existing table, but overridden by the table_schema.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_capacity_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_capacity_constraints!","text":"add_capacity_constraints!(connection, model, expressions, constraints, profiles)\n\nAdds the capacity constraints for all asset types to the model\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_capacity_outgoing_semi_compact_method_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_capacity_outgoing_semi_compact_method_constraints!","text":"add_capacity_outgoing_semi_compact_method_constraints!(connection, model, expressions, constraints, profiles)\n\nAdds the capacity constraints for the semi-compact investment method.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_consumer_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_consumer_constraints!","text":"add_consumer_constraints!(connection, model, constraints, profiles)\n\nAdds the consumer asset constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_conversion_constraints!-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_conversion_constraints!","text":"add_conversion_constraints!(connection, model, constraints)\n\nAdds the conversion asset constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_dc_power_flow_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_dc_power_flow_constraints!","text":"add_dc_power_flow_constraints!(connection, model, variables, constraints, model_parameters)\n\nAdds the dc power flow constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_decommission_variables!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_decommission_variables!","text":"add_decommission_variables!(model, variables)\n\nAdds decommission variables to the optimization model, and sets bounds on selected variables based on the input data.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_energy_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_energy_constraints!","text":"add_energy_constraints!(connection, model, constraints, profiles)\n\nAdds the energy constraints for assets within the period blocks of the timeframe (overclusteredyear) to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_expression_terms_over_clustered_year_constraints!-Tuple{Any, TulipaConstraint, TulipaVariable, Any}","page":"API Reference","title":"TulipaEnergyModel.add_expression_terms_over_clustered_year_constraints!","text":"add_expression_terms_over_clustered_year_constraints!(\n    connection,\n    cons,\n    flow,\n    profiles;\n    is_storage_level = false,\n)\n\nComputes the incoming and outgoing expressions per row of df_inter for the constraints that are between (inter) the representative periods.\n\nThis function is only used internally in the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_expression_terms_rep_period_constraints!-Tuple{Any, TulipaConstraint, TulipaVariable, Any}","page":"API Reference","title":"TulipaEnergyModel.add_expression_terms_rep_period_constraints!","text":"add_expression_terms_rep_period_constraints!(\n    connection,\n    cons::TulipaConstraint,\n    flow::TulipaVariable,\n    workspace;\n    use_highest_resolution = true,\n    multiply_by_duration = true,\n    add_min_outgoing_flow_duration = false,\n    multiply_by_capacity_coefficient = false,\n    include_commission_year = false,\n)\n\nComputes the incoming and outgoing expressions per row of cons for the constraints that are within the representative periods.\n\nIncludecommissionyear is only used for the constraints regarding the flows for the semi-compact investment method. If true, the expression will include the commission year of the flows. If false (the default), it will only use the year (i.e., milestone_year).\n\nThis function is only used internally in the model.\n\nThis strategy is based on the replies in this discourse thread:\n\nhttps://discourse.julialang.org/t/help-improving-the-speed-of-a-dataframes-operation/107615/23\n\nImplementation\n\nThis expression computation uses a workspace to store all variables defined for each timestep. The idea of this algorithm is to append all variables defined at time timestep in workspace[timestep] and then aggregate then for the constraint time block.\n\nThe algorithm works like this:\n\n1. Loop over each group of (asset, year, rep_period)\n1.1. Loop over each variable in the group: (var_id, var_time_block_start, var_time_block_end)\n1.1.1. Loop over each timestep in var_time_block_start:var_time_block_end\n1.1.1.1. Compute the coefficient of the variable based on the rep_period resolution and the variable efficiency\n1.1.1.2. Store (var_id, coefficient) in workspace[timestep]\n1.2. Loop over each constraint in the group: (cons_id, cons_time_block_start, cons_time_block_end)\n1.2.1. Aggregate all variables in workspace[timestep] for timestep in the time block to create a list of variable ids and their coefficients [(var_id1, coef1), ...]\n1.2.2. Compute the expression using the variable container, the ids and coefficients\n\nNote:\n\nOn step 1.2.1, the aggregation can be either by uniqueness or not, i.e., if the variable happens in more that one workspace[timestep], should we add up the coefficients or not. This is defined by the keyword multiply_by_duration\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_flow_variables!-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_flow_variables!","text":"add_flow_variables!(connection, model, variables)\n\nAdds flow variables to the optimization model based on data from the variables. The flow variables are created using the @variable macro for each row in the :flow table.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_flows_relationships_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_flows_relationships_constraints!","text":"add_flows_relationships_constraints!(connection, model, variables, constraints)\n\nAdds the flows relationships constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_group_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_group_constraints!","text":"add_group_constraints!(connection, model, variables, constraints)\n\nAdds group constraints for assets that share a common limits or bounds.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_hub_constraints!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_hub_constraints!","text":"add_hub_constraints!(model, constraints)\n\nAdds the hub asset constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_investment_variables!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_investment_variables!","text":"add_investment_variables!(model, variables)\n\nAdds investment variables to the optimization model, and sets bounds on selected variables based on the input data.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_limit_decommission_compact_method_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_limit_decommission_compact_method_constraints!","text":"add_limit_decommission_compact_method_constraints!(connection, model, expressions, constraints)\n\nAdds the lower bound for the available capacity of decommissionable assets for the compact investment method. This is used to give a upper bound for the decommission variable.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_power_flow_variables!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_power_flow_variables!","text":"add_power_flow_variables!(model, variables)\n\nAdds power flow variables to the optimization model based on the :electricity_angle indices.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_ramping_constraints!-NTuple{6, Any}","page":"API Reference","title":"TulipaEnergyModel.add_ramping_constraints!","text":"add_ramping_and_unit_commitment_constraints!(\n    connection,\n    model,\n    variables,\n    expressions,\n    constraints,\n    profiles\n)\n\nAdds the ramping constraints for producer and conversion assets where ramping = true in assets_data\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_shut_down_upper_bound_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_shut_down_upper_bound_constraints!","text":"add_shut_down_upper_bound_constraints!(model, constraints)\n\nAdds the shut down constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_start_up_and_shut_down_variables!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_start_up_and_shut_down_variables!","text":"add_start_up_and_shut_down_variables!(model, variables)\n\nAdds 3var UC variables to the optimization model based on the :start_up and :shut_down indices. Additionally, variables are constrained to be integers based on the unit_commitment_integer property.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_start_up_upper_bound_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_start_up_upper_bound_constraints!","text":"add_start_up_upper_bound_constraints!(model, constraints)\n\nAdds the start up upper bound constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_storage_constraints!-NTuple{6, Any}","page":"API Reference","title":"TulipaEnergyModel.add_storage_constraints!","text":"add_storage_constraints!(connection, model, variables, expressions, constraints, profiles)\n\nAdds the storage asset constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_storage_variables!-Tuple{Any, Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_storage_variables!","text":"add_storage_variables!(connection, model, variables)\n\nAdds storage-related variables to the optimization model, including storage levels for both within rep-period and over-clustered-year, as well as charging state variables. The function also optionally sets binary constraints for certain charging variables based on storage methods.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_transport_constraints!-NTuple{6, Any}","page":"API Reference","title":"TulipaEnergyModel.add_transport_constraints!","text":"add_transport_constraints!(connection, model, variables, expressions, constraints, profiles)\n\nAdds the transport flow constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_uc_logic_constraints!-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.add_uc_logic_constraints!","text":"add_uc_logic_constraints!(model, constraints)\n\nAdds the unit commitment logic constraint (i.e., start up - shut down = units_on difference) to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_unit_commitment_variables!-Tuple{Any, Any}","page":"API Reference","title":"TulipaEnergyModel.add_unit_commitment_variables!","text":"add_unit_commitment_variables!(model, variables)\n\nAdds unit commitment variables to the optimization model based on the :units_on indices. Additionally, variables are constrained to be integers based on the unit_commitment_integer property.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.add_vintage_flow_sum_constraints!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.add_vintage_flow_sum_constraints!","text":"add_vintage_flow_sum_constraints!(connection, model, variables, constraints)\n\nAdds the vintage flow sum constraints to the model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.attach_coefficient!-Tuple{TulipaConstraint, Symbol, Any}","page":"API Reference","title":"TulipaEnergyModel.attach_coefficient!","text":"attach_coefficient!(cons, name, container)\n\nAttach a coefficient named name stored in container. This checks that the container length matches the stored indices number of rows.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.attach_constraint!-Tuple{JuMP.Model, TulipaConstraint, Symbol, Vector{<:JuMP.ConstraintRef}}","page":"API Reference","title":"TulipaEnergyModel.attach_constraint!","text":"attach_constraint!(model, cons, name, container)\n\nAttach a constraint named name stored in container, and set model[name] = container. This checks that the container length matches the stored indices number of rows.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.attach_expression!-Tuple{TulipaEnergyModel.TulipaTabularIndex, Symbol, Vector{JuMP.AffExpr}}","page":"API Reference","title":"TulipaEnergyModel.attach_expression!","text":"attach_expression!(cons_or_expr, name, container)\nattach_expression!(model, cons_or_expr, name, container)\n\nAttach a expression named name stored in container, and optionally set model[name] = container. This checks that the container length matches the stored indices number of rows.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.attach_expression_on_constraints_grouping_variables!-Tuple{Any, TulipaConstraint, TulipaVariable, Any, Any}","page":"API Reference","title":"TulipaEnergyModel.attach_expression_on_constraints_grouping_variables!","text":"attach_expression_on_constraints_grouping_variables!(\n    connection,\n    constraint,\n    variable,\n    expr_name;\n    agg_strategy\n)\n\nComputes the intersection of the constraint and variable grouping by (:asset, :year, :rep_period).\n\nThe intersection is made on time blocks, so both the constraint table and the variable table must have columns id, timeblockstart and timeblockend.\n\nThe variable expr_name will be the name of the attached expression.\n\nThe agg_strategy must be either :sum, :mean, and :unique_sum, indicating how to aggregate the variables for a given constraint time block.\n\nImplementation\n\nThe expression uses a workspace to store all variables defined for each timestep. The idea of this algorithm is to append all variables defined at time timestep in workspace[timestep] and then aggregate then for the constraint time block.\n\nThe algorithm works like this:\n\nLoop over each group of (asset, year, rep_period)\n\n1.1. Loop over each variable in the group: (varid, vartimeblockstart, vartimeblockend) 1.1.1. Loop over each timestep in vartimeblockstart:vartimeblockend 1.1.1.1. Compute the coefficient of the variable based on the repperiod   resolution and the variable efficiency 1.1.1.2. Store (varid, coefficient) in workspace[timestep] 1.2. Loop over each constraint in the group: (consid, constimeblockstart, constimeblockend) 1.2.1. Aggregate all variables in workspace[timestep] for timestep in the time   block to create a list of variable ids and their coefficients [(var_id1, coef1), ...] 1.2.2. Compute the expression using the variable container, the ids and coefficients\n\nNotes:\n\nOn step 1.2.1, the aggregation can be by either\n:sum - add the coefficients\n:mean - add the coefficients and divide by number of times the variable appears\n:unique_sum - use 1.0 for the coefficient (this is not robust)\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.compute_dual_variables!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.compute_dual_variables!","text":"compute_dual_variables!(model)\n\nCompute the dual variables for the given model.\n\nIf the model does not have dual variables, this function fixes the discrete variables, optimizes the model, and then computes the dual variables.\n\nArguments\n\nmodel: The model for which to compute the dual variables.\n\nReturns\n\nA named tuple containing the dual variables of selected constraints.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.create_internal_tables!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.create_internal_tables!","text":"create_internal_tables!(connection)\n\nCreates internal tables.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.create_merged_tables!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.create_merged_tables!","text":"create_merged_tables!(connection)\n\nCreate the internal tables of merged flows and assets time partitions to be used in the computation of the lowest and highest resolution tables. The inputs tables are the flows table flow_time_resolution_rep_period, the assets table asset_time_resolution_rep_period and the flows_relationships. All merged tables have the same columns: asset, year, rep_period, time_block_start, and time_block_end. Given a \"group\" (asset, year, rep_period), the table will have the list of all partitions that should be used to compute the resolution tables. These are the output tables:\n\nmerged_in_flows: Set asset = from_asset and drop to_asset from flow_time_resolution_rep_period.\nmerged_out_flows: Set asset = to_asset and drop from_asset from flow_time_resolution_rep_period.\nmerged_assets_and_out_flows: Union of merged_out_flows and asset_time_resolution_rep_period.\nmerged_all_flows: Union (i.e., vertically concatenation) of the tables above.\nmerged_all: Union of merged_all_flows and asset_time_resolution_rep_period.\nmerged_flows_relationship: Set asset from flow_time_resolution_rep_period depending on flows_relationships\n\nThis function is intended for internal use.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.create_model!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.create_model!","text":"create_model!(energy_problem; kwargs...)\n\nCreate the internal model of a TulipaEnergyModel.EnergyProblem. Any keyword argument will be passed to the underlying create_model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.create_model-NTuple{5, Any}","page":"API Reference","title":"TulipaEnergyModel.create_model","text":"model, expressions = create_model(\n    connection,\n    variables,\n    constraints,\n    profiles,\n    model_parameters;\n    optimizer = HiGHS.Optimizer,\n    optimizer_parameters = default_parameters(optimizer),\n    model_file_name = \"\",\n    enable_names = true\n    direct_model = false,\n)\n\nCreate the energy model manually. We recommend using create_model! instead.\n\nThe optimizer argument should be an MILP solver from the JuMP list of supported solvers. By default we use HiGHS.\n\nThe keyword argument optimizer_parameters should be passed as a dictionary of key => value pairs. These can be created manually, obtained using default_parameters, or read from a file using read_parameters_from_file.\n\nparameters = Dict{String,Any}(\"presolve\" => \"on\", \"time_limit\" => 60.0, \"output_flag\" => true)\nsolve_model(model; optimizer = HiGHS.Optimizer, optimizer_parameters = parameters)\n\nSet enable_names = false to avoid assigning names to variables and constraints, which improves speed but reduces the readability of log messages. For more information, see JuMP.set_string_names_on_creation.\n\nSet direct_model = true to create a JuMP direct_model using optimizer_with_attributes, which has memory improvements. For more information, see JuMP.direct_model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.create_unrolled_partition_tables!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.create_unrolled_partition_tables!","text":"create_unrolled_partition_table!(connection)\n\nCreate unrolled partitions tables from existing DuckDB tables, i.e., adds the time block start and end information.\n\nInput\n\nThe following tables are expected to exist in the connection, containing the partition of some, or all, assets or flows, with their respective time information.\n\nassets_rep_periods_partitions\nflows_rep_periods_partitions\nassets_timeframe_partitions\n\nOutput\n\nThe generated tables are the unrolled version of the tables above. It transforms each row in (possibly) multiple rows. The columns specification and partition are used to determine the time blocks, and are replaced by columns time_block_start and time_block_end.\n\nasset_time_resolution_rep_period\nflow_time_resolution_rep_period\nasset_time_resolution_over_clustered_year\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.default_parameters-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.default_parameters","text":"default_parameters(Val(optimizer_name_symbol))\ndefault_parameters(optimizer)\ndefault_parameters(optimizer_name_symbol)\ndefault_parameters(optimizer_name_string)\n\nReturns the default parameters for a given JuMP optimizer. Falls back to Dict() for undefined solvers.\n\nArguments\n\nThere are four ways to use this function:\n\nVal(optimizer_name_symbol): This uses type dispatch with the special Val type. Pass the solver name as a Symbol (e.g., Val(:HiGHS)).\noptimizer: The JuMP optimizer type (e.g., HiGHS.Optimizer).\noptimizer_name_symbol or optimizer_name_string: Pass the name in Symbol or String format and it will be converted to Val.\n\nUsing Val is necessary for the dispatch. All other cases will convert the argument and call the Val version, which might lead to type instability.\n\nExamples\n\nusing HiGHS\ndefault_parameters(HiGHS.Optimizer)\n\n# output\n\nDict{String, Any} with 1 entry:\n  \"output_flag\" => false\n\nAnother case\n\ndefault_parameters(Val(:Cbc))\n\n# output\n\nDict{String, Any} with 1 entry:\n  \"logLevel\" => 0\n\ndefault_parameters(:Cbc) == default_parameters(\"Cbc\") == default_parameters(Val(:Cbc))\n\n# output\n\ntrue\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.export_solution_to_csv_files-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.export_solution_to_csv_files","text":"export_solution_to_csv_files(output_file, connection, variables, constraints)\n\nSaves the solution in CSV files inside output_folder. Notice that this assumes that the solution has been computed by save_solution!.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.export_solution_to_csv_files-Tuple{Any, EnergyProblem}","page":"API Reference","title":"TulipaEnergyModel.export_solution_to_csv_files","text":"export_solution_to_csv_files(output_folder, energy_problem)\n\nSaves the solution from energy_problem in CSV files inside output_file. Notice that this assumes that the solution has been computed by save_solution!.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.get_single_element_from_query_and_ensure_its_only_one-Tuple{DuckDB.QueryResult}","page":"API Reference","title":"TulipaEnergyModel.get_single_element_from_query_and_ensure_its_only_one","text":"get_single_element_from_query_and_ensure_its_only_one(query_result :: QueryResult)\n\nGiven a DuckDB query_result (output of DuckDB.query(...) or DuckDB.execute), return the single element returned by it.\n\nIn other words, this assumes that query_result has a single row with a single column.\n\nWe use only twice to obtain this single element.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.populate_with_defaults!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.populate_with_defaults!","text":"populate_with_defaults!(connection)\n\nOverwrites all tables expected by TulipaEnergyModel appending columns that have defaults. The expected columns and their defaults are obtained from TulipaEnergyModel.schema.\n\nThis should be called when you have enough data for a TulipaEnergyModel, but doesn't want to fill out all default columns by hand.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.read_parameters_from_file-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.read_parameters_from_file","text":"read_parameters_from_file(filepath)\n\nParse the parameters from a file into a dictionary. The keys and values are NOT checked to be valid parameters for any specific solvers.\n\nThe file should contain a list of lines of the following type:\n\nkey = value\n\nThe file is parsed as TOML, which is intuitive. See the example below.\n\nExample\n\n# Creating file\nfilepath, io = mktemp()\nprintln(io,\n  \"\"\"\n    true_or_false = true\n    integer_number = 5\n    real_number1 = 3.14\n    big_number = 6.66E06\n    small_number = 1e-8\n    string = \"something\"\n  \"\"\"\n)\nclose(io)\n# Reading\nread_parameters_from_file(filepath)\n\n# output\n\nDict{String, Any} with 6 entries:\n  \"string\"         => \"something\"\n  \"integer_number\" => 5\n  \"small_number\"   => 1.0e-8\n  \"true_or_false\"  => true\n  \"real_number1\"   => 3.14\n  \"big_number\"     => 6.66e6\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.run_scenario-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.run_scenario","text":"energy_problem = run_scenario(\n    connection;\n    output_folder,\n    optimizer,\n    optimizer_parameters,\n    model_parameters_file,\n    model_file_name,\n    enable_names,\n    log_file,\n    show_log)\n\nRun the scenario in the given connection and return the energy problem.\n\nThe optimizer and optimizer_parameters keyword arguments can be used to change the optimizer (the default is HiGHS) and its parameters. The arguments are passed to the create_model function.\n\nSet model_file_name = \"some-name.lp\" to export the problem that is sent to the solver to a file for viewing (.lp or .mps). Set enable_names = false to turn off variable and constraint names (faster model creation). Set direct_model = true to create a JuMP direct model (faster & less memory). Set show_log = false to silence printing the log while running.\n\nSpecify a output_folder name to export the solution to CSV files. Specify a model_parameters_file name to load the model parameters from a TOML file. Specify a log_file name to export the log to a file.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.save_solution!-NTuple{4, Any}","page":"API Reference","title":"TulipaEnergyModel.save_solution!","text":"save_solution!(connection, model, variables, constraints; compute_duals = true)\n\nSaves the primal and dual variables values, in the following way:\n\nFor each variable in variables, get the solution value and save it in a\n\ncolumn named solution in the corresponding dataset.\n\nFor each constraint in constraints, get the dual of each attached\n\nconstraint listed in constraint.constraint_names and save it to the dictionary constraint.duals with the key given by the name.\n\nNotice that the duals are only computed if compute_duals is true.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.save_solution!-Tuple{EnergyProblem}","page":"API Reference","title":"TulipaEnergyModel.save_solution!","text":"save_solution!(energy_problem::EnergyProblem; compute_duals = true)\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.solve_model!-Tuple{EnergyProblem}","page":"API Reference","title":"TulipaEnergyModel.solve_model!","text":"solve_model!(energy_problem::EnergyProblem)\n\nSolve the internal model of an energy_problem.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.solve_model-Tuple{JuMP.Model}","page":"API Reference","title":"TulipaEnergyModel.solve_model","text":"solve_model(model::JuMP.Model)\n\nSolve the JuMP model.\n\n\n\n\n\n","category":"method"},{"location":"70-reference/#TulipaEnergyModel.validate_data!-Tuple{Any}","page":"API Reference","title":"TulipaEnergyModel.validate_data!","text":"validate_data!(connection)\n\nRaises an error if the data is not valid.\n\n\n\n\n\n","category":"method"},{"location":"40-scientific-foundation/40-formulation/#formulation","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"This section shows the mathematical formulation of TulipaEnergyModel.jl, assuming that the temporal definition of timesteps is the same for all the elements in the model (e.g., hourly). The concepts section shows how the model handles the flexible temporal resolution of assets and flows in the model.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Pages = [\"40-formulation.md\"]\nDepth = [2,3]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#math-sets","page":"Mathematical Formulation","title":"Sets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Assets","page":"Mathematical Formulation","title":"Sets for Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalA Energy assets a in mathcalA  The Energy asset types (i.e., consumer, producer, storage, hub, and conversion) are mutually exclusive\nmathcalA^textc Consumer energy assets  mathcalA^textc  subseteq mathcalA \nmathcalA^textp Producer energy assets  mathcalA^textp  subseteq mathcalA \nmathcalA^texts Storage energy assets  mathcalA^texts  subseteq mathcalA \nmathcalA^texth Hub energy assets (e.g., transshipment)  mathcalA^texth  subseteq mathcalA \nmathcalA^textcv Conversion energy assets  mathcalA^textcv subseteq mathcalA ","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"In addition, the following asset sets represent methods for incorporating additional variables and constraints in the model.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalA^texti_y Energy assets with investment method at year y  mathcalA^texti_y  subseteq mathcalA \nmathcalA^textoperation Energy assets with operation mode at year y  mathcalA^textoperation  subseteq mathcalA \nmathcalA^textsimple investment Energy assets with simple investment method at year y  mathcalA^textsimple investment  subseteq mathcalA \nmathcalA^textcompact investment Energy assets with compact investment method at year y  mathcalA^textcompact investment  subseteq mathcalA \nmathcalA^textsemi-compact investment Energy assets with semi-compact investment method at year y  mathcalA^textsemi-compact investment  subseteq mathcalA \nmathcalA^textss_y Energy assets with seasonal method at year y  mathcalA^textss_y subseteq mathcalA This set contains assets that use the seasonal method method. Please visit the how-to sections for seasonal storage and maximum/minimum outgoing energy limit to learn how to set up this feature.\nmathcalA^textse_y Storage energy assets with energy method at year y  mathcalA^textse_y subseteq mathcalA^texts This set contains storage assets that use investment energy method. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textsb_y Storage energy assets with binary method at year y  mathcalA^textsb_y subseteq mathcalA^texts setminus mathcalA^textss_y This set contains storage assets that use an extra binary variable to avoid charging and discharging simultaneously. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textmax e_y Energy assets with maximum outgoing energy method at year y  mathcalA^textmax e_y subseteq mathcalA This set contains assets that use the maximum outgoing energy method. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textmin e_y Energy assets with minimum outgoing energy method at year y  mathcalA^textmin e _ysubseteq mathcalA This set contains assets that use the minimum outgoing energy method. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textuc_y Energy assets with unit commitment method at year y  mathcalA^textuc_y  subseteq mathcalA^textcv cup mathcalA^textp This set contains conversion and production assets that have a unit commitment method. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textuc basic_y Energy assets with a basic unit commitment method at year y  mathcalA^textuc basic_y subseteq mathcalA^textuc_y This set contains the assets that have a basic unit commitment method that uses only the units on variable. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textuc 3var_y Energy assets with a 3var unit commitment method at year y  mathcalA^textuc 3var_y subseteq mathcalA^textuc_y This set contains the assets that have a unit commitment method using three variables: units on, start-up, and shut-down. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textramp_y Energy assets with ramping method at year y  mathcalA^textramp_y  subseteq mathcalA^textcv cup mathcalA^textp This set contains conversion and production assets that have a ramping method. Please visit the how-to section to learn how to set up this feature.\nmathcalA^textdc-opf_y Energy assets with a DC power flow method at year y  mathcalA^textdc-opf_y subseteq mathcalA This set contains the assets that have that use the dc-opf method.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Flows","page":"Mathematical Formulation","title":"Sets for Flows","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalF Flow connections between two assets f in mathcalF  \nmathcalF^textin_ay Set of flows going into asset a at year y  mathcalF^textin_ay  subseteq mathcalF \nmathcalF^textout_ay Set of flows going out of asset a at year y  mathcalF^textout_ay subseteq mathcalF ","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"In addition, the following flow sets represent methods for incorporating additional variables and constraints in the model.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalF^textt Flow between two assets with a transport method  mathcalF^textt subseteq mathcalF \nmathcalF^textti_y Transport flow with investment method at year y  mathcalF^textti_y subseteq mathcalF^textt \nmathcalF^textdc-opf_y Flow between two assets with a DC power flow method at year y  mathcalF^textdc-opf_y subseteq mathcalF This set contains flows that use the dc-opf method.\nmathcalF^text1_xy First flow in the relationship x at year y  mathcalF^text1_xy subseteq mathcalF \nmathcalF^text2_xy Second flow in the relationship x at year y  mathcalF^text2_xy subseteq mathcalF ","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Temporal-Structures","page":"Mathematical Formulation","title":"Sets for Temporal Structures","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalY Milestone years y in mathcalY mathcalY subset mathbbN \nmathcalY^texti_a Milestone years where asset a is investable y in mathcalY^texti_a mathcalY subseteq mathcalY \nmathcalY^texti_f Milestone years where flow f is investable y in mathcalY^texti_f mathcalY subseteq mathcalY \nmathcalV All years v in mathcalV mathcalV subset mathbbN \nmathcalP_y Periods in the timeframe at year y p_y in mathcalP_y mathcalP_y subset mathbbN \nmathcalK_y Representative periods (rp) at year y k_y in mathcalK_y mathcalK_y subset mathbbN mathcalK_y does not have to be a subset of mathcalP_y\nmathcalB_k_y Timesteps blocks within a representative period k_y at year y b_k_y in mathcalB_k_y  mathcalB_k_y is a partition of timesteps in a representative period k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Stochastic-Scenarios","page":"Mathematical Formulation","title":"Sets for Stochastic Scenarios","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalS Stochastic scenarios s in mathcalS  ","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Groups","page":"Mathematical Formulation","title":"Sets for Groups","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalG^texta Groups of energy assets g in mathcalG^texta  ","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"In addition, the following subsets represent methods for incorporating additional constraints in the model.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalG^textai_y Group of assets that share min/max investment limit  mathcalG^textai_y subseteq mathcalG^texta This set contains assets that have a group investment limit. Please visit the how-to section to learn how to set up this feature.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Sets-for-Flows-Relationships","page":"Mathematical Formulation","title":"Sets for Flows Relationships","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Description Elements Superset Notes\nmathcalX Relationship between two flows x in mathcalX  ","category":"page"},{"location":"40-scientific-foundation/40-formulation/#math-parameters","page":"Mathematical Formulation","title":"Parameters","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Assets","page":"Mathematical Formulation","title":"Parameters for Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#General-Parameters-for-Assets","page":"Mathematical Formulation","title":"General Parameters for Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textinv cost_ay mathbbR_+ a in mathcalA, y in mathcalY Overnight cost of a unit of asset a at year y [kEUR/MW]\np^textcommodity price_ay mathbbR_+ a in mathcalA, y in mathcalY Price of the commodity to produce a unit of energy for asset a at year y. Only applies to producers. [kEUR/MWh] or other units\np^textannualized inv cost_ay mathbbR_+ a in mathcalA, y in mathcalY Annualized investment cost of a unit of asset a at year y [kEUR/MW/year]\np^textsalvage value_ay mathbbR_+ a in mathcalA, y in mathcalY Salvage value of a unit of asset a at year y [kEUR/MW]\np^textdiscounting factor asset inv cost_ay mathbbR_+ a in mathcalA, y in mathcalY Discounting factor for investment cost of a unit of asset a at year y [-]\np^textfixed cost_ay mathbbR_+ a in mathcalA, y in mathcalY Fixed cost of a unit of asset a at year y [kEUR/MW/year]\np^textinv limit_ay mathbbR_+ a in mathcalA, y in mathcalY Investment potential of asset a at year y [MW]\np^textcapacity_a mathbbR_+ a in mathcalA Capacity per unit of asset a [MW]\np^texttechnical lifetime_a mathbbZ_+ a in mathcalA Technical lifetime of asset a [year]\np^texteconomic lifetime_a mathbbZ_+ a in mathcalA Economic lifetime of asset a [year]\np^texttechnology-specific discount rate_a mathbbR_+ a in mathcalA Technology-specific discount rate of asset a [year]\np^textinit units_ay mathbbR_+ a in mathcalA, y in mathcalY Initial number of units of asset a available at year y [units]\np^textinit units_ayv mathbbR_+ $ (a,y,v) \\in \\mathcal{D}^{\\text{compact investment}}$ Initial number of units of asset a available at year y commissioned in year v [units]\np^textavailability profile_avk_yb_k_y mathbbR_+ a in mathcalA, v in mathcalV, k_y in mathcalK_y, b_k_y in mathcalB_k_y Availability profile of asset a invested in year v in the representative period k_y and timestep block b_k_y [p.u.]\np^textgroup_a mathcalG^texta a in mathcalA Group g to which the asset a belongs [-]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Consumer-Assets","page":"Mathematical Formulation","title":"Extra Parameters for Consumer Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textpeak demand_ay mathbbR_+ a in mathcalA^textc, y in mathcalY Peak demand of consumer asset a at year y [MW]\np^textdemand profile_ak_yb_k_y mathbbR_+ a in mathcalA^textc, , y in mathcalY, k_y in mathcalK_y, b_k_y in mathcalB_k_y Demand profile of consumer asset a in the representative period k_y and timestep block b_k_y [p.u.]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Storage-Assets","page":"Mathematical Formulation","title":"Extra Parameters for Storage Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textinit storage units_ay mathbbR_+ a in mathcalA^texts, y in mathcalY Initial storage units of storage asset a available at year y [units]\np^textinit storage level_ay mathbbR_+ a in mathcalA^texts, y in mathcalY Initial storage level of storage asset a at year y [MWh]\np^textinflows_ak_yb_k_y mathbbR_+ a in mathcalA^texts, k_y in mathcalK_y, b_k_y in mathcalB_k_y Inflows of storage asset a in the representative period k_y and timestep block b_k_y [MWh]\np^textcharging eff_ay mathbbR_+ a in mathcalA^texts, y in mathcalY Charging efficiency of storage asset a at year y [p.u.]\np^textdischarging eff_ay mathbbR_+ a in mathcalA^texts, y in mathcalY Discharging efficiency of storage asset a at year y [p.u.]\np^textinv cost energy_ay mathbbR_+ a in mathcalA^textse, y in mathcalY Overnight cost of a energy unit of asset a at year y [kEUR/MWh]\np^textfixed cost energy_ay mathbbR_+ a in mathcalA^textse, y in mathcalY Fixed cost of a energy unit of asset a at year y [kEUR/MWh/year]\np^textinv limit energy_ay mathbbR_+ a in mathcalA^textse, y in mathcalY Investment energy potential of asset a at year y [MWh]\np^textenergy capacity_a mathbbR_+ a in mathcalA^textse Energy capacity of a unit of investment of the asset a [MWh]\np^textenergy to power ratio_ay mathbbR_+ a in mathcalA^texts setminus mathcalA^textse_y Energy to power ratio of storage asset a at year y [h]\np^textmax rep-period-storage level_ak_yb_k_y mathbbR_+ a in mathcalA^texts setminus mathcalA^textss_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Maximum rep-period-storage level profile of storage asset a in representative period k_y and timestep block b_k_y [p.u.]\np^textmin rep-period-storage level_ak_yb_k_y mathbbR_+ a in mathcalA^texts setminus mathcalA^textss_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Minimum rep-period-storage level profile of storage asset a in representative period k_y and timestep block b_k_y [p.u.]\np^textmax over-clustered-year-storage level_ap_y mathbbR_+ a in mathcalA^textss_y, p_y in mathcalP_y Maximum over-clustered-year-storage level profile of storage asset a in the period p_y of the timeframe [p.u.]\np^textmin over-clustered-year-storage level_ap_y mathbbR_+ a in mathcalA^textss_y, p_y in mathcalP_y Minimum over-clustered-year-storage level profile of storage asset a in the period p_y of the timeframe [p.u.]\np^textstorage loss from stored energy_ay mathbbR_+ a in mathcalA^texts, y in mathcalY_y [e.g. 0.01 means 1% every hour] Loss of stored energy over time. [p.u./h]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Conversion-Assets","page":"Mathematical Formulation","title":"Extra Parameters for Conversion Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textefficiency_ay mathbbR_+ a in mathcalA^textcv, y in mathcalY efficiency of conversion asset a at year y [p.u.]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Energy-Constraints","page":"Mathematical Formulation","title":"Extra Parameters for Energy Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textmin over-clustered-year-storage profile_ap_y mathbbR_+ a in mathcalA^textmin e_y, p_y in mathcalP_y Minimum outgoing over-clustered-year energy profile of asset a in the period p_y of the timeframe [p.u.]\np^textmax over-clustered-year-storage profile_ap_y mathbbR_+ a in mathcalA^textmax e_y, p_y in mathcalP_y Maximum outgoing over-clustered-year energy profile of asset a in the period p_y of the timeframe [p.u.]\np^textmax energy_ap_y mathbbR_+ a in mathcalA^textmax e_y Maximum outgoing over-clustered-year energy value of asset a [MWh]\np^textmin energy_ap_y mathbbR_+ a in mathcalA^textmin e_y Minimum outgoing over-clustered-year energy value of asset a [MWh]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Unit-Commitment-and-Ramping-Constraints","page":"Mathematical Formulation","title":"Extra Parameters for Unit Commitment and Ramping Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textmin operating point_ay mathbbR_+ a in mathcalA^textuc_y Minimum operating point or minimum stable generation level defined as a portion of the capacity of asset a at year y [p.u.]\np^textunits on cost_ay mathbbR_+ a in mathcalA^textuc_y Objective function coefficient on units_on variable. e.g., no-load cost or idling cost of asset a at year y [kEUR/h/units]\np^textmax ramp up_ay mathbbR_+ a in mathcalA^textramp_y Maximum ramping up rate as a portion of the capacity of asset a at year y [p.u./h]\np^textmax ramp down_ay mathbbR_+ a in mathcalA^textramp_y Maximum ramping down rate as a portion of the capacity of asset a at year y [p.u./h]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Flows","page":"Mathematical Formulation","title":"Parameters for Flows","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textoperational cost_fy mathbbR_+ f in mathcalF, y in mathcalY Operational cost of flow f at year y [kEUR/MWh]\np^textreactance_fy mathbbR_+ f in mathcalF, y in mathcalY Reactance of flow f at year y [p.u.]\np^textcapacity coefficient_fy mathbbR_+ f in mathcalF, y in mathcalY Coefficient that multiplies the flow f at year y in the capacity constraints [-]\np^textconversion coefficient_fy mathbbR_+ f in mathcalF, y in mathcalY Coefficient that multiplies the flow f at year y in the conversion constraints [-]\np^textinv cost_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Overnight cost of transport flow f at year y [kEUR/MW]\np^textannualized inv cost_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Annualized investment cost of transport flow f at year y [kEUR/MW/year]\np^textsalvage value_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Salvage value of transport flow f at year y [kEUR/MW]\np^textdiscounting factor flow inv cost_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Discounting factor for investment cost of transport flow f at year y [-]\np^textfixed cost_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Fixed cost of transport flow f at year y [kEUR/MW/year]\np^textinv limit_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Investment potential of flow f at year y [MW]\np^textcapacity_f mathbbR_+ f in mathcalF^textt Capacity per unit of investment of transport flow f (both exports and imports) [MW]\np^texttechnical lifetime_f mathbbZ_+ f in mathcalF^textt Technical lifetime of investment of transport flow f (both exports and imports) [year]\np^texteconomic lifetime_f mathbbZ_+ f in mathcalF^textt Economic lifetime of investment of transport flow f (both exports and imports) [year]\np^texttechnology-specific discount rate_f mathbbR_+ f in mathcalF^textt Technology-specific discount rate of investment of transport flow f (both exports and imports) [year]\np^textinit export units_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Initial export units of transport flow f available at year y [MW]\np^textinit import units_fy mathbbR_+ f in mathcalF^textt, y in mathcalY Initial import units of transport flow f available at year y [MW]\np^textavailability profile_fvk_yb_k_y mathbbR_+ a in mathcalF, v in mathcalV, k_y in mathcalK_y, b_k_y in mathcalB_k_y Availability profile of flow f invested in year v in the representative period k_y and timestep block b_k_y [p.u.]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Stochastic-Scenarios","page":"Mathematical Formulation","title":"Parameters for Stochastic Scenarios","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textprobability_s 0 1 s in mathcalS Probability of stochastic scenario s [-]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Temporal-Structures","page":"Mathematical Formulation","title":"Parameters for Temporal Structures","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textduration_b_k_y mathbbR_+ b_k_y in mathcalB_k_y Duration of the timestep blocks b_k_y [h]\np^textrp weight_sk_y mathbbR_+ s in mathcalS k_y in mathcalK_y Weight of representative period k_y in stochastic scenario s [-]\np^textmap_sp_yk_y mathbbR_+ s in mathcalS p_y in mathcalP_y, k_y in mathcalK_y Map with the weight of representative period k_y in period p_y, and stochastic scenario s [-]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Groups","page":"Mathematical Formulation","title":"Parameters for Groups","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textmin invest limit_gy mathbbR_+ g in mathcalG^textai, y in mathcalY Minimum investment limit (potential) of group g at year y [MW]\np^textmax invest limit_gy mathbbR_+ g in mathcalG^textai, y in mathcalY Maximum investment limit (potential) of group g at year y [MW]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-Flows-Relationship","page":"Mathematical Formulation","title":"Parameters for Flows Relationship","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textconstant_xy mathbbR x in mathcalX, y in mathcalY Constant value in the flow relationship x at year y [MW]\np^textratio_xy mathbbR x in mathcalX, y in mathcalY Ratio value in the flow relationship x at year y [-]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Parameters-for-the-Model","page":"Mathematical Formulation","title":"Parameters for the Model","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Description Units\np^textsocial discount rate mathbbR_+ Social discount rate [-]\np^textdiscount year mathbbZ_+ Discount year [year]\np^textpower system base mathbbR_+ Power system base [MVA]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Extra-Parameters-for-Discounting","page":"Mathematical Formulation","title":"Extra Parameters for Discounting","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\np^textdiscounting factor operation cost_y mathbbR_+ y in mathcalY Discounting factor for operation cost at year y [-]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#math-variables","page":"Mathematical Formulation","title":"Variables","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Name Domain Domains of Indices Description Units\nv^textflow_fk_yb_k_y mathbbR f in mathcalF, k_y in mathcalK_y, b_k_y in mathcalB_k_y Flow f between two assets in representative period k_y and timestep block b_k_y [MW]\nv^textvintage flow_fvk_yb_k_y mathbbR f in mathcalF^textout_ay mid a in mathcalA^textp cup mathcalA^textcv cup mathcalA^texts  v in mathcalV, k_y in mathcalK_y, b_k_y in mathcalB_k_y Vintage flow f between two assets in commission year v in representative period k_y and timestep block b_k_y [MW]\nv^textinv_ay mathbbZ_+ a in mathcalA^texti_y, y in mathcalY Number of invested units of asset a at year y [units]\nv^textdecom simple_ay mathbbZ_+ a in mathcalA^textsimple investment, y in mathcalY Number of decommissioned units of asset a that uses simple investment method at year y [units]\nv^textdecom compact_ayv mathbbZ_+ $ (a,y,v) \\in \\mathcal{D}^{\\text{compact investment}}$ Number of decommissioned units of asset a commissioned in year v that uses compact investment method at year y [units]\nv^textinv energy_ay mathbbZ_+ a in mathcalA^texti_y cap mathcalA^textse_y, y in mathcalY Number of invested units of the energy component of the storage asset a that uses energy method at year y [units]\nv^textdecom energy simple_ay mathbbZ_+ a in mathcalA^texti_y cap mathcalA^textse_y, y in mathcalY Number of decommissioned units of the energy component of the storage asset a that uses energy method at year y [units]\nv^textinv_fy mathbbZ_+ f in mathcalF^textti_y, y in mathcalY Number of invested units of capacity increment of transport flow f at year y [units]\nv^textdecom simple_fy mathbbZ_+ f in mathcalF^textti_y, y in mathcalY Number of decommissioned units of capacity increment of transport flow f at year y [units]\nv^textrep-period-storage_ak_yb_k_y mathbbR_+ a in mathcalA^texts_y setminus mathcalA^textss_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Rep-period-storage level for storage asset a, representative period k_y, and timestep block b_k_y [MWh]\nv^textover-clustered-year-storage_asp_y mathbbR_+ a in mathcalA^textss_y, s in mathcalS, p_y in mathcalP_y Over-clustered-year-storage level for storage asset a, stochastic scenario s, and period p_y [MWh]\nv^textis charging_ak_yb_k_y 0 1 a in mathcalA^textsb_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y If an storage asset a is charging or not in representative period k_y and timestep block b_k_y [-]\nv^textangle_ak_yb_k_y mathbbR a in mathcalA^textdc-opf_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Electricity angle of asset a in representative period k_y and timestep block b_k_y [rad]\nv^textunits on_ak_yb_k_y mathbbZ_+ a in mathcalA^textuc_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Number of units ON of asset a in representative period k_y and timestep block b_k_y [units]\nv^textstart up_ak_yb_k_y mathbbZ_+ a in mathcalA^textuc 3var_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Number of units of asset a STARTING UP in representative period k_y and timestep block b_k_y [units]\nv^textshut down_ak_yb_k_y mathbbZ_+ a in mathcalA^textuc 3var_y, k_y in mathcalK_y, b_k_y in mathcalB_k_y Number of units of asset a SHUTTING DOWN in representative period k_y and timestep block b_k_y [units]","category":"page"},{"location":"40-scientific-foundation/40-formulation/#math-objective-function","page":"Mathematical Formulation","title":"Objective Function","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Expresssions-for-the-Objective-Function","page":"Mathematical Formulation","title":"Expresssions for the Objective Function","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"There are two types of investment methods for multi-year investment modelling: simple method and compact method. The simple method aggregates all units available in a year, regardless of when they were invested. The compact method tracks availability by investment and operational year, enabling vintage-specific constraints while reducing model size. For more information on this topic, refer to the How to use or Wang and Morales-España (2025).","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"For available units across years, we define the following expresssions:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable units simple method_ay  = p^textinitial units_ay + sum_i in mathcalY^texti_a y - p^texttechnical lifetime_a + 1  le i le y   v^textinv_ai - sum_i in mathcalY y - p^texttechnical lifetime_a + 1  le i le y  v^textdecom simple_ai \n     forall a in mathcalA^textsimple investment cup mathcalA^textoperation forall y in mathcalY \n    v^textavailable units compact method_ayv  = p^textinitial units_ayv + v^textinv_av - sum_i in mathcalY v  i le y  (aiv) in mathcalD^textcompact investment v^textdecom compact_aiv\n \n     forall (ayv) in mathcalD^textcompact investment \n    v^textavailable energy units simple method_ay  = p^textinitial storage units_ay + sum_i in mathcalY^texti_a y - p^texttechnical lifetime_a + 1  le i le y   v^textinv energy_ai - sum_i in mathcalY y - p^texttechnical lifetime_a + 1  le i le y  v^textdecom energy simple_ai \n     forall a in mathcalA^textse_y forall y in mathcalY \n    v^textavailable export units simple method_fy  = p^textinitial export units_fy + sum_i in mathcalY^texti_f y - p^texttechnical lifetime_f + 1  le i le y   v^textinv_fi - sum_i in mathcalY y - p^texttechnical lifetime_f + 1  le i le y  v^textdecom simple_fi \n     forall f in mathcalF^textt_y forall y in mathcalY \n    v^textavailable import units simple method_fy  = p^textinitial import units_fy + sum_i in mathcalY^texti_f y - p^texttechnical lifetime_f + 1  le i le y   v^textinv_fi - sum_i in mathcalY y - p^texttechnical lifetime_f + 1  le i le y  v^textdecom simple_fi \n     forall f in mathcalF^textt_y forall y in mathcalY \nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"In addition, we define the following expressions to determine the available units. This expression takes a few forms depending on whether the asset uses simple or compact investment method.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If the asset uses simple investment method","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable units_ay  = v^textavailable units simple method_ay quad forall a in mathcalA forall y in mathcalY\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If the asset uses compact investment method","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable units_ay  = sum_v in mathcalV  (ayv) in mathcalD^textcompact investment v^textavailable units compact method_ayv quad forall a in mathcalA forall y in mathcalY\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Storage assets with energy method always use simple investment method","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable energy units_ay  = v^textavailable energy units simple method_ay quad forall a in mathcalA^textse_y forall y in mathcalY\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Transport assets always use simple investment method","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable export units_fy  = v^textavailable export units simple method_fy quad forall f in mathcalF^textt_y forall y in mathcalY \n    v^textavailable import units_fy  = v^textavailable import units simple method_fy quad forall f in mathcalF^textt_y forall y in mathcalY\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Economic-Representation-for-the-Objective-Function","page":"Mathematical Formulation","title":"Economic Representation for the Objective Function","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The model accounts for discounting in multi-year investment modelling. For more information on this topic, refer to the How to use or Wang and Tejada-Arango (2025).","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Discounting-Factor-for-Asset-Investment-Costs","page":"Mathematical Formulation","title":"Discounting Factor for Asset Investment Costs","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p_a y^textdiscounting factor asset inv cost=frac1(1+p^textsocial discount rate)^y-p^textdiscount year(1-fracp_a y^textsalvage valuep_a y^textinv cost) quad forall a in mathcalA_y^texti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"where salvage value is","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p^textsalvage value_a y = p^textannualized inv cost_a y sum_i=y^textlast+1^y + p^texteconomic lifetime_a y - 1 frac1(1 + p^texttechnology-specific discount rate_a y)^i - y  quad forall a in mathcalA_y^texti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"and where annualized cost is","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p^textannualized inv cost_a y = fracp^texttechnology-specific discount rate_a y (1+p^texttechnology-specific discount rate_a y) cdot bigg( 1 - frac1 (1+p^texttechnology-specific discount rate_a y)^p^texteconomic lifetime_a y  bigg)  p^textinv cost_a y quad forall a in mathcalA_y^texti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Discounting-Factor-for-Flow-Investment-Costs","page":"Mathematical Formulation","title":"Discounting Factor for Flow Investment Costs","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p_f y^textdiscounting factor flow inv cost=frac1(1+p^textsocial discount rate)^y-p^textdiscount year(1-fracp_f y^textsalvage valuep_f y^textinv cost) quad forall f in mathcalF_y^textti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"where salvage value is","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p^textsalvage value_f y = p^textannualized inv cost_f y sum_i=y^textlast+1^y + p^texteconomic lifetime_f y - 1 frac1(1 + p^texttechnology-specific discount rate_f y)^i - y  quad forall f in mathcalF_y^textti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"and where annualized cost is","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p^textannualized inv cost_f y = fracp^texttechnology-specific discount rate_f y (1+p^texttechnology-specific discount rate_f y) cdot bigg( 1 - frac1 (1+p^texttechnology-specific discount rate_f y)^p^texteconomic lifetime_f y  bigg)  p^textinv cost_f y quad forall f in mathcalF_y^textti forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Discounting-Factor-for-Operation-Costs","page":"Mathematical Formulation","title":"Discounting Factor for Operation Costs","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"p_y^textdiscounting factor operation cost= sum^textnext(y)-1_y=y frac1(1+p^textsocial discount rate)^y-p^textdiscount year quad forall y in mathcalY","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"This definition of the discount factor at year y includes the discounts for the range of years from the milestone year y to the next milestone year y+1, i.e., {y, y+1, ..., next(y)-1}, so the discounts at the non-modeled years are also correctly considered. When y=last(y), only the discount at year y is included.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Objective-Function","page":"Mathematical Formulation","title":"Objective Function","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The objective function is formulated as a two-stage stochastic optimization problem, where the investment decisions are the first-stage variables and the expected value of the operation variables is in the second stage.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\ntextminimize quad  assets_investment_cost + assets_fixed_cost \n                         + flows_investment_cost + flows_fixed_cost \n                         + sum_s in mathcalS p^textprobability_s cdot (flows_operational_cost_s + unit_on_cost_s)\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Where:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nassets_investment_cost = sum_y in mathcalY sum_a in mathcalA^texti_y  p_a y^textdiscounting factor asset inv cost cdot p^textinv cost_ay cdot p^textcapacity_a cdot v^textinv_ay  +  sum_y in mathcalY sum_a in mathcalA^textse_y cap mathcalA^texti_y  p_a y^textdiscounting factor asset inv cost cdotp^textinv cost energy_ay cdot p^textenergy capacity_a cdot v^textinv energy_ay   \nassets_fixed_cost = sum_y in mathcalY sum_a in mathcalA^textsimple investment cup mathcalA^textoperation  p_y^textdiscounting factor operation cost cdot p^textfixed cost_ay cdot p^textcapacity_a cdot v^textavailable units simple method_ay \n + sum_(ayv) in mathcalD^textcompact investment   p_y^textdiscounting factor operation cost cdot p^textfixed cost_av cdot p^textcapacity_a cdot v^textavailable units compact method_ayv \n + sum_y in mathcalY sum_a in mathcalA^textse_y cap (mathcalA^textsimple investment cup mathcalA^textoperation)  p_y^textdiscounting factor operation cost cdot p^textfixed cost energy_ay cdot p^textenergy capacity_a cdot v^textavailable energy capacity simple method_ay \nflows_investment_cost = sum_y in mathcalY sum_f in mathcalF^textti_y p_f y^textdiscounting factor flow inv cost cdot p^textinv cost_fy cdot p^textcapacity_f cdot v^textinv_fy \nflows_fixed_cost = frac12 sum_y in mathcalY sum_f in mathcalF^textt_y p_y^textdiscounting factor operation cost cdot p^textfixed cost_fy cdot p^textcapacity_f cdot left( v^textavailable export units_fy + v^textavailable import units_fy right) \nflows_operational_cost_s =\nsum_y in mathcalY sum_k_y in mathcalK_y sum_b_k_y in mathcalB_k_y p_y^textdiscounting factor operation cost cdot p^textrp weight_sk_y cdot p^textduration_b_k_y cdot bigg( sum_f in F^textin_ay  a in mathcalA  p^textoperational cost_fy cdot v^textflow_fk_yb_k_y \n sum_f in F^textout_ay  a in mathcalA^textsemi-compact investment  sum_v in mathcalV (p^textcommodity price_a y  p^textefficiency_a v + p^textoperational cost_f y) cdot v^textvintage flow_fvk_yb_k_y \n sum_f in F^textout_ay  a in mathcalA^textcompact investment cup mathcalA^textsimple investment cup mathcalA^textoperation  (p^textcommodity price_a y  p^textefficiency_a v + p^textoperational cost_f y) cdot v^textflow_fk_yb_k_y bigg) \nunit_on_cost_s = sum_y in mathcalY sum_a in mathcalA^textuc_y sum_k_y in mathcalK_y sum_b_k_y in mathcalB_k_y p_y^textdiscounting factor operation cost cdot p^textrp weight_sk_y cdot p^textunits on cost_ay cdot p^textduration_b_k_y cdot v^textunits on_ak_yb_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#math-constraints","page":"Mathematical Formulation","title":"Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#cap-constraints","page":"Mathematical Formulation","title":"Capacity Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Output-Flows-Limit","page":"Mathematical Formulation","title":"Maximum Output Flows Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Maximum output flow constraints depend on the chosen investment method (operation, simple, compact, or semi-compact). For more information on this topic, refer to the How to use or Wang and Morales-España (2025).","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot v^textavailable units simple method_ay  quad\n  forall y in mathcalY forall a in (mathcalA^textsimple investment cup mathcalA^textoperation) cap left(mathcalA^textcv cup left(mathcalA^texts setminus mathcalA^textsb_y right)  cup mathcalA^textp right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y  \nsum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textcapacity_a cdot sum_v in mathcalV  (ayv) in mathcalD^textcompact investment p^textavailability profile_avk_yb_k_y cdot v^textavailable units compact method_ayv  quad\n  forall y in mathcalY forall a in mathcalA^textcompact investment cap left(mathcalA^textcv cup left(mathcalA^texts setminus mathcalA^textsb_y right) cup mathcalA^textp right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\n \nsum_f in mathcalF^textout_ay  p^textcapacity coefficient_fv cdot v^textvintage flow_fvk_yb_k_y leq p^textcapacity_a cdot p^textavailability profile_avk_yb_k_y cdot v^textavailable units compact method_ayv  quad\n forall y in mathcalY forall v in mathcalV forall a in mathcalA^textsemi-compact investment forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Storage assets using the method to avoid charging and discharging simultaneously, i.e., a in mathcalA^textsb_y, use the following constraints instead of the previous one:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Maximum output flows limit for storage assets such that a in mathcalA^textsb_y cap mathcalA^texti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot left(p^textcapacity_a cdot p^textinit units_ay + p^textinv limit_ay right) cdot left(1 - v^textis charging_ak_yb_k_y right) quad\n  forall y in mathcalY forall a in mathcalA^textsb_y cap mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot left(p^textinit units_ay cdot (1 - v^textis charging_ak_yb_k_y) - v^textavailable units_ay right)\n  forall y in mathcalY forall a in mathcalA^textsb_y cap mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"info: Info\nThe negative sign before the v^textavailable units_ay is because the available units include the p^textinit units_ay in its calculation.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Maximum output flows limit for storage assets such that a in mathcalA^textsb_y setminus mathcalA^texti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot p^textinit units_ay cdot left(1 - v^textis charging_ak_yb_k_y right) quad\n  forall y in mathcalY forall a in mathcalA^textsb_y setminus mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Input-Flows-Limit","page":"Mathematical Formulation","title":"Maximum Input Flows Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot v^textavailable units_ay   quad\n  forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textsb_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Storage assets using the method to avoid charging and discharging simultaneously, i.e., a in mathcalA^textsb, use the following constraints instead of the previous one:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Maximum input flows limit for storage assets such that a in mathcalA^textsb_y cap mathcalA^texti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot left(p^textcapacity_a cdot p^textinit units_ay + p^textinv limit_ay right)  cdot v^textis charging_ak_yb_k_y quad forall y in mathcalY forall a in mathcalA^textsb_y cap mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot left(p^textinit units_ay cdot v^textis charging_ak_yb_k_y - v^textavailable units_ay right)  quad forall y in mathcalY forall a in mathcalA^textsb_y cap mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"info: Info\nThe negative sign before the v^textavailable units_ay is because the available units include the p^textinit units_ay in its calculation.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Maximum input flows limit for storage assets such that a in mathcalA^textsb_y setminus mathcalA^texti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot p^textinit units_ay  cdot v^textis charging_ak_yb_k_y quad forall y in mathcalY forall a in mathcalA^textsb_y setminus mathcalA^texti_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Lower-Limit-for-Available-Units-Compact-method","page":"Mathematical Formulation","title":"Lower Limit for Available Units Compact method","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\n    v^textavailable units compact method_ayv ge 0 quad  forall (ayv) in mathcalD^textcompact investment\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Lower-Limit-for-Flows","page":"Mathematical Formulation","title":"Lower Limit for Flows","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textflow_fk_yb_k_y geq 0 quad forall y in mathcalY forall f in (mathcalF setminus mathcalF^t) textwith a^textfrom_f notin mathcalA^textsemi-compact investment forall k_y in mathcalK_y forall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textvintage flow_fvk_yb_k_y geq 0 quad forall y in mathcalY forall v in mathcalV forall f in ( mathcalF^textout_ay setminus mathcalF^t ) textwith a^textfrom_f in mathcalA^textsemi-compact investment forall k_y in mathcalK_y forall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"sum_f in mathcalF^textout_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y geq 0 quad forall y in mathcalY forall a in (mathcalA^textp cup mathcalA^textcv cup mathcalA^texts ) setminus mathcalA^textuc setminus mathcalA^textsemi-compact investment textwith mathcalF^textout_ay cap mathcalF^t neq emptyset forall k_y in mathcalK_y forall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"sum_f in mathcalF^textin_ay p^textcapacity coefficient_fy cdot v^textflow_fk_yb_k_y geq 0 quad forall y in mathcalY forall a in (mathcalA^textcv cup mathcalA^texts) setminus mathcalA^textsemi-compact investment textwith mathcalF^textin_ay cap mathcalF^t neq emptyset forall k_y in mathcalK_y forall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"sum_f in mathcalF^textout_ay p^textcapacity coefficient_fv cdot v^textvintage flow_fvk_yb_k_y geq 0 quad  forall y in mathcalY forall v in mathcalV forall a in (mathcalA^textp cup mathcalA^textcv cup mathcalA^texts ) cap mathcalA^textsemi-compact investment textwith mathcalF^textout_ay cap mathcalF^t neq emptyset forall k_y in mathcalK_y forall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#vintage-sum-constraints","page":"Mathematical Formulation","title":"Vintage Flow Sum Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"When the semi-compact investment method is selected, the model introduces vintage flow variables which represent flows from different commissioning years alongside the standard flow variables. Vintage flow variables are included only where relevant, such as in the objective function, capacity constraints, and conversion balance. In all other cases, standard flow variables are used. A linkage is established between the two sets of variables to maintain consistency.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"  sum_v in mathcalV  (ayv) in mathcalD^textsemi-compact investment v^textvintage flow_fvk_yb_k_y = v^textflow_fk_yb_k_y forall y in mathcalY  forall f in mathcalF^textout_ay forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#uc-constraints","page":"Mathematical Formulation","title":"Unit Commitment Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Production and conversion assets within the set mathcalA^textuc will contain the unit commitment constraints in the model. These constraints are based on the work of Morales-España et al. (2013) and Morales-España et al. (2014).","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The current version of the code only incorporates a basic unit commitment version of the constraints (i.e., utilizing only the unit commitment variable v^textunits on). However, upcoming versions will include more detailed constraints, incorporating startup and shutdown variables.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"For the unit commitment constraints, we define the following expression for the flow that is above the minimum operating point of the asset:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textflow above min_ak_yb_k_y = sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y - p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot p^textmin operating point_ay cdot v^texton_ak_yb_k_y  quad\n  forall y in mathcalY forall a in mathcalA^textuc_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Limit-to-the-units-on-variable","page":"Mathematical Formulation","title":"Limit to the units on variable","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^texton_ak_yb_k_y leq v^textavailable units_ay  quad\n  forall y in mathcalY forall a in mathcalA^textuc_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-output-flow-above-the-minimum-operating-point","page":"Mathematical Formulation","title":"Maximum output flow above the minimum operating point","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textflow above min_ayk_yb_k_y leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot left(1 - p^textmin operating point_ay right) cdot v^texton_ak_yb_k_y  quad\n  forall y in mathcalY forall a in mathcalA^textuc basic_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Minimum-output-flow-above-the-minimum-operating-point","page":"Mathematical Formulation","title":"Minimum output flow above the minimum operating point","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textflow above min_ak_yb_k_y geq 0  quad\n  forall y in mathcalY forall a in mathcalA^textuc basic_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Tight-logical-constraints-for-start-up-and-shut-down-variables","page":"Mathematical Formulation","title":"Tight logical constraints for start-up and shut-down variables","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^texton_a k_y b_k_y - v^texton_a k_y (b_k_y - 1) = v^textstart up_a k_y b_k_y - v^textshut down_a k_y b_k_y quad\n  forall y in mathcalY forall a in mathcalA^textuc 3var_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\n v^textstart up_a k_y b_k_y leq v^texton_a k_y b_k_y quad\n  forall y in mathcalY forall a in mathcalA^textuc 3var_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\n v^textshut down_a k_y b_k_y leq v^textavailable units_ay - v^texton_a k_y b_k_y quad\n  forall y in mathcalY forall a in mathcalA^textuc 3var_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#ramp-constraints","page":"Mathematical Formulation","title":"Ramping Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Ramping constraints restrict the rate at which the output flow of a production or conversion asset can change. If the asset is part of the unit commitment set (e.g., mathcalA^textuc_y), the ramping limits apply to the flow above the minimum output, but if it is not, the ramping limits apply to the total output flow.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Ramping constraints that take into account unit commitment variables are based on the work done by Damcı-Kurt et. al (2016). Also, please note that since the current version of the code only handles the basic unit commitment implementation, the ramping constraints are applied to the assets in the set mathcalA^textuc basic_y.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"info: Duration parameter\nThe following constraints are multiplied by p^textduration_b_k_y on the right-hand side to adjust for the duration of the timesteps since the ramp parameters are defined as rates. This assumption is based on the idea that all timesteps are the same in this section, which simplifies the formulation. However, in a flexible temporal resolution context, this may not hold true, and the duration needs to be the minimum duration of all the outgoing flows at the timestep block b_k_y. For more information, please visit the concept section on flexible time resolution.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Ramp-Up-Rate-Limit-WITH-Unit-Commitment-Method","page":"Mathematical Formulation","title":"Maximum Ramp-Up Rate Limit WITH Unit Commitment Method","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textflow above min_ak_yb_k_y - e^textflow above min_ak_yb_k_y-1 leq p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot p^textmax ramp up_ay cdot p^textduration_b_k_y cdot v^texton_ak_yb_k_y  quad\n  forall y in mathcalY forall a in left(mathcalA^textramp_y cap mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Ramp-Down-Rate-Limit-WITH-Unit-Commmitment-Method","page":"Mathematical Formulation","title":"Maximum Ramp-Down Rate Limit WITH Unit Commmitment Method","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textflow above min_ak_yb_k_y - e^textflow above min_ak_yb_k_y-1 geq - p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot p^textmax ramp down_ay cdot p^textduration_b_k_y cdot v^texton_ak_yb_k_y-1  quad\n  forall y in mathcalY forall a in left(mathcalA^textramp_y cap mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Ramp-Up-Rate-Limit-WITHOUT-Unit-Commitment-Method","page":"Mathematical Formulation","title":"Maximum Ramp-Up Rate Limit WITHOUT Unit Commitment Method","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y - sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y-1 leq p^textmax ramp up_ay cdot p^textduration_b_k_y cdot p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot v^textavailable units simple method_ay  quad\n  forall y in mathcalY forall a in  (mathcalA^textsimple investment cup mathcalA^textoperation) capleft(mathcalA^textramp_y setminus mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y \nsum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y - sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y-1 leq p^textmax ramp up_ay cdot p^textduration_b_k_y cdot p^textcapacity_a cdot  sum_v in mathcalV  (ayv) in mathcalD^textcompact investment p^textavailability profile_avk_yb_k_y cdot v^textavailable units compact method_ayv  quad\n  forall y in mathcalY forall a in  mathcalA^textcompact investment capleft(mathcalA^textramp_y setminus mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Ramp-Down-Rate-Limit-WITHOUT-Unit-Commitment-Method","page":"Mathematical Formulation","title":"Maximum Ramp-Down Rate Limit WITHOUT Unit Commitment Method","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y - sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y-1 geq - p^textmax ramp down_ay cdot p^textduration_b_k_y cdot p^textavailability profile_ayk_yb_k_y cdot p^textcapacity_a cdot v^textavailable units simple method_ay  quad\n  forall y in mathcalY forall a in  (mathcalA^textsimple investment cup mathcalA^textoperation) capleft(mathcalA^textramp_y setminus mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y \nsum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y - sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y-1 geq - p^textmax ramp down_ay cdot p^textduration_b_k_y cdot p^textcapacity_a cdot  sum_v in mathcalV  (ayv) in mathcalD^textcompact investment p^textavailability profile_avk_yb_k_y cdot v^textavailable units compact method_ayv  quad\n  forall y in mathcalY forall a in  mathcalA^textcompact investment capleft(mathcalA^textramp_y setminus mathcalA^textuc basic_y right) forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#dc-opf-constraints","page":"Mathematical Formulation","title":"DC Power Flow Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"For a flow f connecting assets a^textfrom and a^textto, which belongs to the set mathcalF^textdc-opf_y, the power flow constraints utilize the following equations:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textflow_fk_yb_k_y = fracp^textpower system basep^textreactance_fy cdot (v^textangle_a^textfromk_yb_k_y - v^textangle_a^texttok_yb_k_y) quad forall y in mathcalY forall f(a^textfroma^textto) in mathcalF^textdc-opf_y forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Energy-Consumer-Assets","page":"Mathematical Formulation","title":"Constraints for Energy Consumer Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Balance-Constraint-for-Consumers","page":"Mathematical Formulation","title":"Balance Constraint for Consumers","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The balance constraint sense depends on the method selected in the asset file's parameter consumer_balance_sense. The default value is =, but the user can choose geq as an option.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay v^textflow_fk_yb_k_y - sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y leftbeginarrayl =  geq endarrayright p^textdemand profile_ak_yb_k_y cdot p^textpeak demand_ay quad forall y in mathcalY forall a in mathcalA^textc forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Energy-Storage-Assets","page":"Mathematical Formulation","title":"Constraints for Energy Storage Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"There are two types of constraints for energy storage assets: rep-period and over-clustered-year. Rep-period constraints impose limits inside a representative period, while over-clustered-year constraints combine information from several representative periods (e.g., to model seasonal storage). For more information on this topic, refer to the concepts section or Tejada-Arango et al. (2018) and Tejada-Arango et al. (2019).","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"In addition, we define the following expression to determine the energy investment limit of the storage assets. This expression takes two different forms depending on whether the storage asset belongs to the set mathcalA^textse or not.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Investment energy method:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textavailable energy inv limit_ay = p^textenergy capacity_a cdot v^textavailable energy units_ay quad forall y in mathcalY forall a in mathcalA^texti cap mathcalA^textse_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"Fixed energy-to-power ratio method:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"e^textavailable energy inv limit_ay = p^textcapacity storage energy_a cdot p^textinitial storage units_ay quad forall y in mathcalY forall a in (mathcalA^texts setminus mathcalA^textse_y)","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\ne^textavailable energy inv limit_ay\n = p^textcapacity storage energy_a cdot p^textinitial storage units_ay \n + p^textenergy to power ratio_ay cdot p^textcapacity_a cdot v^textavailable units_ay quad forall y in mathcalY forall a in mathcalA^texti cap (mathcalA^texts setminus mathcalA^textse_y)\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#rep-period-storage-balance","page":"Mathematical Formulation","title":"Rep-period Constraint for Storage Balance","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textrep-period-storage_ak_yb_k_y = left(1 - p^textstorage loss from stored energy_a yright)^p^textduration_b_k_y\n cdot  v^textrep-period-storage_ak_yb_k_y-1  + p^textinflows_ak_yb_k_y + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay p^textduration_b_k_y cdot v^textflow_fk_yb_k_y - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay p^textduration_b_k_y cdot v^textflow_fk_yb_k_y quad\n  forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Rep-period-Constraint-for-Maximum-Storage-Level-Limit","page":"Mathematical Formulation","title":"Rep-period Constraint for Maximum Storage Level Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textrep-period-storage_ak_yb_k_y leq p^textmax rep-period-storage level_ak_yb_k_y cdot e^textavailable energy inv limit_ay quad forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Rep-period-Constraint-for-Minimum-Storage-Level-Limit","page":"Mathematical Formulation","title":"Rep-period Constraint for Minimum Storage Level Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textrep-period-storage_ak_yb_k_y geq p^textmin rep-period-storage level_ak_yb_k_y cdot e^textavailable energy inv limit_ay quad forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Rep-period-Cycling-Constraint","page":"Mathematical Formulation","title":"Rep-period Cycling Constraint","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The cycling constraint for the rep-period constraints links the first timestep block (b^textfirst_k_y) and the last one (b^textlast_k_y) in each representative period. The parameter p^textinit storage level_ay determines the considered equations in the model for this constraint:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If parameter p^textinit storage level_ay is not defined, the rep-period-storage level of the last timestep block (b^textlast_k_y) is used as the initial value for the first timestep block in the rep-period constraint for the storage balance.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textrep-period-storage_ak_yb^textfirst_k_y = v^textrep-period-storage_ak_yb^textlast_k_y  + p^textinflows_ak_yb^textfirst_k_y + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay p^textduration_b_k_y cdot v^textflow_fk_yb^textfirst_k_y - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay p^textduration_b_k_y cdot v^textflow_fk_yb^textfirst_k_y quad\n  forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If parameter p^textinit storage level_ay is defined, we use it as the initial value for the first timestep block in the rep-period constraint for the storage balance. In addition, the rep-period-storage level of the last timestep block (b^textlast_k_y) in each representative period must be greater than this initial value.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textrep-period-storage_ak_yb^textfirst_k_y = p^textinit storage level_ay  + p^textinflows_ak_yb^textfirst_k_y + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay p^textduration_b_k_y cdot v^textflow_fk_yb^textfirst_k_y - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay p^textduration_b_k_y cdot v^textflow_fk_yb^textfirst_k_y quad\n  forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textrep-period-storage_ak_yb^textlast_k_y geq p^textinit storage level_ay quad\n  forall y in mathcalY forall a in mathcalA^texts setminus mathcalA^textss forall k_y in mathcalK_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#over-clustered-year-storage-balance","page":"Mathematical Formulation","title":"Over-clustered-year Constraint for Storage Balance","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"This constraint allows us to consider the storage seasonality throughout the model's timeframe (e.g., a year) and stochastic scenario. The parameter p^textmap_sp_yk_y determines how much of the representative period k_y is in the period p_y, and stochastic scenario s. Researchers and practitioners often use clustering techniques to determine this parameter. For TulipaEnergyModel.jl, we recommend using TulipaClustering.jl to compute the clusters for the representative periods and their map.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"For the sake of simplicity, we show the constraint assuming the over-clustered-year-storage level between two consecutive periods p_y; however, TulipaEnergyModel.jl can handle more flexible period block definition through the timeframe definition in the model using the information in the timeframe partitions file, see schemas.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textover-clustered-year-storage_asp_y =  left(1 - p^textstorage loss from stored energy_a yright)^sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y\n cdot v^textover-clustered-year-storage_asp_y-1 + sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textinflows_ak_yb_k_y \n + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y \n - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y\n   forall s in mathcalS y in mathcalY forall a in mathcalA^textss forall p_y in mathcalP_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Over-clustered-year-Constraint-for-Maximum-Storage-Level-Limit","page":"Mathematical Formulation","title":"Over-clustered-year Constraint for Maximum Storage Level Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textover-clustered-year-storage_asp_y leq p^textmax over-clustered-year-storage level_ap_y cdot e^textavailable energy inv limit_ay quad forall s in mathcalS y in mathcalY forall a in mathcalA^textss forall p_y in mathcalP_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Over-clustered-year-Constraint-for-Minimum-Storage-Level-Limit","page":"Mathematical Formulation","title":"Over-clustered-year Constraint for Minimum Storage Level Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textover-clustered-year-storage_asp_y geq p^textmin over-clustered-year-storage level_ap_y cdot e^textavailable energy inv limit_ay quad forall s in mathcalS y in mathcalY forall a in mathcalA^textss forall p_y in mathcalP_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Over-clustered-year-Cycling-Constraint","page":"Mathematical Formulation","title":"Over-clustered-year Cycling Constraint","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The cycling constraint for the over-clustered-year constraints links the first-period block (p^textfirst_y) and the last one (p^textlast_y) in the timeframe. The parameter p^textinit storage level_ay determines the considered equations in the model for this constraint:","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If parameter p^textinit storage level_ay is not defined, the over-clustered-year-storage level of the last period block (p^textlast_y) is used as the initial value for the first-period block in the over-clustered-year constraint for the storage balance.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textover-clustered-year-storage_asp^textfirst_y =  v^textover-clustered-year-storage_asp^textlast_y + sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textinflows_ak_yb_k_y \n + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y \n - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y\n   s in mathcalS forall y in mathcalY forall a in mathcalA^textss\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If parameter p^textinit storage level_ay is defined, we use it as the initial value for the first-period block in the over-clustered-year constraint for the storage balance. In addition, the over-clustered-year-storage level of the last period block (p^textlast_y) in the timeframe must be greater than this initial value.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textover-clustered-year-storage_asp^textfirst_y =  p^textinit storage level_ay + sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textinflows_ak_yb_k_y \n + p^textcharging eff_ay cdot sum_f in mathcalF^textin_ay sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y \n - frac1p^textdischarging eff_ay cdot sum_f in mathcalF^textout_ay sum_k_y in mathcalK_y p^textmap_sp^textfirst_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k_y cdot v^textflow_fk_yb_k_y\n   s in mathcalS forall y in mathcalY forall a in mathcalA^textss\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textover-clustered-year-storage_asp^textlast_y geq p^textinit storage level_ay quad\n  s in mathcalS forall y in mathcalY forall a in mathcalA^textss","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Energy-Hub-Assets","page":"Mathematical Formulation","title":"Constraints for Energy Hub Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Balance-Constraint-for-Hubs","page":"Mathematical Formulation","title":"Balance Constraint for Hubs","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textin_ay v^textflow_fk_yb_k_y = sum_f in mathcalF^textout_ay v^textflow_fk_yb_k_y\nquad forall y in mathcalY forall a in mathcalA^texth forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Energy-Conversion-Assets","page":"Mathematical Formulation","title":"Constraints for Energy Conversion Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#conversion-balance-constraints","page":"Mathematical Formulation","title":"Balance Constraint for Conversion Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\np^textefficiency_ay cdot  sum_f in mathcalF^textin_ay p^textconversion coefficient_fy cdot v^textflow_fk_yb_k_y =  \n sum_f in mathcalF^textout_ay p^textconversion coefficient_fy cdot v^textflow_fk_yb_k_y \n quad forall y in mathcalY forall a in mathcalA^textcv forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#flows-relationships-constraints","page":"Mathematical Formulation","title":"Constraints for Flows Relationships","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"For each relationship x, two flows are related to each other using the following constraint. The first flow is defined in the set mathcalF^text1_xy and the second flow in the relationship is defined in set mathcalF^text2_xy. Notice, the same pair of flows can be defined in several relationships in the set mathcalX. In other words, two flows can have more than one flow relationship constraint. These constraints can be used to model Combined Heat and Power (CHP) operation constraints, CO2 emissions, or any other linear constraint that involves two flows in the model.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^text1_xy v^textflow_fk_yb_k_y leftbeginarrayl =  geq  leq endarrayright  p^textconstant_xy  + p^textratio_xy cdot sum_f in mathcalF^text2_xy v^textflow_fk_yb_k_y\nquad forall y in mathcalY forall x in mathcalX forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Transport-Assets","page":"Mathematical Formulation","title":"Constraints for Transport Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Transport-Flow-Limit","page":"Mathematical Formulation","title":"Maximum Transport Flow Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textflow_fk_yb_k_y leq p^textavailability profile_fyk_yb_k_y cdot p^textcapacity_f cdot v^textavailable export units_fy  quad forall y in mathcalY forall f in mathcalF^textt forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Minimum-Transport-Flow-Limit","page":"Mathematical Formulation","title":"Minimum Transport Flow Limit","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nv^textflow_fk_yb_k_y geq - p^textavailability profile_fyk_yb_k_y cdot p^textcapacity_f cdot v^textavailable import units_fy  quad forall y in mathcalY forall f in mathcalF^textt forall k_y in mathcalK_yforall b_k_y in mathcalB_k_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Constraints-for-Investments","page":"Mathematical Formulation","title":"Constraints for Investments","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Investment-Limit-for-Assets","page":"Mathematical Formulation","title":"Maximum Investment Limit for Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textinv_ay leq fracp^textinv limit_ayp^textcapacity_a quad forall y in mathcalY forall a in mathcalA^texti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If the parameter investment_integer is set to true, then the right-hand side of this constraint uses a least integer function (floor function) to guarantee that the limit is integer.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Energy-Investment-Limit-for-Assets","page":"Mathematical Formulation","title":"Maximum Energy Investment Limit for Assets","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textinv energy_ay leq fracp^textinv limit energy_ayp^textenergy capacity_a quad forall y in mathcalY  forall a in mathcalA^texti_y cap mathcalA^textse_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If the parameter investment_integer_storage_energy is set to true, then the right-hand side of this constraint uses a least integer function (floor function) to guarantee that the limit is integer.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Investment-Limit-for-Flows","page":"Mathematical Formulation","title":"Maximum Investment Limit for Flows","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"v^textinv_fy leq fracp^textinv limit_fyp^textcapacity_f quad forall y in mathcalY forall f in mathcalF^textti_y","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"If the parameter investment_integer is set to true, then the right-hand side of this constraint uses a least integer function (floor function) to guarantee that the limit is integer.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#over-clustered-year-energy-constraints","page":"Mathematical Formulation","title":"Over-clustered-year Energy Constraints","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"These constraints allow us to consider a maximum or minimum energy limit for an asset throughout the model's timeframe (e.g., a year). It uses the same principle explained in the over-clustered-year constraint for storage balance and in the Storage Modeling section.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Outgoing-Energy-During-the-Timeframe","page":"Mathematical Formulation","title":"Maximum Outgoing Energy During the Timeframe","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k cdot v^textflow_fk_yb_k_y leq  p^textmax over-clustered-year-storage profile_ap_y cdot p^textmax energy_ay\n   s in mathcalS forall y in mathcalY forall a in mathcalA^textmax e forall p_y in mathcalP_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Minimum-Outgoing-Energy-During-the-Timeframe","page":"Mathematical Formulation","title":"Minimum Outgoing Energy During the Timeframe","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_f in mathcalF^textout_ay sum_k_y in mathcalK_y p^textmap_sp_yk_y sum_b_k_y in mathcalB_k_y p^textduration_b_k cdot v^textflow_fk_yb_k_y geq  p^textmin over-clustered-year-storage profile_ap_y cdot p^textmin energy_ay\n   s in mathcalS forall y in mathcalY forall a in mathcalA^textmin e forall p_y in mathcalP_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#group-constraints","page":"Mathematical Formulation","title":"Constraints for Groups","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"The following constraints aggregate variables of different assets depending on the method that applies to the group.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#investment-group-constraints","page":"Mathematical Formulation","title":"Investment Limits of a Group","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"These constraints apply to assets in a group using the investment method mathcalG^textai_y. They help impose an investment potential of a spatial area commonly shared by several assets that can be invested there.","category":"page"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"info: Info\nThese constraints are applied to the investments each year. The model does not yet have investment limits to a group's available invested capacity.","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Minimum-Investment-Limit-of-a-Group","page":"Mathematical Formulation","title":"Minimum Investment Limit of a Group","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_a in mathcalA^texti_y  p^textgroup_a = g p^textcapacity_a cdot v^textinv_ay geq  p^textmin invest limit_gy\n   forall y in mathcalY forall g in mathcalG^textai_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/40-formulation/#Maximum-Investment-Limit-of-a-Group","page":"Mathematical Formulation","title":"Maximum Investment Limit of a Group","text":"","category":"section"},{"location":"40-scientific-foundation/40-formulation/","page":"Mathematical Formulation","title":"Mathematical Formulation","text":"beginaligned\nsum_a in mathcalA^texti_y  p^textgroup_a = g p^textcapacity_a cdot v^textinv_ay leq  p^textmax invest limit_gy\n   forall y in mathcalY forall g in mathcalG^textai_y\nendaligned","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#scientific-refs","page":"Scientific References","title":"Scientific References","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"One strength of Tulipa is that its concepts and mathematical formulation are based on academic research that pushes the frontier of energy system modelling. This section shows the primary scientific references used in the model.","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Pages = [\"45-scientific-references.md\"]\nDepth = [2, 3]","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Flexible-Connection-of-Energy-Assets","page":"Scientific References","title":"Flexible Connection of Energy Assets","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Tejada-Arango, D. A., Kiviluoma, J., & Morales-España, G. (2025). Debunking the speed-fidelity trade-off: Speeding-up large-scale energy models while keeping fidelity. International Journal of Electrical Power & Energy Systems, 168, 110674. https://doi.org/10.1016/j.ijepes.2025.110674","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Flexible-Temporal-Resolution","page":"Scientific References","title":"Flexible Temporal Resolution","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Gao, Z., Gazzani, M., Tejada-Arango, D. A., Siqueira, A. S., Wang, N., Gibescu, M., & Morales-España, G. (2025). Fully flexible temporal resolution for energy system optimization. Applied Energy, 396, 126267. https://doi.org/10.1016/j.apenergy.2025.126267","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Storage-Modelling","page":"Scientific References","title":"Storage Modelling","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/#Seasonal-Storage-with-Representative-Periods","page":"Scientific References","title":"Seasonal Storage with Representative Periods","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Tejada-Arango, D. A., Domeshek, M., Wogrin, S., & Centeno, E. (2018). Enhanced representative days and system states modeling for energy storage investment analysis. IEEE Transactions on Power Systems, 33(6), 6534–6544. https://doi.org/10.1109/TPWRS.2018.2819578","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Tejada-Arango, D. A., Wogrin, S., Siddiqui, A. S., & Centeno, E. (2019). Opportunity cost including short-term energy storage in hydrothermal dispatch models using a linked representative periods approach. Energy, 188, 116079. https://doi.org/10.1016/j.energy.2019.116079","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Tight-Formulations-to-Avoid-Simultaneous-Charging-and-Discharging","page":"Scientific References","title":"Tight Formulations to Avoid Simultaneous Charging and Discharging","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Elgersma, M. B., Aardal, K. I., Helistö, N., Kiviluoma, J., & De Weerdt, M. M. (2024). Tight MIP formulations for optimal operation and investment of storage including reserves. arXiv. https://arxiv.org/abs/2411.17484","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Ramping-and-Unit-Commitment","page":"Scientific References","title":"Ramping and Unit Commitment","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Damcı-Kurt, P., Küçükyavuz, S., Rajan, D., & Atamtürk, A. (2016). A polyhedral study of production ramping. Mathematical Programming, 158(1–2), 175–205. https://doi.org/10.1007/s10107-015-0919-9","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Morales-España, G., Ramos, A., & García-González, J. (2014). An MIP formulation for joint market-clearing of energy and reserves based on ramp scheduling. IEEE Transactions on Power Systems, 29(1), 476–488. https://doi.org/10.1109/TPWRS.2013.2259601","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Morales-España, G., Latorre, J. M., & Ramos, A. (2013). Tight and compact MILP formulation for the thermal unit commitment problem. IEEE Transactions on Power Systems, 28(4), 4897–4908. https://doi.org/10.1109/TPWRS.2013.2251373","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Multi-year-Investments","page":"Scientific References","title":"Multi-year Investments","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Wang, N., & Tejada-Arango, D. A. (2025). Discounting approaches in multi-year investment modelling for energy systems. ArXiv. https://arxiv.org/abs/2504.21709","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Wang, N., & Morales-España, G. (2025). Vintage-based formulations in multi-year investment modelling for energy systems. ArXiv. https://arxiv.org/abs/2505.00379","category":"page"},{"location":"40-scientific-foundation/45-scientific-references/#Two-Stage-Stochastic-Programming","page":"Scientific References","title":"Two-Stage Stochastic Programming","text":"","category":"section"},{"location":"40-scientific-foundation/45-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Kremer, L.A.A., de Weerdt, M.M., Neustroev, G., Morales-España, G. (2025). Stochastic programming for energy models: A blended cross-scenario representative periods approach. Master Thesis, TU Delft - Electrical Engineering, Mathematics and Computer Science. https://resolver.tudelft.nl/uuid:0e87f306-1c92-4eec-805f-72377ed57fb2","category":"page"},{"location":"10-tutorials/99-manual-steps/#tutorial-manual","page":"Advanced Control","title":"Advanced Control","text":"","category":"section"},{"location":"10-tutorials/99-manual-steps/#Manually-running-each-step","page":"Advanced Control","title":"Manually running each step","text":"","category":"section"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"If you need more control, you can create the energy problem first, then the optimization model inside it, and finally ask for it to be solved.","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"First create the DuckDB connection, populate the data, and create an empty EnergyProblem:","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"using DuckDB, TulipaIO, TulipaEnergyModel\n\ncp(joinpath(pkgdir(TulipaEnergyModel), \"test\", \"inputs\", \"Tiny\"), \"example-data\") # Copy the path to the test folder\ninput_dir = \"example-data\"\nconnection = DBInterface.connect(DuckDB.DB)\nread_csv_folder(connection, input_dir; schemas = TulipaEnergyModel.schema_per_table_name)\nenergy_problem = EnergyProblem(connection)","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"The energy problem does not have a model yet:","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"energy_problem.model === nothing","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"To create the internal model, call the function create_model!.","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"create_model!(energy_problem)\nenergy_problem.model","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"Now the internal model has been created and you can see the number of variables and constraints being used.","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"The model has not been solved yet, which can be verified through the solved flag inside the energy problem:","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"energy_problem.solved","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"Finally, you can solve the model:","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"solve_model!(energy_problem)","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"To compute the solution and save it in the DuckDB connection, you can use","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"save_solution!(energy_problem)","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"The solutions will be saved in the variable and constraints tables. To save the solution to CSV files, you can use export_solution_to_csv_files","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"mkdir(\"output_folder\")\nexport_solution_to_csv_files(\"output_folder\", energy_problem)","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"The objective value and the termination status are also included in the energy problem:","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"energy_problem.objective_value, energy_problem.termination_status","category":"page"},{"location":"10-tutorials/99-manual-steps/#Manually-creating-all-structures-without-EnergyProblem","page":"Advanced Control","title":"Manually creating all structures without EnergyProblem","text":"","category":"section"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"The EnergyProblem structure holds various internal structures, including the JuMP model and the DuckDB connection. There is currently no reason to manually create and maintain these structures yourself, so we recommend that you use the previous sections instead.","category":"page"},{"location":"10-tutorials/99-manual-steps/","page":"Advanced Control","title":"Advanced Control","text":"To avoid having to update this documentation whenever we make changes to the internals of TulipaEnergyModel before the v1.0.0 release, we will keep this section empty until then.","category":"page"},{"location":"80-ecosystem/#ecosystem","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"","category":"section"},{"location":"80-ecosystem/","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"Pages = [\"80-ecosystem.md\"]","category":"page"},{"location":"80-ecosystem/","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"There are multiple packages in the Tulipa ecosystem, which you can find on the TulipaEnergy organisation page. Other packages have minimal documentation, so the documentation is concentrated in the TulipaEnergyModel repository. (The docs you are currently reading!)","category":"page"},{"location":"80-ecosystem/","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"Here's an overview:","category":"page"},{"location":"80-ecosystem/","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"TulipaEnergyModel: The main package that takes data in Tulipa Format, produces the problem formulation, and sends the problem to the chosen solver.\nTulipaClustering: A pre-processing package that chooses representative periods for clustering data and produces the clusters and mapping.\nTulipaProfileFitting: A pre-processing package that fits (renewable) time series profiles from historical data to future target capacity factors.\nTulipaIO: A data-handling tool that communicates between Julia and DuckDB to manage data-handling for TulipaEnergyModel. It also includes convenience functions to help users build data processing pipelines using minimal SQL.\nTulipaVisualizer: A (prototype) visualisation dashboard for analysts to explore results.\nNearOptimalAlternatives: A post-optimisation package that uses methods such as Modelling to Generate Alternatives (MGA) to generate alternative solutions with objective function values near the optimal, but with output variables (solutions) as different from the optimal solution as possible.\nexcel2tulipa: A convenience package for importing data from Excel to DuckDB database files - only requiring the user to fill in a file that specifies the mapping from one to the other.","category":"page"},{"location":"80-ecosystem/","page":"Tulipa Ecosystem","title":"Tulipa Ecosystem","text":"Some case studies also have repositories, which are open for others to view and get ideas!","category":"page"},{"location":"#home","page":"Welcome","title":"Welcome","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"TulipaEnergyModel.jl is an optimization model for analysing energy systems (electricity, hydrogen, heat, natural gas, etc.). The model determines the optimal investment and operation decisions for different types of assets (production, consumption, conversion, storage, and transport). Tulipa is developed in Julia and depends on the JuMP.jl package.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Tulipa is free and easy to install. Check out Getting Started to start using Tulipa today!","category":"page"},{"location":"#Tulipa-in-a-Nutshell","page":"Welcome","title":"Tulipa in a Nutshell","text":"","category":"section"},{"location":"#Example-Questions","page":"Welcome","title":"Example Questions","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"Tulipa can answer questions such as:","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"How much flexible energy supply and demand is available? How much is needed in the future?\nHow will different investment decisions impact the balance and generation mix of the energy system?\nWhere will there be grid congestion in the future? How would placing [technology] at [location] impact congestion?\nHow will policy targets influence investment and dispatch?\nHow will a future energy system handle different weather patterns and extreme events (such as dunkelflaute)?","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Not sure if Tulipa is right for your project? Feel free to ask in our Discussions!","category":"page"},{"location":"#Scope-and-Features","page":"Welcome","title":"Scope & Features","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"For modellers, here is a brief summary of Tulipa's scope and features. More details can be found in the Concepts and Formulation.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Optimization Objective: Minimize total system cost for investment & dispatch (investment in production, conversion, storage, transport/grid)\nGeographic scope: Flexible (Anywhere - Region/Country/Continent)\nEnergy carriers: Any/All (electricity, gas, H2, heat, etc.)\nTimespan: Any (Usually Yearly or Multi-year)\nTime resolution: Fully Flexible - even mixing different resolutions (1-hr, 2-hr, 3-hr, etc) within a scenario)\nTemporal aggregation: Time series aggregation with blended representative periods using TulipaClustering\nStorage representation: Short- and Long-term storage - even while using representative periods","category":"page"},{"location":"#license","page":"Welcome","title":"License","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"This content is released under the Apache License 2.0 License.","category":"page"},{"location":"#Contributors","page":"Welcome","title":"Contributors","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://abelsiqueira.com\"><img src=\"https://avatars.githubusercontent.com/u/1068752?v=4?s=100\" width=\"100px;\" alt=\"Abel Soares Siqueira\"/><br /><sub><b>Abel Soares Siqueira</b></sub></a><br /><a href=\"#code-abelsiqueira\" title=\"Code\">💻</a> <a href=\"#review-abelsiqueira\" title=\"Reviewed Pull Requests\">👀</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/datejada\"><img src=\"https://avatars.githubusercontent.com/u/12887482?v=4?s=100\" width=\"100px;\" alt=\"Diego Alejandro Tejada Arango\"/><br /><sub><b>Diego Alejandro Tejada Arango</b></sub></a><br /><a href=\"#code-datejada\" title=\"Code\">💻</a> <a href=\"#review-datejada\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#ideas-datejada\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-datejada\" title=\"Research\">🔬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/g-moralesespana\"><img src=\"https://avatars.githubusercontent.com/u/42405171?v=4?s=100\" width=\"100px;\" alt=\"Germán Morales\"/><br /><sub><b>Germán Morales</b></sub></a><br /><a href=\"#research-g-moralesespana\" title=\"Research\">🔬</a> <a href=\"#ideas-g-moralesespana\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#fundingFinding-g-moralesespana\" title=\"Funding Finding\">🔍</a> <a href=\"#projectManagement-g-moralesespana\" title=\"Project Management\">📆</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/greg-neustroev\"><img src=\"https://avatars.githubusercontent.com/u/32451432?v=4?s=100\" width=\"100px;\" alt=\"Greg Neustroev\"/><br /><sub><b>Greg Neustroev</b></sub></a><br /><a href=\"#ideas-greg-neustroev\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-greg-neustroev\" title=\"Research\">🔬</a> <a href=\"#code-greg-neustroev\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/IsaiMaganTNO\"><img src=\"https://avatars.githubusercontent.com/u/163312300?v=4?s=100\" width=\"100px;\" alt=\"IsaiMaganTNO\"/><br /><sub><b>IsaiMaganTNO</b></sub></a><br /><a href=\"#review-IsaiMaganTNO\" title=\"Reviewed Pull Requests\">👀</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jkiviluo\"><img src=\"https://avatars.githubusercontent.com/u/40472544?v=4?s=100\" width=\"100px;\" alt=\"Juha Kiviluoma\"/><br /><sub><b>Juha Kiviluoma</b></sub></a><br /><a href=\"#ideas-jkiviluo\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-jkiviluo\" title=\"Research\">🔬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/clizbe\"><img src=\"https://avatars.githubusercontent.com/u/11889283?v=4?s=100\" width=\"100px;\" alt=\"Lauren Clisby\"/><br /><sub><b>Lauren Clisby</b></sub></a><br /><a href=\"#code-clizbe\" title=\"Code\">💻</a> <a href=\"#review-clizbe\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#ideas-clizbe\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#projectManagement-clizbe\" title=\"Project Management\">📆</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lsoucasse\"><img src=\"https://avatars.githubusercontent.com/u/135331272?v=4?s=100\" width=\"100px;\" alt=\"Laurent Soucasse\"/><br /><sub><b>Laurent Soucasse</b></sub></a><br /><a href=\"#ideas-lsoucasse\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mdeweerdt\"><img src=\"https://avatars.githubusercontent.com/u/1650785?v=4?s=100\" width=\"100px;\" alt=\"Mathijs de Weerdt\"/><br /><sub><b>Mathijs de Weerdt</b></sub></a><br /><a href=\"#fundingFinding-mdeweerdt\" title=\"Funding Finding\">🔍</a> <a href=\"#projectManagement-mdeweerdt\" title=\"Project Management\">📆</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gnawin\"><img src=\"https://avatars.githubusercontent.com/u/125902905?v=4?s=100\" width=\"100px;\" alt=\"Ni Wang\"/><br /><sub><b>Ni Wang</b></sub></a><br /><a href=\"#code-gnawin\" title=\"Code\">💻</a> <a href=\"#review-gnawin\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#ideas-gnawin\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-gnawin\" title=\"Research\">🔬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.svrijn.nl\"><img src=\"https://avatars.githubusercontent.com/u/8833517?v=4?s=100\" width=\"100px;\" alt=\"Sander van Rijn\"/><br /><sub><b>Sander van Rijn</b></sub></a><br /><a href=\"#ideas-sjvrijn\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/suvayu\"><img src=\"https://avatars.githubusercontent.com/u/229540?v=4?s=100\" width=\"100px;\" alt=\"Suvayu Ali\"/><br /><sub><b>Suvayu Ali</b></sub></a><br /><a href=\"#code-suvayu\" title=\"Code\">💻</a> <a href=\"#review-suvayu\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#ideas-suvayu\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gzclarence\"><img src=\"https://avatars.githubusercontent.com/u/70965161?v=4?s=100\" width=\"100px;\" alt=\"Zhi\"/><br /><sub><b>Zhi</b></sub></a><br /><a href=\"#ideas-gzclarence\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-gzclarence\" title=\"Research\">🔬</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/maaikeelgersma\"><img src=\"https://avatars.githubusercontent.com/u/55436655?v=4?s=100\" width=\"100px;\" alt=\"maaikeelgersma\"/><br /><sub><b>maaikeelgersma</b></sub></a><br /><a href=\"#ideas-maaikeelgersma\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#research-maaikeelgersma\" title=\"Research\">🔬</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nope82\"><img src=\"https://avatars.githubusercontent.com/u/80949386?v=4?s=100\" width=\"100px;\" alt=\"nope82\"/><br /><sub><b>nope82</b></sub></a><br /><a href=\"#review-nope82\" title=\"Reviewed Pull Requests\">👀</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->","category":"page"}]
}
